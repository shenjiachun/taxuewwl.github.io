<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>朝·闻·道</title>
  <subtitle>SnoWalker&#39;s Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wuwenliang.net/"/>
  <updated>2019-05-17T06:38:45.487Z</updated>
  <id>http://wuwenliang.net/</id>
  
  <author>
    <name>SnoWalker</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>研磨消息中间件kafka之消息持久化及副本</title>
    <link href="http://wuwenliang.net/2019/05/17/%E7%A0%94%E7%A3%A8%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6kafka%E4%B9%8B%E6%B6%88%E6%81%AF%E6%8C%81%E4%B9%85%E5%8C%96%E5%8F%8A%E5%89%AF%E6%9C%AC/"/>
    <id>http://wuwenliang.net/2019/05/17/研磨消息中间件kafka之消息持久化及副本/</id>
    <published>2019-05-17T05:55:55.000Z</published>
    <updated>2019-05-17T06:38:45.487Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文主要介绍Kafka的消息持久化策略及副本机制。</p>
</blockquote>
<h2 id="Kafka消息持久化策略"><a href="#Kafka消息持久化策略" class="headerlink" title="Kafka消息持久化策略"></a>Kafka消息持久化策略</h2><p>首先简要说明一下Kafka持久化消息的优点：</p>
<ol>
<li>Kafka通过消息持久化解耦了消息的生产者和消费者，这也是采用队列的优势，使得生产者和消费者均只需要关心自己的逻辑，而不需要直接感知到彼此的存在。</li>
<li>Kafka支持对消费过的消息进行“消息重演(Message Replay)”，而重演的基础就是实现消息持久化。</li>
</ol>
<p>Kafka为了保证消息落盘的实时，确保消息不丢失，没有采用直接写内存，等写满后一次性刷盘的策略，而是将数据立即写入文件系统的日志中，写入成功后才将结果返回给客户端告知客户端–消息已经成功写入。这么做的目的是，一方面实时地保存了数据，另一方面又减少了对内存的消耗，将内存空间尽量留给页缓存使用，从而提升了整体的性能。</p>
<a id="more"></a>
<h2 id="Kafka的副本机制"><a href="#Kafka的副本机制" class="headerlink" title="Kafka的副本机制"></a>Kafka的副本机制</h2><p>Kafka为了实现服务高可靠，采用了多副本机制。这么做的目的是为了解决分布式系统都会面临的高可靠保证的问题。</p>
<p>如果只保留一份数据，如果该节点down机，则节点中保存的消息日志就会丢失，从而造成难以估计的问题。因此Kafka采用目前应用较为广泛的一种解决策略：即采用冗余机制，通俗的说就是 <strong>“不要把鸡蛋放在一个篮子里。”</strong></p>
<p>Kafka的冗余机制简单地说就是将消息日志备份多份，而这些备份的日志在Kafka的概念中成为“副本（replica）”，之所以采用副本机制，核心的目的就是为了防止数据丢失。</p>
<p>对于副本，又有两个角色，分别为：<strong>leader replica(领导者副本)</strong> 、 <strong>follower replica(跟随者副本)</strong> 。 </p>
<p>只有leader角色的副本才对外提供服务，即只有leader副本才能够响应客户端发送的消息写入即消息消费的请求。而follower副本不对客户端提供服务，它只能被动获取leader副本的数据，保持与leader的消息同步。</p>
<p>当出现leader副本所在的broker发生down机，Kafka会在剩余的副本中选举新的leader继续提供服务，这也是Kafka与其他消息队列，如：RocketMQ的不同之处，也是它设计的精要及难点。</p>
<p>Kafka的leader选举依赖zookeeper进行。</p>
<h3 id="解析leader和follower"><a href="#解析leader和follower" class="headerlink" title="解析leader和follower"></a>解析leader和follower</h3><p>上文中我们提到Kafka的副本包括 leader副本和follower副本，与MySQL的主从机制不同，在Kafka的leader-follower体系中，同一时刻只有leader对外提供服务，follower只是起到冗余数据备份的作用，它与leader保持数据同步，并追随leader的状态进行自身状态的变更。</p>
<p>当leader节点出现down机，集群会发生新的leader选举过程，在剩余的follower节点中选举一个作为新的leader角色并对外提供服务，从而保证集群的高可用性。</p>
<p><strong>注意</strong> ：Kafka能够保证对于同一个分区（Partition，关于Partition会在后面的文章中讲解）下的多个replica一定不会分配在同一台broker上，通过这个规则，Kafka保证副本是有效且可靠的，实现了将鸡蛋存放在多个篮子中的目的。原理如图：</p>
<p><img src="/2019/05/17/研磨消息中间件kafka之消息持久化及副本/./kafka-replica.png" alt="Kafka的leader-follower副本机制示意图"></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文主要介绍Kafka的消息持久化策略及副本机制。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Kafka消息持久化策略&quot;&gt;&lt;a href=&quot;#Kafka消息持久化策略&quot; class=&quot;headerlink&quot; title=&quot;Kafka消息持久化策略&quot;&gt;&lt;/a&gt;Kafka消息持久化策略&lt;/h2&gt;&lt;p&gt;首先简要说明一下Kafka持久化消息的优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Kafka通过消息持久化解耦了消息的生产者和消费者，这也是采用队列的优势，使得生产者和消费者均只需要关心自己的逻辑，而不需要直接感知到彼此的存在。&lt;/li&gt;
&lt;li&gt;Kafka支持对消费过的消息进行“消息重演(Message Replay)”，而重演的基础就是实现消息持久化。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Kafka为了保证消息落盘的实时，确保消息不丢失，没有采用直接写内存，等写满后一次性刷盘的策略，而是将数据立即写入文件系统的日志中，写入成功后才将结果返回给客户端告知客户端–消息已经成功写入。这么做的目的是，一方面实时地保存了数据，另一方面又减少了对内存的消耗，将内存空间尽量留给页缓存使用，从而提升了整体的性能。&lt;/p&gt;
    
    </summary>
    
      <category term="研磨Kafka" scheme="http://wuwenliang.net/categories/%E7%A0%94%E7%A3%A8Kafka/"/>
    
    
      <category term="研磨Kafka" scheme="http://wuwenliang.net/tags/%E7%A0%94%E7%A3%A8Kafka/"/>
    
  </entry>
  
  <entry>
    <title>研磨消息中间件kafka之高吞吐低延时策略</title>
    <link href="http://wuwenliang.net/2019/05/17/%E7%A0%94%E7%A3%A8%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6kafka%E4%B9%8B%E9%AB%98%E5%90%9E%E5%90%90%E4%BD%8E%E5%BB%B6%E6%97%B6%E7%AD%96%E7%95%A5/"/>
    <id>http://wuwenliang.net/2019/05/17/研磨消息中间件kafka之高吞吐低延时策略/</id>
    <published>2019-05-17T03:41:09.000Z</published>
    <updated>2019-05-17T03:59:18.776Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>提升Kafka对消息处理的吞吐量及低延时主要通过磁盘顺序写、零拷贝（zero copy）以及利用页缓存(Page Cache)实现。下面我们进行具体说明。</p>
</blockquote>
<h3 id="消息顺序写"><a href="#消息顺序写" class="headerlink" title="消息顺序写"></a>消息顺序写</h3><p>Kafka的消息存储在每次写入时，只是将数据写入到操作系统的页缓存（PageCache）中，最终是由操作系统决定何时将页缓存中的数据落盘的。这样做的好处如下：</p>
<ol>
<li>由于页缓存是OS在内存中分配的，因此消息写入速度很快；</li>
<li>由于Kafka将消息写入页缓存中，因此避免了直接与底层文件系统打交道时候的繁琐流程，所有的I/O操作均交给了操作系统进行处理；</li>
<li>Kafka写操作采用了append方式（即：追加写入），这种顺序写盘的方式速度很快，避免了因随机写而导致的写入效率低下。</li>
</ol>
<a id="more"></a>
<p>对于上述的第三点，着重进行解析：</p>
<p>对于机械硬盘而言，对数据进行随机读写的吞吐量往往是很低的，但如果读写是顺序的，则速度很快，其顺序读写的速度甚至接近内存的随机I/O。而Kafka正是因此而采用了append方式进行消息的写入。</p>
<p>即：只在日志文件的末尾追加写入新消息，同时对于已经写入的消息，不允许进行修改。</p>
<p>正因为Kafka采用的是磁盘顺序访问方式，所以其消息发送的吞吐量很高，实际使用中达到每秒写入数万到数十万条消息是很轻松的。</p>
<h3 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h3><p>Kafka对消息读取时，首先尝试从OS的pageCache中读取，读取成功则将消息通过页缓存直接发送到网络的Socket上。该过程利用了Linux平台上的sendfile系统调用实现，该技术的核心原理便是零拷贝（Zero Copy）。</p>
<p>零拷贝的原理示意图如下:</p>
<p><img src="/2019/05/17/研磨消息中间件kafka之高吞吐低延时策略/./zerocopy.png" alt="零拷贝图示"></p>
<h4 id="详解零拷贝"><a href="#详解零拷贝" class="headerlink" title="详解零拷贝"></a>详解零拷贝</h4><p>接下来对该图做一个较为详细的讲解：</p>
<p>传统Linux操作系统在进行I/O操作时是通过数据的复制（或者说拷贝）实现的，在零拷贝技术出现之前，一个I/O操作会对数据进行多次拷贝，该过程涉及到内核态与用户态的上下文切换，对于CPU的压力较大，无法做到高效率的进行数据的传输。</p>
<p>而零拷贝就是为改善该问题而存在的，当内核驱动程序通过I/O处理数据(如：从磁盘中读取文件)时，不需要进行上下文切换，即：无需将数据从内核缓冲区（PageCache）复制到应用程序内存（即用户态），而是直接在内核空间中从内核缓冲区拷贝到Socket缓冲区。节省了内核缓冲区与用户态应用程序内存之间的数据拷贝，</p>
<p>实际上，内核缓冲区与Socket缓冲区之间并没有真正的做数据拷贝操作，而是做了地址映射，当底层网卡驱动要读取数据并发送到网络的时候，看起来好像是读取了Socket缓冲区的数据，实际上是直接读取了内核缓冲区的数据，数据实际上只有一份，而这是利用了DMA（Direct Memeory Access，直接内存存储器访问技术）实现的，通过DMA进行I/O操作，不仅避免了内核缓冲区与用户缓冲区的数据拷贝，还减少了内核缓冲区与socket缓冲区间的数据拷贝，因此得名“零拷贝”。</p>
<h4 id="Kafka的应用"><a href="#Kafka的应用" class="headerlink" title="Kafka的应用"></a>Kafka的应用</h4><p>Kafka消息消费机制使用的是Linux提供的sendfile系统调用实现的零拷贝技术，进一步说是通过Java的FileChannel.transferTo来实现的。</p>
<h3 id="页缓存"><a href="#页缓存" class="headerlink" title="页缓存"></a>页缓存</h3><p>Kafka大量使用了操作系统的页缓存，当读取消息时，由于大量的消息保存在页缓存中，因此读取消息能够直接命中缓存而不必穿透到底层的物理磁盘中获取消息，这极大的提升了消息读取的吞吐量。</p>
<p>在经过良好的系统调优的Kafka集群中，对于存在较明显负载的Broker机器而言，对物理磁盘的读操作也是很少的，这正是因为消息读取操作很大程度上是直接命中了页缓存而未到达物理磁盘。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>Kafka之所以能够表现出高吞吐、低延时的良好性能，主要依托本文提到的要点进行了设计：</p>
<ol>
<li>大量地使用OS的页缓存进行操作，减少I/O性能消耗</li>
<li>Kafka本身不进行物理I/O操作，而是利用了OS进行I/O操作</li>
<li>消息写入采用了追加写入的方式，避免了对磁盘的随机读写，从而极大的提高了写入的效率</li>
<li>采用“零拷贝”技术，极大的提升了网络传输效率。</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;提升Kafka对消息处理的吞吐量及低延时主要通过磁盘顺序写、零拷贝（zero copy）以及利用页缓存(Page Cache)实现。下面我们进行具体说明。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;消息顺序写&quot;&gt;&lt;a href=&quot;#消息顺序写&quot; class=&quot;headerlink&quot; title=&quot;消息顺序写&quot;&gt;&lt;/a&gt;消息顺序写&lt;/h3&gt;&lt;p&gt;Kafka的消息存储在每次写入时，只是将数据写入到操作系统的页缓存（PageCache）中，最终是由操作系统决定何时将页缓存中的数据落盘的。这样做的好处如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;由于页缓存是OS在内存中分配的，因此消息写入速度很快；&lt;/li&gt;
&lt;li&gt;由于Kafka将消息写入页缓存中，因此避免了直接与底层文件系统打交道时候的繁琐流程，所有的I/O操作均交给了操作系统进行处理；&lt;/li&gt;
&lt;li&gt;Kafka写操作采用了append方式（即：追加写入），这种顺序写盘的方式速度很快，避免了因随机写而导致的写入效率低下。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="研磨Kafka" scheme="http://wuwenliang.net/categories/%E7%A0%94%E7%A3%A8Kafka/"/>
    
    
      <category term="研磨Kafka" scheme="http://wuwenliang.net/tags/%E7%A0%94%E7%A3%A8Kafka/"/>
    
  </entry>
  
  <entry>
    <title>研磨消息中间件kafka之总览</title>
    <link href="http://wuwenliang.net/2019/05/17/%E7%A0%94%E7%A3%A8%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6kafka%E4%B9%8B%E6%80%BB%E8%A7%88/"/>
    <id>http://wuwenliang.net/2019/05/17/研磨消息中间件kafka之总览/</id>
    <published>2019-05-17T03:26:48.000Z</published>
    <updated>2019-05-17T03:59:15.498Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文是新系列“研磨”系列的开篇，该系列主要立足源码分析、核心技术点分析、常见问题整理等方面。一篇文章围绕一个中间件，立足于讲清、讲透、讲明白。</p>
</blockquote>
<p>系列的第一部分主题为–“研磨Kafka”，本篇中，我们先从宏观的视角窥探Kafka的核心角色，并对后文中要讲到的主题做一个宏观的概述。</p>
<h2 id="Kafka的设计原理及结构概述"><a href="#Kafka的设计原理及结构概述" class="headerlink" title="Kafka的设计原理及结构概述"></a>Kafka的设计原理及结构概述</h2><blockquote>
<p>首先对Kafka重要的角色进行总结。</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">要点</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Kafka概述</td>
<td style="text-align:left">Kafka是一款分布式消息中间件，但它不符合JMS规范。</td>
</tr>
<tr>
<td style="text-align:left">消费特点</td>
<td style="text-align:left">Kafka消费消息成功，不会马上删除消息。消息存储一段时间后，会被批量删除。</td>
</tr>
<tr>
<td style="text-align:left">Broker</td>
<td style="text-align:left">Broker是Kafka的服务端，主要作用为接收消息并对消息进行持久化存储。<br> Broker可以有多个，每一个Broker节点可存储多个Topic。但是Broker本身并不会存储消费的Offset（即消费者消费消息的位置），Offset数据由Consumer（消费者）保存，保存位置为Zookeeper。</td>
</tr>
<tr>
<td style="text-align:left">Topic</td>
<td style="text-align:left">Topic为消息主题，它是生产者与消费者之间进行消息传递的依据。单个Topic下包括多个Partition，它的所有元数据存储在zookeeper中。</td>
</tr>
<tr>
<td style="text-align:left">Partition</td>
<td style="text-align:left">Partition即分区，Kafka为提高性能及扩展性，将一个Topic分为多个分区，及Partition，每个Partition均可独立存放在一个Broker上，这保证了Kafka的可用性及稳定性。</td>
</tr>
<tr>
<td style="text-align:left">Producer</td>
<td style="text-align:left">Producer为消息生产者，它一般是集成了Kafka客户端的业务应用。<br> Producer负责发送消息到Broker。Producer直连Broker，具有往Topic下发布消息的能力。<br> 它会与Topic下的所有PartitionLeader保持Socket长连接。Producer具有同步、异步两种消息发送能力，且Producer支持消息的批量发送，即将多条消息缓存在客户端，在达到指定的时间延迟或者消息数量后，批量地提交给Broker。</td>
</tr>
<tr>
<td style="text-align:left">Consumer</td>
<td style="text-align:left">Consumer为消息消费者，它一般是集成了Kafka客户端的业务应用。消费者向Broker订阅Topic，并从Topic中接收消息。<br> 每一个消费者均属于某一个消费者组，且同消费者组中的消费者订阅同一个Topic，同一个Topic下的不同消费者分别订阅该Topic下不同Partition的数据。一个消费者可以订阅多个Partition，但同一个Partition只能被一个消费者订阅，该策略的目的是一定程度上避免消息被重复消费。<br> 可以通过增加Partition的方式对消费能力进行横向扩展。<br> 当出现某个消费者down机，消费过程会进行 <strong>Rebalance</strong>。</td>
</tr>
</tbody>
</table>
<h2 id="研磨Kafka主题"><a href="#研磨Kafka主题" class="headerlink" title="研磨Kafka主题"></a>研磨Kafka主题</h2><blockquote>
<p>该系列后续会涉及到的要点，在此处进行整理</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">要点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">如何提升Kafka的吞吐量及低延时</td>
</tr>
<tr>
<td style="text-align:left">Kafka的消息持久化方式</td>
</tr>
<tr>
<td style="text-align:left">Kafka如何实现负载均衡及故障转移</td>
</tr>
<tr>
<td style="text-align:left">如何理解Kafka的“伸缩性”特点</td>
</tr>
<tr>
<td style="text-align:left">概览主题（Topic）与分区（Partition）</td>
</tr>
<tr>
<td style="text-align:left">解释什么是消息位移offset</td>
</tr>
<tr>
<td style="text-align:left">解释下Kafka的副本机制如何实现</td>
</tr>
<tr>
<td style="text-align:left">Kafka如何利用“ISR机制”保证消息不丢失?</td>
</tr>
<tr>
<td style="text-align:left">kafka是否存在消息丢失的情况?</td>
</tr>
<tr>
<td style="text-align:left">概览Kafka的使用场景</td>
</tr>
</tbody>
</table>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文是新系列“研磨”系列的开篇，该系列主要立足源码分析、核心技术点分析、常见问题整理等方面。一篇文章围绕一个中间件，立足于讲清、讲透、讲明白。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;系列的第一部分主题为–“研磨Kafka”，本篇中，我们先从宏观
    
    </summary>
    
      <category term="研磨Kafka" scheme="http://wuwenliang.net/categories/%E7%A0%94%E7%A3%A8Kafka/"/>
    
    
      <category term="研磨Kafka" scheme="http://wuwenliang.net/tags/%E7%A0%94%E7%A3%A8Kafka/"/>
    
  </entry>
  
  <entry>
    <title>我说分布式之Gossip协议与Raft算法概览</title>
    <link href="http://wuwenliang.net/2019/05/13/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%B9%8BGossip%E5%8D%8F%E8%AE%AE%E4%B8%8ERaft%E7%AE%97%E6%B3%95%E6%A6%82%E8%A7%88/"/>
    <id>http://wuwenliang.net/2019/05/13/我说分布式之Gossip协议与Raft算法概览/</id>
    <published>2019-05-13T07:16:07.000Z</published>
    <updated>2019-05-13T08:41:29.683Z</updated>
    
    <content type="html"><![CDATA[<p>如果说分布式领域是一片蓝海，那各种分布式一致性算法就是其中闪耀的明珠。</p>
<p>本文中，我将着重介绍两个有趣且应用广泛的分布式一致性算法，Gossip协议与Raft算法。</p>
<a id="more"></a>
<h2 id="Gossip协议"><a href="#Gossip协议" class="headerlink" title="Gossip协议"></a>Gossip协议</h2><p>首先介绍一下Gossip协议，它的通俗解释如下：</p>
<blockquote>
<p>Gossip protocol 也叫 Epidemic Protocol （流行病协议），它还有很多别名，如：“谣言算法”、“疫情传播算法”等。</p>
</blockquote>
<p>这个协议的作用就像其名字表示的意思一样容易理解，它的运行方式在我们日常生活中也很常见，如疾病致病病菌的传播，森林大火扩散等。</p>
<p>Gossip协议的思想比较有趣，它的集群拓扑是去中心化的，如下图所示，是一个抽象的Gossip集群拓扑。</p>
<p><img src="/2019/05/13/我说分布式之Gossip协议与Raft算法概览/./gossip.png" alt="Gossip拓扑"></p>
<p>图中的每个节点均为运行着Gossip协议的Agent，包括服务器节点与普通节点，他们均加入了此Gossip集群并收发Gossip消息。</p>
<p>每经过一段固定的时间，每个节点都会随机选取几个与它保持连接的若干节点发送Gossip消息，与此同时，其他节点也会选择与自己保持连接的几个节点进行消息的传递。如此经过一点时间之后，整个集群都收到了这条Gossip消息，从而达到最终一致。</p>
<p><strong>注意</strong>  每次消息传递都会选择 <strong>尚未发送过的节点</strong> 进行散播，即收到消息的节点不会再往发送的节点散播，eg:A-&gt;B, 则当B进行散播的时候，不会再发送给A。</p>
<p>这样做的好处是当集群中的节点总量增加，分摊到每个节点的压力基本是稳定的，在一致性时间窗的忍耐限度内，整个集群的规模可以达到数千节点。</p>
<p>Gossip已经落地的产品包括但不限于Consul、Cassandra。其中Consul主要使用Gossip做为集群成员管理及消息广播的主要手段。Consul的Agent之间通过Gossip协议进行状态检查，通过节点之间互ping而减轻了作为server的节点的压力。如果有节点down机，任意与其保持连接的节点发现即可通过Gossip广播给整个集群。当该down机的节点重启后重新加入集群，一段时间后，它的状态也能够通过Gossip协议与其他的节点达成一致，这体现出Gossip协议具有的天然的分布式容错的特点。</p>
<blockquote>
<p>Gossip算法又被称为反熵（Anti-Entropy），表示在杂乱无章中寻求一致，这充分说明了Gossip的特点：在一个有界网络中，每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，只要这些节可以通过网络连通，最终他们的状态都是一致的，当然这也是疫情传播的特点。</p>
</blockquote>
<h2 id="Raft算法"><a href="#Raft算法" class="headerlink" title="Raft算法"></a>Raft算法</h2><p>接着了解下Raft算法，度娘如此介绍：</p>
<blockquote>
<p>Raft是一种共识算法，旨在替代Paxos。 它通过逻辑分离比Paxos更容易理解，但它也被正式证明是安全的，并提供了一些额外的功能。[1] Raft提供了一种在计算系统集群中分布状态机的通用方法，确保集群中的每个节点都同意一系列相同的状态转换。 </p>
<p>Raft通过当选的领导者达成共识。筏集群中的服务器是领导者或追随者，并且在选举的精确情况下可以是候选者（领导者不可用）。领导者负责将日志复制到关注者。它通过发送心跳消息定期通知追随者它的存在。每个跟随者都有一个超时（通常在150到300毫秒之间），它期望领导者的心跳。接收心跳时重置超时。如果没有收到心跳，则关注者将其状态更改为候选人并开始领导选举。</p>
</blockquote>
<p>Raft算法的主要包含如下要点：</p>
<ol>
<li>leader选取</li>
<li>日志复制</li>
<li>安全</li>
</ol>
<p>我们主要介绍leader选举以及日志复制，安全相关的内容本文不做展开讲解。</p>
<h3 id="Raft流程"><a href="#Raft流程" class="headerlink" title="Raft流程"></a>Raft流程</h3><p>首先，需要明确一个概念：</p>
<blockquote>
<p>raft 集群中的每个节点都可以根据集群运行的情况在三种状态间切换：follower（从节点）, candidate（候选者节点） 与 leader（主节点）。</p>
</blockquote>
<p>它们的职责描述如下：</p>
<h4 id="leader节点"><a href="#leader节点" class="headerlink" title="leader节点"></a>leader节点</h4><p>leader节点向follower节点进行日志同步</p>
<h4 id="follower节点"><a href="#follower节点" class="headerlink" title="follower节点"></a>follower节点</h4><p>follower节点只能从leader节点获取日志。</p>
<p>我们将通过一系列的拓扑图介绍下Raft协议是如何运行的。</p>
<h4 id="Raft基本流程"><a href="#Raft基本流程" class="headerlink" title="Raft基本流程"></a>Raft基本流程</h4><p>正常情况下，leader节点定时向follower节点发送heartbeat心跳包。</p>
<p><img src="/2019/05/13/我说分布式之Gossip协议与Raft算法概览/raft1.png" alt="集群稳定状态,leader发送心跳给follower"></p>
<p>由于某些异常情况发生，leader不再发送心跳包，或者因为网络超时，导致follower无法收到心跳包。如下</p>
<p><img src="/2019/05/13/我说分布式之Gossip协议与Raft算法概览/raft2.png" alt="leader与follower之间心跳断开"></p>
<p>此时，如果在一个时间周期（election timeout），follower没有收到来自leader的心跳包，则节点将会发起leader选举。</p>
<p>某个节点发生election timeout，节点的 raft 状态机将自己的状态变更为candidate（候选者），并向其余的follower发起投票。</p>
<p><img src="/2019/05/13/我说分布式之Gossip协议与Raft算法概览/raft3.png" alt="某个follower转变为candidate并发起投票请求"></p>
<p>当该候选节点收到了集群中超过半数的节点的接受投票响应后，该候选节点成为leader节点，并开始接受并保存client的数据对外提供服务，并向其余的follower节点同步日志。它作为leader节点同时还会向其余的存活的follower节点发送heartbeat心跳包来保持其leader地位。</p>
<p><img src="/2019/05/13/我说分布式之Gossip协议与Raft算法概览/raft4.png" alt="candidate接受投票成为leader节点"></p>
<p>当经过一点时间后，原先的leader重启并重新加入到集群中，此时需要比较两个leader的步进数，步进数低的那个leader将切换为follower节点（此处即为重启恢复的那个leader）<br>：</p>
<p><img src="/2019/05/13/我说分布式之Gossip协议与Raft算法概览/raft5.png" alt="原先的leader再次加入节点，比较步进数成为follower节点"></p>
<p>此时leader节点已经变更，因此之前的那个leader节点（此时已经是follower）中的日志将会被清理，并作为follower接受当前leader的日志同步，从而保持一致。</p>
<p><img src="/2019/05/13/我说分布式之Gossip协议与Raft算法概览/raft6.png" alt="原先的leader再次加入节点，日志同步，保持心跳"></p>
<h2 id="小结复盘"><a href="#小结复盘" class="headerlink" title="小结复盘"></a>小结复盘</h2><p>关于Gossip协议，我们需要了解最终一致的达成过程，同时我们需要知道当前已落地的应用为Cassandra缓存中间件、Consul等。</p>
<p>关于Raft，我们要明确两个要素: 选主以及日志复制，目前落地Raft协议的中间件有：Etcd、consul等。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.cnblogs.com/williamjie/p/9369795.html" target="_blank" rel="external">Consul实现原理系列文章2: 用Gossip来做集群成员管理和消息广播</a></p>
<p><a href="https://www.jianshu.com/p/8e4bbe7e276c" target="_blank" rel="external">共识算法：Raft</a></p>
<p><a href="https://www.jianshu.com/p/aa77c8f4cb5c" target="_blank" rel="external">说一说那些我也不太懂的 Raft 协议</a></p>
<p><a href="https://www.jianshu.com/p/8279d6fd65bb" target="_blank" rel="external">P2P 网络核心技术：Gossip 协议</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果说分布式领域是一片蓝海，那各种分布式一致性算法就是其中闪耀的明珠。&lt;/p&gt;
&lt;p&gt;本文中，我将着重介绍两个有趣且应用广泛的分布式一致性算法，Gossip协议与Raft算法。&lt;/p&gt;
    
    </summary>
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/categories/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/tags/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>跟我学SPI之SPI详解及实战</title>
    <link href="http://wuwenliang.net/2019/04/17/%E8%B7%9F%E6%88%91%E5%AD%A6SPI%E4%B9%8BSPI%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%AE%9E%E6%88%98/"/>
    <id>http://wuwenliang.net/2019/04/17/跟我学SPI之SPI详解及实战/</id>
    <published>2019-04-17T05:55:51.000Z</published>
    <updated>2019-04-24T01:16:10.362Z</updated>
    
    <content type="html"><![CDATA[<p>首先了解下何为SPI，这里引用Dubbo官方对SPI的解说，比较全面。<a href="http://dubbo.apache.org/zh-cn/docs/source_code_guide/dubbo-spi.html" target="_blank" rel="external">SPI简介</a></p>
<blockquote>
<p>SPI 全称为 Service Provider Interface，是一种服务发现机制。SPI 的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。正因此特性，我们可以很容易的通过 SPI 机制为我们的程序提供拓展功能。</p>
</blockquote>
<p>Dubbo本身实现了对JDK的SPI的扩展，为了能够更好的理解Dubbo的SPI机制，我们需要理解JDK的原生SPI原理。</p>
<p>从概念可以看出，SPI机制是一种服务发现机制，能够在运行时动态的增加、获取服务实现。个人感觉很像设计原则中的里氏替换原则。</p>
<p>我将通过一个实例来讲解如何对JDK的SPI进行运用。</p>
<a id="more"></a>
<h2 id="首先定义接口"><a href="#首先定义接口" class="headerlink" title="首先定义接口"></a>首先定义接口</h2><p>首先定义一个名为DemoInterface的接口，定义两个抽象方法。</p>
<pre><code>public interface DemoInterface&lt;T, P&gt; {

    T execute(P p);

    String className();
}
</code></pre><p>注意：<strong>className()</strong> 实现类实现该方法，需要返回子类的全限定名。</p>
<h2 id="定义实现-UserServiceImpl"><a href="#定义实现-UserServiceImpl" class="headerlink" title="定义实现-UserServiceImpl"></a>定义实现-UserServiceImpl</h2><p>为了说明问题，我们需要定义两个不同的实现类，首先定义UserServiceImpl，实现接口的方法，execute方法为通过userName构造不同的User实体并返回。</p>
<pre><code>public class UserServiceImpl implements  DemoInterface&lt;User, String&gt; {

    @Override
    public User execute(String userName) {
        return new User().setUserId(&quot;123123123&quot;).setUserName(userName);
    }

    @Override
    public String className() {
        return UserServiceImpl.class.getCanonicalName();
    }
}
</code></pre><p>className()返回了UserServiceImpl的全限定名。</p>
<h2 id="定义实现-JetFighterServiceImpl"><a href="#定义实现-JetFighterServiceImpl" class="headerlink" title="定义实现-JetFighterServiceImpl"></a>定义实现-JetFighterServiceImpl</h2><p>不同于UserServiceImpl，JetFighterServiceImpl为战斗机（太中二了）实现，execute方法为通过战机型号返回对应的战机实例。所有的战机实例通过static代码块加载到ConcurrentHashMap中。</p>
<pre><code>public class JetFighterServiceImpl implements DemoInterface&lt;JetFighter, String&gt; {

    private static final Map&lt;String, JetFighter&gt; JET_FIGHTER_MAP =
            new ConcurrentHashMap&lt;&gt;(16);

    static {
        JET_FIGHTER_MAP.put(&quot;f15&quot;, new JetFighter().setJetId(&quot;f15&quot;).setJetName(&quot;F15战斗机&quot;));
        JET_FIGHTER_MAP.put(&quot;f22&quot;, new JetFighter().setJetId(&quot;f22&quot;).setJetName(&quot;F22战斗机&quot;));
        JET_FIGHTER_MAP.put(&quot;f35&quot;, new JetFighter().setJetId(&quot;f35&quot;).setJetName(&quot;F35战斗机&quot;));
        JET_FIGHTER_MAP.put(&quot;j20&quot;, new JetFighter().setJetId(&quot;j20&quot;).setJetName(&quot;J15战斗机&quot;));
        JET_FIGHTER_MAP.put(&quot;j31&quot;, new JetFighter().setJetId(&quot;j31&quot;).setJetName(&quot;J31战斗机&quot;));
    }

    @Override
    public JetFighter execute(String s) {
        return JET_FIGHTER_MAP.get(s);
    }

    @Override
    public String className() {
        return JetFighterServiceImpl.class.getCanonicalName();
    }
}
</code></pre><p>className()返回了JetFighterServiceImpl的全限定名。</p>
<h2 id="通过ServiceLoader加载服务"><a href="#通过ServiceLoader加载服务" class="headerlink" title="通过ServiceLoader加载服务"></a>通过ServiceLoader加载服务</h2><p>定义好不同的接口实现，我们需要通过ServiceLoader加载服务，建立一个bean工厂，将服务实例解析后设置到bean工厂中。</p>
<pre><code>public class DemoServiceFactory {

    private static final Map&lt;String, DemoInterface&gt; serviveContext =
            new ConcurrentHashMap&lt;&gt;();

    private static final DemoServiceFactory factory = null;

    private DemoServiceFactory() {
        ServiceLoader&lt;DemoInterface&gt; serviceLoaders =
                ServiceLoader.load(DemoInterface.class);
        for (DemoInterface demoInterface : serviceLoaders) {
            serviveContext.put(demoInterface.className(), demoInterface);
        }
    }

    public static DemoServiceFactory getInstance() {
        if(factory == null) {
            synchronized (Object.class) {
                if (factory == null) {
                    factory = new DemoServiceFactory();
                }
            }
        }
        return factory;
    }

    public DemoInterface getServiceInstance(String className) {
        DemoInterface demoInterface = serviveContext.get(className);
        if (demoInterface == null) {
            throw new IllegalArgumentException(&quot;请输入合法的className&quot;);
        }
        return demoInterface;
    }
}
</code></pre><p>这里解释下DemoServiceFactory工厂的实现。</p>
<p>DemoServiceFactory是基于线程安全懒汉模式的单例实现。首先实例化了一个ConcurrentHashMap，它就是我们的Bean容器，key为DemoInterface的实例全限定名，value为DemoInterface的具体实例。</p>
<p>在DemoServiceFactory的私有构造方法中，我们通过 <strong>ServiceLoader.load(Class service)</strong> 方法加载了所有的DemoInterface。</p>
<p>然后通过foreach遍历所有的DemoInterface的实例，并依次加载到serviveContext中，key=实例的全限定类名，value为实例。</p>
<p>getServiceInstance(String className) 方法通过实例的全限定名，从serviveContext中获取对应的DemoInterface的实现类的实例。</p>
<h2 id="编写服务定义"><a href="#编写服务定义" class="headerlink" title="编写服务定义"></a>编写服务定义</h2><p>最后一步，也是比较关键的步骤。</p>
<p>我们需要在classpath下建立META-INF，并在META-INF下建立services文件夹，并建立文件名为DemoInterface的全限定的文本文件，文件名为：com.snowalker.spi.DemoInterface</p>
<p>我的项目基于maven构建，因此我在resources下建立了目录 <strong>META-INF/services/</strong> ，在该路径下建立文本文件，名为 <strong>com.snowalker.spi.DemoInterface</strong> 。</p>
<p>打开该文本文件，并在其中添加所有DemoInterface的实现类的全限定名，一行一个，具体的内容如下：</p>
<pre><code># DemoInterface实现类
com.snowalker.impl.UserServiceImpl
com.snowalker.impl.JetFighterServiceImpl
</code></pre><p>注释不会解析。</p>
<p>到此，我们的SPI开发就基本结束了，应用通过DemoServiceFactory获取实例的时候，ServiceLoader会扫描META-INF/services下的接口定义文件，并加载所有的实例。</p>
<h2 id="编写测试"><a href="#编写测试" class="headerlink" title="编写测试"></a>编写测试</h2><p>我们写一个测试用例测试一下上面写的demo是否能满足我们的需求–通过实现类的全限定名获取到对应的实现类实例。</p>
<p>代码如下：</p>
<pre><code>DemoServiceFactory demoServiceFactory =
        DemoServiceFactory.getInstance();
String userServiceImplClassName = &quot;com.snowalker.impl.UserServiceImpl&quot;;
String jetFighterServiceImplClassName = &quot;com.snowalker.impl.JetFighterServiceImpl&quot;;

DemoInterface&lt;User, String&gt; userInstance = demoServiceFactory.getServiceInstance(userServiceImplClassName);
DemoInterface&lt;JetFighter, String&gt; jetFightInstance = demoServiceFactory.getServiceInstance(jetFighterServiceImplClassName);

System.out.println(&quot;---------用户服务实例调用开始-----------&quot;);
User result = userInstance.execute(&quot;snowalker&quot;);
System.out.println(&quot;         用户服务实例调用结束：&quot;  + result.toString());

System.out.println(&quot;---------战斗机服务调用开始--------------&quot;);
JetFighter fighter = jetFightInstance.execute(&quot;j20&quot;);
System.out.println(&quot;         战斗机服务实例调用结束：&quot;  + fighter.toString());
</code></pre><p>我们分别获取UserServiceImpl、JetFighterServiceImpl的实例，并调用各自的execute方法。</p>
<p>运行测试用例，打印如下：</p>
<pre><code>---------用户服务实例调用开始-----------
        用户服务实例调用结束：User{userId=&apos;123123123&apos;, userName=&apos;snowalker&apos;}
---------战斗机服务调用开始--------------
        战斗机服务实例调用结束：JetFighter{jetId=&apos;j20&apos;, jetName=&apos;J15战斗机&apos;}

Process finished with exit code 0
</code></pre><p>可以看到，调用达到预期，通过SPI的ServiceLoader，我们实现了一种更加优雅的工厂模式。</p>
<p>之所以说优雅，就在于我们能够通过只编写接口实现类并在META-INF/services下的接口定义文件中配置实现类的全限定名，就可以按需获取不同的接口实例。这种方式在大量的接口实现类场景下优势很明显，我们不需要实现包扫描以及实例的加载，避免了重复造轮子，而且借助SPI方式，实现更加稳定美观。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>实际上，SPI本质上是面向接口编程的一种体现，中间件厂商通过SPI能够实现插件的可插拔。它的优势在于在模块装配的时候不需要显式的指定实现而能够动态的寻找到服务实现，有点像IOC的机制。业务不需要关系服务装配，将服务装配的控制权反转给了框架本身。</p>
<p>最后再总结一下SPI的开发流程: </p>
<ol>
<li>服务提供者需要提供服务接口的声明</li>
<li>服务提供者在jar包META-INF/services/目录里创建一个以服务接口命名的文件</li>
<li>服务实现方实现服务提供者发布的接口，并在META-INF/services/目录里以服务接口命名的文件中添加该实现的全限定名。</li>
<li>外部程序装配该模块时，通过jar包META-INF/services/里的配置文件就可以找到具体的实现类名，java.util.ServiceLoader将接口实现装载并实例化从而完成模块的注入。且该实例过程对于调用方是透明的，</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;首先了解下何为SPI，这里引用Dubbo官方对SPI的解说，比较全面。&lt;a href=&quot;http://dubbo.apache.org/zh-cn/docs/source_code_guide/dubbo-spi.html&quot;&gt;SPI简介&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;SPI 全称为 Service Provider Interface，是一种服务发现机制。SPI 的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。正因此特性，我们可以很容易的通过 SPI 机制为我们的程序提供拓展功能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Dubbo本身实现了对JDK的SPI的扩展，为了能够更好的理解Dubbo的SPI机制，我们需要理解JDK的原生SPI原理。&lt;/p&gt;
&lt;p&gt;从概念可以看出，SPI机制是一种服务发现机制，能够在运行时动态的增加、获取服务实现。个人感觉很像设计原则中的里氏替换原则。&lt;/p&gt;
&lt;p&gt;我将通过一个实例来讲解如何对JDK的SPI进行运用。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>自己写分布式调度组件shield-job之使用单机模式</title>
    <link href="http://wuwenliang.net/2019/04/16/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E8%B0%83%E5%BA%A6%E7%BB%84%E4%BB%B6shield-job%E4%B9%8B%E4%BD%BF%E7%94%A8%E5%8D%95%E6%9C%BA%E6%A8%A1%E5%BC%8F/"/>
    <id>http://wuwenliang.net/2019/04/16/自己写分布式调度组件shield-job之使用单机模式/</id>
    <published>2019-04-16T03:28:11.000Z</published>
    <updated>2019-04-16T08:19:08.044Z</updated>
    
    <content type="html"><![CDATA[<p>考虑到部分业务场景下没有使用RocketMQ，因此我在之前的基础上添加了对单机模式调度的封装。</p>
<p>本文就单机模式下，不依赖RocketMQ如何使用shield-job进行定时任务调度展开讲解。</p>
<p>目前有两种主要的调用方式，客户端实现抽象调度方法 <strong>execute</strong> ，或者直接使用内置的 <strong>executeOneway</strong> 方法进行调用，接下来分别介绍两种方式。</p>
<a id="more"></a>
<h2 id="调用方式1-自行实现execute方法"><a href="#调用方式1-自行实现execute方法" class="headerlink" title="调用方式1:自行实现execute方法"></a>调用方式1:自行实现execute方法</h2><p>首先定义单机调度处理器，继承抽象类AbstractJobScheduleStandaloneHandler，需要实现execute()方法。</p>
<pre><code>public class MyStandaloneScheduleHandler extends AbstractJobScheduleStandaloneHandler {

        @Override
        public void execute() {
            // 生产
            List&lt;String&gt; list = super.produce(new JobScheduleProducerListener&lt;String&gt;() {
                @Override
                public List&lt;String&gt; produce(Object arg) {
                    final List&lt;String&gt; strings2 = new ArrayList&lt;&gt;(10);
                    for (int i = 0; i &lt; 10; i++) {
                        String str = &quot;snowalker-----&quot; + i;
                        strings2.add(str);
                    }
                    return strings2;
                }
            }, null);

            // 消费
            super.consume(new JobScheduleConsumerListener&lt;String&gt;() {
                @Override
                public Object consume(String s) {
                    LOGGER.info(&quot;consuming start!!!! s = &quot; + s);
                    return null;
                }
            }, list);
        }
    }
</code></pre><p>在实现类的execute()中，分别调用produce和consume方法，实现生产和消费逻辑。</p>
<p>其中，在 <strong>produce(JobScheduleProducerListener<t> jobScheduleStandaloneListener, Object arg)</t></strong> 方法中实现生产逻辑，客户端需要传入JobScheduleProducerListener的实例，调用方便的情况下可以直接使用匿名内部类或者lambda表达式，将需要进行调度的列表生产出来，具体的生产过程业务方需要关心。</p>
<p>生产完成后，将列表返回，并传入 <strong>consume(JobScheduleConsumerListener<t> jobScheduleConsumerListener, List<t> list)</t></t></strong> 方法的第二个参数中，第一个参数为JobScheduleConsumerListener的实例，客户端需要实现消费逻辑，这里的逻辑是单个元素的消费逻辑，不需要再进行迭代了，这样设计的目的是保证集合和单个实体的消费逻辑的统一性。</p>
<p>写个测试用例测一下，日志输入如下。</p>
<pre><code>13:46:56.528 [main] INFO COMMON-APPENDER - consuming start!!!! s = snowalker-----0
13:46:56.532 [main] INFO COMMON-APPENDER - consuming start!!!! s = snowalker-----1
13:46:56.532 [main] INFO COMMON-APPENDER - consuming start!!!! s = snowalker-----2
13:46:56.532 [main] INFO COMMON-APPENDER - consuming start!!!! s = snowalker-----3
13:46:56.532 [main] INFO COMMON-APPENDER - consuming start!!!! s = snowalker-----4
13:46:56.532 [main] INFO COMMON-APPENDER - consuming start!!!! s = snowalker-----5
13:46:56.532 [main] INFO COMMON-APPENDER - consuming start!!!! s = snowalker-----6
13:46:56.532 [main] INFO COMMON-APPENDER - consuming start!!!! s = snowalker-----7
13:46:56.532 [main] INFO COMMON-APPENDER - consuming start!!!! s = snowalker-----8
13:46:56.532 [main] INFO COMMON-APPENDER - consuming start!!!! s = snowalker-----9
</code></pre><h2 id="调用方式2-executeOneway方式"><a href="#调用方式2-executeOneway方式" class="headerlink" title="调用方式2:executeOneway方式"></a>调用方式2:executeOneway方式</h2><p>如果业务逻辑简单，推荐使用executeOneway方式，自描述性更强，调用方式如下</p>
<p>首先定义业务的调度实现类，execute()使用空实现即可。</p>
<pre><code>public class MyStandaloneScheduleHandler2 extends AbstractJobScheduleStandaloneHandler {

    @Override
    public void execute() {
    }
}
</code></pre><p>调用逻辑如下：</p>
<pre><code>MyStandaloneScheduleHandler scheduleHandler2 = new MyStandaloneScheduleHandler();
// ②
scheduleHandler2.executeOneway(new JobScheduleProducerListener&lt;String&gt;() {
    @Override
    public List&lt;String&gt; produce(Object arg) {
        final List&lt;String&gt; strings2 = new ArrayList&lt;&gt;(10);
        for (int i = 0; i &lt; 10; i++) {
            String str = &quot;executeOneway---snowalker-----&quot; + i;
            strings2.add(str);
        }
        return strings2;
    }
}, new JobScheduleConsumerListener&lt;String&gt;() {
    @Override
    public Object consume(String s) {
        LOGGER.info(&quot;executeOneway---consuming start!!!! s = &quot; + s);
        return null;
    }
});
</code></pre><p>调用MyStandaloneScheduleHandler实例的executeOneway方法，将生产监听器JobScheduleProducerListener实例，消费监听器JobScheduleConsumerListener实例传入。对②处代码的理解就很直观：通过executeOneway发起业务调度，将JobScheduleProducerListener生产的列表在JobScheduleConsumerListener中进行consume，具体的迭代同样封装在了AbstractJobScheduleStandaloneHandler内部。</p>
<h2 id="springboot调度实战"><a href="#springboot调度实战" class="headerlink" title="springboot调度实战"></a>springboot调度实战</h2><p>上文中讲解了如何调用单机模式的shield-job，这里通过springboot的定时任务写一个实例，增强理解。</p>
<p>demo基于 <a href="http://wuwenliang.net/2019/04/15/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E8%B0%83%E5%BA%A6%E7%BB%84%E4%BB%B6shield-job%E4%B9%8B%E4%BD%BF%E7%94%A8shield-job/">自己写分布式调度组件shield-job之使用shield-job</a> 中的代码。</p>
<p>代码如下：</p>
<pre><code>@Component
public class OrderInfoJobProducerStandalone extends AbstractJobScheduleStandaloneHandler {

    private static final Logger LOGGER = LoggerFactory.getLogger(OrderInfoJobProducerStandalone.class);

    private JobProducerExecutor jobProducerExecutor;

    @PostConstruct
    public void init() {
        LOGGER.info(&quot;单机模式调度执行初始化......&quot;);
    }

    @Scheduled(cron = &quot;${order.standalone.cron}&quot;)
    public void execute() {
        executeOneway(new JobScheduleProducerListener&lt;String&gt;() {
            @Override
            public List&lt;String&gt; produce(Object arg) {
                LOGGER.info(&quot;单机模式作业生产开始...&quot;);
                final List&lt;String&gt; strings2 = new ArrayList&lt;&gt;(10);
                for (int i = 0; i &lt; 10; i++) {
                    String str = &quot;executeOneway---snowalker-----&quot; + i;
                    strings2.add(str);
                }
                LOGGER.info(&quot;单机模式作业生产结束...&quot;);
                return strings2;
            }
        }, new JobScheduleConsumerListener&lt;String&gt;() {
            @Override
            public Object consume(String s) {
                LOGGER.info(&quot;executeOneway---consuming start!!!! s = &quot; + s);
                return null;
            }
        });
    }
}
</code></pre><p>配置的调度cron表达式为：0/3 <em> </em> <em> </em> ?</p>
<p>从0s开始，每隔扫描运行一次。</p>
<p>运行程序日志打印如下：</p>
<pre><code>2019-04-16 14:09:24.001 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [40] 
    - 单机模式作业生产开始...
2019-04-16 14:09:24.001 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [46] 
    - 单机模式作业生产结束...
2019-04-16 14:09:24.001 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [52] 
    - executeOneway---consuming start!!!! s = executeOneway---snowalker-----0
2019-04-16 14:09:24.001 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [52] 
    - executeOneway---consuming start!!!! s = executeOneway---snowalker-----1
2019-04-16 14:09:24.001 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [52] 
    - executeOneway---consuming start!!!! s = executeOneway---snowalker-----2
2019-04-16 14:09:24.001 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [52]
    - executeOneway---consuming start!!!! s = executeOneway---snowalker-----3
2019-04-16 14:09:24.002 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [52] 
    - executeOneway---consuming start!!!! s = executeOneway---snowalker-----4
2019-04-16 14:09:24.002 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [52] 
    - executeOneway---consuming start!!!! s = executeOneway---snowalker-----5
2019-04-16 14:09:24.002 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [52] 
    - executeOneway---consuming start!!!! s = executeOneway---snowalker-----6
2019-04-16 14:09:24.002 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [52] 
    - executeOneway---consuming start!!!! s = executeOneway---snowalker-----7
2019-04-16 14:09:24.002 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [52] 
    - executeOneway---consuming start!!!! s = executeOneway---snowalker-----8
2019-04-16 14:09:24.002 [scheduling-1] INFO  c.s.s.j.p.s.OrderInfoJobProducerStandalone [52] 
    - executeOneway---consuming start!!!! s = executeOneway---snowalker-----9
</code></pre><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>到此就完成了对纯单机模式下调度的抽象和封装的讲解，这种方式对于没有RocketMQ运维能力的项目来讲比较适用。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;考虑到部分业务场景下没有使用RocketMQ，因此我在之前的基础上添加了对单机模式调度的封装。&lt;/p&gt;
&lt;p&gt;本文就单机模式下，不依赖RocketMQ如何使用shield-job进行定时任务调度展开讲解。&lt;/p&gt;
&lt;p&gt;目前有两种主要的调用方式，客户端实现抽象调度方法 &lt;strong&gt;execute&lt;/strong&gt; ，或者直接使用内置的 &lt;strong&gt;executeOneway&lt;/strong&gt; 方法进行调用，接下来分别介绍两种方式。&lt;/p&gt;
    
    </summary>
    
      <category term="自己写分布式组件系列" scheme="http://wuwenliang.net/categories/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E7%BB%84%E4%BB%B6%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="自己写分布式组件系列" scheme="http://wuwenliang.net/tags/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E7%BB%84%E4%BB%B6%E7%B3%BB%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>自己写分布式调度组件shield-job之使用shield-job</title>
    <link href="http://wuwenliang.net/2019/04/15/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E8%B0%83%E5%BA%A6%E7%BB%84%E4%BB%B6shield-job%E4%B9%8B%E4%BD%BF%E7%94%A8shield-job/"/>
    <id>http://wuwenliang.net/2019/04/15/自己写分布式调度组件shield-job之使用shield-job/</id>
    <published>2019-04-15T02:11:46.000Z</published>
    <updated>2019-04-16T08:19:01.758Z</updated>
    
    <content type="html"><![CDATA[<p>自己写分布式调度组件继续更新，目前已经完成了一个里程碑版本。</p>
<p>千呼万唤始出来，却不是当初想的模样。之前立的flag太大，最终决定暂时放弃开发分布式版本，把目标改为基于消息队列RocketMQ的任务分发框架，具体的调度逻辑由调用方自行开发。</p>
<h2 id="客户端接口"><a href="#客户端接口" class="headerlink" title="客户端接口"></a>客户端接口</h2><blockquote>
<p>首先介绍客户端需要关注的接口以及实体</p>
</blockquote>
<h3 id="客户端实体–任务实体BaseJob"><a href="#客户端实体–任务实体BaseJob" class="headerlink" title="客户端实体–任务实体BaseJob"></a>客户端实体–任务实体BaseJob</h3><p>任务实体BaseJob为shield-job的调度核心实体，调用方的业务实体需要继承该作业抽象类，实现其中的<strong>encode()</strong> 以及 <strong>decode(String msg)</strong> 抽象方法。</p>
<a id="more"></a>
<p>其中：</p>
<p>客户端需要在encode()方法中实现业务对象到String形式的消息体转换，如：</p>
<pre><code>@Override
public String encode() {
    // 组装消息协议头
    ImmutableMap.Builder headerBuilder = new ImmutableMap.Builder&lt;String, String&gt;()
            .put(&quot;version&quot;, this.getVersion())
            .put(&quot;jobTopic&quot;, this.getJobTopic())
            .put(&quot;jobTag&quot;, this.getJobTag())
            .put(&quot;jobBizDesc&quot;, &quot;测试订单协议&quot;)
            .put(&quot;jobProducerGroup&quot;, this.getJobProducerGroup())
            .put(&quot;jobConsumerGroup&quot;, this.getJobConsumerGroup())
            .put(&quot;jobTraceId&quot;, this.getJobTraceId());
    header = headerBuilder.build();

    body = new ImmutableMap.Builder&lt;String, String&gt;()
            .put(&quot;userId&quot;, this.getUserId())
            .put(&quot;userName&quot;, this.getUserName())
            .put(&quot;orderId&quot;, this.getOrderId())
            .build();

    ImmutableMap&lt;String, Object&gt; map = new ImmutableMap.Builder&lt;String, Object&gt;()
            .put(&quot;header&quot;, header)
            .put(&quot;body&quot;, body)
            .build();
    // 返回序列化消息Json串
    String ret_string = null;
    ObjectMapper objectMapper = new ObjectMapper();
    try {
        ret_string = objectMapper.writeValueAsString(map);
    } catch (JsonProcessingException e) {
        LOGGER.error(&quot;消息序列化json异常:&quot;, e);
    }
    return ret_string;
}
</code></pre><p>这里我使用了Guava的ImmutableMap作为消息协议的容器，使用jackson作为Json序列化工具。业务调用方必须将BaseJob的属性逐一填充，否则会在调度过程中抛出参数校验异常。</p>
<p>在decode(String msg)中实现String形式消息体到业务作业对象的转换，如：</p>
<pre><code>@Override
public void decode(String msg) {
    Preconditions.checkNotNull(msg);
    ObjectMapper mapper = new ObjectMapper();
    try {
        JsonNode root = mapper.readTree(msg);
        // header
        this.setVersion(root.get(&quot;header&quot;).get(&quot;version&quot;).asText());
        this.setJobTopic(root.get(&quot;header&quot;).get(&quot;jobTopic&quot;).asText());
        this.setJobTag(root.get(&quot;header&quot;).get(&quot;jobTag&quot;).asText());
        this.setJobBizDesc(root.get(&quot;header&quot;).get(&quot;jobBizDesc&quot;).asText());
        this.setJobProducerGroup(root.get(&quot;header&quot;).get(&quot;jobProducerGroup&quot;).asText());
        this.setJobConsumerGroup(root.get(&quot;header&quot;).get(&quot;jobConsumerGroup&quot;).asText());
        this.setJobTraceId(root.get(&quot;header&quot;).get(&quot;jobTraceId&quot;).asText());
        // body
        this.setUserName(root.get(&quot;body&quot;).get(&quot;userName&quot;).asText());
        this.setOrderId(root.get(&quot;body&quot;).get(&quot;orderId&quot;).asText());
        this.setUserId(root.get(&quot;body&quot;).get(&quot;userId&quot;).asText());
    } catch (IOException e) {
        LOGGER.error(&quot;反序列化消息异常:&quot;, e);
    }
}
</code></pre><p>这里我将入参消息实体转换为对象本身，通过this对内部的属性进行赋值，从而实现字符串形式的消息体到对象的转换。避免代码过长影响阅读，完整的代码在下文会放出。</p>
<h3 id="客户端接口-任务生产"><a href="#客户端接口-任务生产" class="headerlink" title="客户端接口-任务生产"></a>客户端接口-任务生产</h3><blockquote>
<p>这部分的内容为任务生产过程中需要调用的类及接口</p>
</blockquote>
<h4 id="JobProducerExecutor"><a href="#JobProducerExecutor" class="headerlink" title="JobProducerExecutor"></a>JobProducerExecutor</h4><blockquote>
<p>JobProducerExecutor是shield-job的任务生产调度核心，是final类，不允许被继承。</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">类名</th>
<th style="text-align:left">方法名</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">JobProducerExecutor</td>
<td style="text-align:left">JobProducerExecutor init(RocketMQProducerProperty rocketMQProducerProperty)</td>
<td style="text-align:left">初始化任务调度核心类</td>
</tr>
<tr>
<td style="text-align:left">JobProducerExecutor</td>
<td style="text-align:left">Result<jobsendresult> execute(final JobProducerListener jobProducerListener,Object arg)</jobsendresult></td>
<td style="text-align:left">执行Job生产逻辑，投递Job消息到MQ中。业务方需要实现JobProducerListener的任务生产回调方法</td>
</tr>
<tr>
<td style="text-align:left">JobProducerExecutor</td>
<td style="text-align:left">void start() throws MQClientException</td>
<td style="text-align:left">启动内置的RocketMQ消息生产者,开启任务投递</td>
</tr>
<tr>
<td style="text-align:left">JobProducerExecutor</td>
<td style="text-align:left">DefaultMQProducer getProducer()</td>
<td style="text-align:left">获取RocketMQ生产者引用</td>
</tr>
<tr>
<td style="text-align:left">RocketMQConsumerProperty</td>
<td style="text-align:left">构造方法</td>
<td style="text-align:left">构造RocketMQ生产者实例配置参数</td>
</tr>
</tbody>
</table>
<h4 id="JobProducerListener"><a href="#JobProducerListener" class="headerlink" title="JobProducerListener"></a>JobProducerListener</h4><blockquote>
<p>JobProducerListener是作业生产者接口，客户端的作业生产者需要实现该接口，传入需要进行任务调度的作业实体列表（参数泛型继承BaseJob）</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">类名</th>
<th style="text-align:left">方法名</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">JobProducerListener<t extends="" basejob=""></t></td>
<td style="text-align:left">List<t> produce(final Object arg)</t></td>
<td style="text-align:left">作业调度生产者返回待调度的业务实体协议列表，shield-job会回调该方法并将业务协议列表投递到MQ供作业消费者进行消费</td>
</tr>
</tbody>
</table>
<p>对于非BaseJob的子类，编译阶段即失败。</p>
<h3 id="客户端接口–任务消费"><a href="#客户端接口–任务消费" class="headerlink" title="客户端接口–任务消费"></a>客户端接口–任务消费</h3><blockquote>
<p>这部分为任务调度消费过程涉及到的类及接口</p>
</blockquote>
<h4 id="JobConsumerExecutor"><a href="#JobConsumerExecutor" class="headerlink" title="JobConsumerExecutor"></a>JobConsumerExecutor</h4><blockquote>
<p>JobConsumerExecutor是shield-job的任务消费调度核心，是final类，不允许被继承。</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">类名</th>
<th style="text-align:left">方法名</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">JobConsumerExecutor</td>
<td style="text-align:left">JobConsumerExecutor execute(RocketMQConsumerProperty rocketMQConsumerProperty,JobConsumerListenerAdapter jobConsumerListenerAdapter)</td>
<td style="text-align:left">初始化任务消费核心，执行任务消费调度过程</td>
</tr>
<tr>
<td style="text-align:left">JobConsumerExecutor</td>
<td style="text-align:left">void start() throws MQClientException</td>
<td style="text-align:left">启动内置的RocketMQ消息消费者，开启任务消费</td>
</tr>
<tr>
<td style="text-align:left">RocketMQProducerProperty</td>
<td style="text-align:left">构造方法</td>
<td style="text-align:left">构造RocketMQ消费者实例配置参数</td>
</tr>
</tbody>
</table>
<h4 id="JobConsumerListenerAdapter"><a href="#JobConsumerListenerAdapter" class="headerlink" title="JobConsumerListenerAdapter"></a>JobConsumerListenerAdapter</h4><blockquote>
<p>JobConsumerListenerAdapter是shield-job的任务消费监听适配器，通过调用不同的构造方法决定是否进行消费失败消息的重投递</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">类名</th>
<th style="text-align:left">方法名</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">JobConsumerListenerAdapter</td>
<td style="text-align:left">JobConsumerListenerAdapter(JobConsumerListener jobConsumerListener)</td>
<td style="text-align:left">任务消费适配器默认构造，只进行消费不进行消息重发</td>
</tr>
<tr>
<td style="text-align:left">JobConsumerListenerAdapter</td>
<td style="text-align:left">JobConsumerListenerAdapter(JobConsumerListener jobConsumerListener,JobScheduleExecutorConfig jobScheduleExecutorConfig)</td>
<td style="text-align:left">任务消费适配器带重发构造，既进行消费又进行消息重发</td>
</tr>
<tr>
<td style="text-align:left">JobConsumerListenerAdapter</td>
<td style="text-align:left">ConsumeConcurrentlyStatus consumeMessage(List<messageext> msgs,ConsumeConcurrentlyContext context)</messageext></td>
<td style="text-align:left">任务消费核心接口，客户端消费者调用该方法，shield-job根据构造传参自行决定是直接消费还是需要进行消息重发</td>
</tr>
</tbody>
</table>
<h4 id="JobConsumerListener"><a href="#JobConsumerListener" class="headerlink" title="JobConsumerListener"></a>JobConsumerListener</h4><blockquote>
<p>JobConsumerListener是任务消费监听器接口，消费者需要实现consumeMessage方法，完成消息的消费</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">类名</th>
<th style="text-align:left">方法名</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">JobConsumerListener</td>
<td style="text-align:left">ConsumeConcurrentlyStatus consumeMessage(final List<messageext> msgs, final ConsumeConcurrentlyContext context)</messageext></td>
<td style="text-align:left">消息消费，该方法为标准的RocektMQ消费接口</td>
</tr>
</tbody>
</table>
<h2 id="调用实例"><a href="#调用实例" class="headerlink" title="调用实例"></a>调用实例</h2><p>上述列出的类及其方法即shield-job任务调度的核心接口，直接看确实不直观，这里我用一个实例去讲解下如何在Spring Boot 2.1.2 Release中整合shield-job实现发布订阅模式的任务调度。</p>
<h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3><blockquote>
<p>项目结构如下</p>
</blockquote>
<p><img src="/2019/04/15/自己写分布式调度组件shield-job之使用shield-job/./structure.png" alt="shield-job-springboot-demo"></p>
<h3 id="引入shield-job核心依赖，配置RocketMQ"><a href="#引入shield-job核心依赖，配置RocketMQ" class="headerlink" title="引入shield-job核心依赖，配置RocketMQ"></a>引入shield-job核心依赖，配置RocketMQ</h3><p>首先引入shield-job核心的坐标，需要自行打包并安装到本地，有条件的可以运行 <strong>mvn clean deploy -DskipTests</strong> 直接发布到私服中。</p>
<p>坐标如下：</p>
<pre><code>&lt;dependency&gt;
    &lt;artifactId&gt;shield-job-scheduler-core&lt;/artifactId&gt;
    &lt;groupId&gt;com.snowalker.shield.job&lt;/groupId&gt;
    &lt;version&gt;1.0.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>由于shield-job核心通过RocketMQ作为任务队列，因此需要在调用方的配置文件中配置RocketMQ的NameServer地址，例如：</p>
<pre><code>########################################################################
#
#     RocketMQ配置
#
#########################################################################
rocketmq.nameServer=192.168.1.107:9876
</code></pre><h3 id="调度实例–任务生产者的开发"><a href="#调度实例–任务生产者的开发" class="headerlink" title="调度实例–任务生产者的开发"></a>调度实例–任务生产者的开发</h3><blockquote>
<p>首先进行业务层任务生产者的开发。</p>
</blockquote>
<p>定义一个名为OrderInfoJobProducer的类，并标记为Spring的bean</p>
<pre><code>@Component
public class OrderInfoJobProducer {

    private static final Logger LOGGER = LoggerFactory.getLogger(OrderInfoJobProducer.class);
</code></pre><p>定义任务发布的MQ的Topic、业务Tag（无tag可以不写）、生产者组、消费者组等参数</p>
<pre><code>/**
* 测试订单任务TOPIC
*/
private static final String TOPIC = &quot;SNOWALKER_TEST_SHIELD_JOB_TOPIC&quot;;
/**
* 测试订单任务TAG
*/
private static final String TAG = &quot;SNOWALKER_TEST_SHIELD_JOB_TAG&quot;;
/**
* 测试订单生产者组
*/
private static final String PRODUCER_GROUP = &quot;PID_SNOWALKER_TEST_SHIELD_JOB&quot;;
/**
* 测试订单消费者组
*/
private static final String CONSUMER_GROUP = &quot;CID_SNOWALKER_TEST_SHIELD_JOB&quot;;
</code></pre><p>读入配置文件中的RocketMQ的NameServer地址</p>
<pre><code>@Value(&quot;${rocketmq.nameServer}&quot;)
private String nameSrvAddr;
</code></pre><p>声明shield-job的任务生产者执行器JobProducerExecutor</p>
<pre><code>private JobProducerExecutor jobProducerExecutor;
</code></pre><p>通过@PostConstruct方式初始化JobProducerExecutor并开启运行内部的生产者</p>
<pre><code>@PostConstruct
public void init() throws MQClientException {
    // 实例化作业生产调度器
    jobProducerExecutor = new JobProducerExecutor()
            .init(new RocketMQProducerProperty(PRODUCER_GROUP,nameSrvAddr));
    jobProducerExecutor.getProducer().start();
}
</code></pre><p>核心调度逻辑，这里可以选用任意的调度框架，此处为spring-scheduler方式，通过 @Scheduled 注解声明此处为定时任务调度核心，并引入配置文件中的cron表达式，示例中的cron表达式为 <strong>0/3 <em> </em> <em> </em> ?</strong>  表示从0S开始，每次调度之间间隔三秒</p>
<pre><code>@Scheduled(cron = &quot;${order.resend.cron}&quot;)
public void execute() {
    try {
        // 传入JobProducerListener实现类，返回作业实体
        Result&lt;JobSendResult&gt; jobSendResult = jobProducerExecutor.execute(
</code></pre><p>此处通过匿名内部类的方式实现了JobProducerListener的回调方法 <strong>produce(Object arg)</strong> 将业务层拼装的业务订单调度协议（OrderInfoJobProcotol继承BaseJob）封装在 List<orderinfojobprocotol> 中，供JobProducerExecutor进行回调，提交任务至RocketMQ中。</orderinfojobprocotol></p>
<pre><code>(new JobProducerListener() {
    @Override
    public List produce(Object arg) {
        List&lt;OrderInfoJobProcotol&gt; jobs = new ArrayList&lt;&gt;(10);
        for (int i = 0; i &lt; 1; i++) {
            OrderInfoJobProcotol orderInfoJobProcotol = new OrderInfoJobProcotol();
            orderInfoJobProcotol.setOrderId(&quot;OD_&quot; + UUID.randomUUID().toString())
                    .setUserId(&quot;SNOWALKER_&quot; + UUID.randomUUID().toString())
                    .setUserName(&quot;SNOWALKER_&quot; + i)
                    .setJobTraceId(&quot;TRACE_&quot; + UUID.randomUUID().toString())
                    .setJobTopic(TOPIC)
                    .setJobTag(TAG)
                    .setJobProducerGroup(PRODUCER_GROUP)
                    .setJobConsumerGroup(CONSUMER_GROUP)
            ;
            jobs.add(orderInfoJobProcotol);
        }
        return jobs;
    }
}), null);
</code></pre><p>这里可以根据返回的 <strong>Result</strong> 对返回的任务提交实体进行更多的操作。JobSendResult中包含了每一次调度中提交成功的任务列表 <strong>sendSuccessJobList</strong> 以及 提交失败的任务列表 <strong>sendFailureJobList</strong>，业务层可以解析这两个列表，进行诸如重发、落库等更多的业务操作。</p>
<pre><code>        if (jobSendResult == null) {
            LOGGER.warn(&quot;执行作业分发失败,返回为空,topic={}&quot;, TOPIC);
        }
        if (jobSendResult.isSuccess()) {
            LOGGER.info(&quot;执行作业分发成功,jobSendResult={}&quot;, jobSendResult.toString());
        }
    } catch (Exception e) {
        LOGGER.error(&quot;执行作业分发异常&quot;, e);
    }
}
</code></pre><p>}</p>
<p>到此就完成了业务层的任务生产者的开发。</p>
<h3 id="调度实例–任务消费者的开发"><a href="#调度实例–任务消费者的开发" class="headerlink" title="调度实例–任务消费者的开发"></a>调度实例–任务消费者的开发</h3><blockquote>
<p>接着进行业务层任务消费者的开发。</p>
</blockquote>
<p>首先定义一个业务任务消费者类OrderInfoJobConsumer，标记为Spring的bean。</p>
<pre><code>@Component
public class OrderInfoJobConsumer {

    private static final Logger LOGGER = LoggerFactory.getLogger(OrderInfoJobConsumer.class);
</code></pre><p>声明需要进行订阅的topic、tag（默认为*）、消费者组</p>
<pre><code>/**测试订单任务TOPIC*/
private static final String TOPIC = &quot;SNOWALKER_TEST_SHIELD_JOB_TOPIC&quot;;
/**测试订单任务TAG*/
private static final String TAG = &quot;SNOWALKER_TEST_SHIELD_JOB_TAG&quot;;
/**测试订单生产者组*/
private static final String CONSUMER_GROUP = &quot;CID_SNOWALKER_TEST_SHIELD_JOB&quot;;
</code></pre><p>引入配置文件中配置的RocketMQ的nameServer地址</p>
<pre><code>@Value(&quot;${rocketmq.nameServer}&quot;)
private String nameSrvAddr;
</code></pre><p>如果需要在消费失败后，进行消息重发，那么需要引入RedisTemplate，不引入则表示不需要框架做消息重发，业务层自行处理消费失败的逻辑。</p>
<pre><code>@Autowired
RedisTemplate redisTemplate;
</code></pre><p>通过@PostConstruct方式启动任务消费者实例，并实现任务消费逻辑，此处为默认不需要框架进行消费失败后重发job消息的业务逻辑书写方式</p>
<p>@PostConstruct<br>    public void execute() throws Exception {</p>
<pre><code>    // 不需要重发
    new JobConsumerExecutor().execute(
            new RocketMQConsumerProperty(
                    TOPIC, CONSUMER_GROUP, nameSrvAddr, TAG),
                        new JobConsumerListenerAdapter(new JobConsumerListener() {
                            @Override
                            public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) {
                                try {
                                    String msgId = &quot;&quot;;
                                    String msgBody = &quot;&quot;;
                                    // 默认msgs只有一条消息
                                    for (MessageExt msg : msgs) {
                                        String message = new String(msg.getBody());
                                        OrderInfoJobProcotol protocol = new OrderInfoJobProcotol();
                                        protocol.decode(message);
                                        // 解析打印实体
                                        msgId = msg.getMsgId();
                                        msgBody = message;
                                    }
                                    LOGGER.info(&quot;模拟订单Job消息消费逻辑结束,状态--[RECONSUME_LATER]--msgId={}&quot;, msgId);

                                    return ConsumeConcurrentlyStatus.RECONSUME_LATER;
                                } catch (Exception e) {
                                    LOGGER.error(&quot;钱包扣款消费异常,e={}&quot;, e);
                                    return ConsumeConcurrentlyStatus.RECONSUME_LATER;
                                }
                            }
                        })).start();
}
</code></pre><p>可以看到，我们需要做的事情为：</p>
<ol>
<li>实例化一个任务消费执行器JobConsumerExecutor</li>
<li>调用execute方法，传入RocketMQConsumerProperty实例</li>
<li>execute的第二个参数为JobConsumerListenerAdapter实例，它接受一个参数JobConsumerListener，这里我们需要实现JobConsumerListener接口，并将具体的实现的引用传入JobConsumerListenerAdapter构造方法</li>
<li>实现consumeMessage方法，将消费状态ConsumeConcurrentlyStatus返回。shield-job会代理真实的RocketMQ的MessageListenerConcurrently接口，将消费状态返给RocketMQ，效果同直接使用RocketMQ的DefaultMQPushConsumer进行消费相同。</li>
</ol>
<p>如果我们使用JobConsumerListenerAdapter的另外一个构造方法，<strong>JobConsumerListenerAdapter(JobConsumerListener jobConsumerListener,JobScheduleExecutorConfig jobScheduleExecutorConfig)</strong> ，该构造方法表示需要对消费失败的消息进行消息重发，那么shield-job会对消费状态ConsumeConcurrentlyStatus进行解析，并对达到重试阈值且重发次数小于3的消息进行消息存储并开启异步线程进行重投递，具体代码如下：</p>
<pre><code>@PostConstruct
public void execute1() throws Exception {

    JobScheduleExecutorConfig jobScheduleExecutorConfig =
            new JobScheduleExecutorConfig(1,
                    nameSrvAddr,
                    new MessageStoreRedisTemplate(redisTemplate),
                    Executors.newScheduledThreadPool(10),
                    0,
                    3,
                    TimeUnit.SECONDS);

    // 需要消息重发
    new JobConsumerExecutor().execute(
            new RocketMQConsumerProperty(
                    TOPIC, CONSUMER_GROUP, nameSrvAddr, TAG),
            new JobConsumerListenerAdapter(new JobConsumerListener() {
                @Override
                public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) {
                    return getConsumeConcurrentlyStatus(msgs);
                }
            }, jobScheduleExecutorConfig)).start();
}
</code></pre><p>可以看到，我们需要构造并实例化任务重发配置JobScheduleExecutorConfig，并将其传入JobConsumerListenerAdapter的构造方法中。</p>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p>目前该功能还处于进一步测试阶段，因此建议还是使用 <strong>JobConsumerListenerAdapter(JobConsumerListener jobConsumerListener)</strong> 进行JobConsumerListenerAdapter的实例化。</p>
<h3 id="调用效果"><a href="#调用效果" class="headerlink" title="调用效果"></a>调用效果</h3><blockquote>
<p>到这里，我们就完成了业务模块对shield-job的整合及调度任务的开发，运行一下程序看一下执行效果。</p>
</blockquote>
<p>首先保证业务系统到RocektMQ的连通，执行启动方法，查看到日志如下：</p>
<pre><code>2019-04-15 14:16:11.188 [main] INFO  c.s.shield.job.consumer.JobConsumerExecutor [45]
- JobConsumerExecuter init successfully, topic=SNOWALKER_TEST_SHIELD_JOB_TOPIC, consumerGroup=CID_SNOWALKER_TEST_SHIELD_JOB
2019-04-15 14:16:13.794 [main] INFO  c.s.shield.job.producer.JobProducerExecutor [56] 
- JobProducerExecutor init successfully, jobProducerGroup=PID_SNOWALKER_TEST_SHIELD_JOB
......
2019-04-15 14:16:14.406 [main] INFO  com.snowalker.shield.jobdemo.App [59] 
- Started App in 6.482 seconds (JVM running for 7.747)
2019-04-15 14:16:14.407 [main] INFO  com.snowalker.shield.jobdemo.App [26] 
- shield-job-server启动完成......
2019-04-15 14:16:15.577 [scheduling-1] DEBUG c.s.shield.job.producer.JobProducerExecutor [100] 
- send job message successful, message sendStatus=SEND_OK, msgId=AC1E534751682437C6DC4B28F5D30000, queueOffset=142, transactionId=null, offsetMsgId=AC1E423300002A9F000000000059D06E, regionId=DefaultRegion, sendSuccessJobList.size()=0
2019-04-15 14:16:15.578 [scheduling-1] INFO  c.s.shield.job.producer.JobProducerExecutor [121] 
- send job messages finished, sendSuccessJobList messages size=1, sendFailureJobList messages size=0, topic=SNOWALKER_TEST_SHIELD_JOB_TOPIC, tag=SNOWALKER_TEST_SHIELD_JOB_TAG
2019-04-15 14:16:15.578 [scheduling-1] INFO  c.s.shield.jobdemo.producer.OrderInfoJobProducer [93] 
- 执行作业分发成功,jobSendResult=Result{code=200, message=&apos;SUCCESS&apos;, content=JobSendResult{sendSuccessJobList=[BaseJob{version=&apos;1.0&apos;, jobTopic=&apos;SNOWALKER_TEST_SHIELD_JOB_TOPIC&apos;, jobTag=&apos;SNOWALKER_TEST_SHIELD_JOB_TAG&apos;, jobBizDesc=&apos;null&apos;, jobProducerGroup=&apos;PID_SNOWALKER_TEST_SHIELD_JOB&apos;, jobConsumerGroup=&apos;CID_SNOWALKER_TEST_SHIELD_JOB&apos;, jobTraceId=&apos;TRACE_cbdb715e-173b-4adc-b0ed-1a1a1aea689c&apos;, jobMsgId=&apos;AC1E534751682437C6DC4B28F5D30000&apos;, params=null}], sendFailureJobList=[]}}
2019-04-15 14:16:16.454 [ConsumeMessageThread_8] INFO  c.s.shield.jobdemo.consumer.OrderInfoJobConsumer [100] 
- 模拟订单Job消息消费逻辑结束,状态--[RECONSUME_LATER]--msgId=AC1E534751682437C6DC4B28F5D30000
</code></pre><p>由于我们的调度生产者和消费者在同一个应用内，因此属于 <strong>“自产自销”</strong> 的模式，模拟的订单作业消息投递到MQ之后，下发至当前应用的消费者，被消费者处理。</p>
<p>返回RECONSUME_LATER是笔者为了测试重发，在实际业务中，当作业消费成功，直接返回 <strong>ConsumeConcurrentlyStatus.CONSUME_SUCCESS</strong> 即可。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>到此，我们就完成了使用shield-job实现业务上的任务调度逻辑的整合过程。代码地址为: <a href="https://github.com/TaXueWWL/shield-job" target="_blank" rel="external">shield-job</a>。</p>
<p>后续的文章中，我将对shield-job的实现方式抽丝剥茧，将我在开发过程中的感悟、思考以及一些编码技巧进行进一步的分享。</p>
<blockquote>
<p>昨夜西风凋碧树。独上高楼，望尽天涯路。</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;自己写分布式调度组件继续更新，目前已经完成了一个里程碑版本。&lt;/p&gt;
&lt;p&gt;千呼万唤始出来，却不是当初想的模样。之前立的flag太大，最终决定暂时放弃开发分布式版本，把目标改为基于消息队列RocketMQ的任务分发框架，具体的调度逻辑由调用方自行开发。&lt;/p&gt;
&lt;h2 id=&quot;客户端接口&quot;&gt;&lt;a href=&quot;#客户端接口&quot; class=&quot;headerlink&quot; title=&quot;客户端接口&quot;&gt;&lt;/a&gt;客户端接口&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;首先介绍客户端需要关注的接口以及实体&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;客户端实体–任务实体BaseJob&quot;&gt;&lt;a href=&quot;#客户端实体–任务实体BaseJob&quot; class=&quot;headerlink&quot; title=&quot;客户端实体–任务实体BaseJob&quot;&gt;&lt;/a&gt;客户端实体–任务实体BaseJob&lt;/h3&gt;&lt;p&gt;任务实体BaseJob为shield-job的调度核心实体，调用方的业务实体需要继承该作业抽象类，实现其中的&lt;strong&gt;encode()&lt;/strong&gt; 以及 &lt;strong&gt;decode(String msg)&lt;/strong&gt; 抽象方法。&lt;/p&gt;
    
    </summary>
    
      <category term="自己写分布式组件系列" scheme="http://wuwenliang.net/categories/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E7%BB%84%E4%BB%B6%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="自己写分布式组件系列" scheme="http://wuwenliang.net/tags/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E7%BB%84%E4%BB%B6%E7%B3%BB%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之消息幂等</title>
    <link href="http://wuwenliang.net/2019/03/28/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89/"/>
    <id>http://wuwenliang.net/2019/03/28/跟我学RocketMQ之消息幂等/</id>
    <published>2019-03-28T08:11:10.000Z</published>
    <updated>2019-04-03T02:58:51.420Z</updated>
    
    <content type="html"><![CDATA[<p>在上篇中，我们了解了RocketMQ中的消息重试机制以及如何在Producer、Consumer两端对重试消息进行处理。</p>
<p>RocketMQ会在消息消费时，按照一定规则推送消息到消费者端进行消息重试。这里涉及到了消息幂等的概念。</p>
<p>首先我们了解一下什么是幂等，以及何为消息幂等。</p>
<h2 id="什么是幂等"><a href="#什么是幂等" class="headerlink" title="什么是幂等"></a>什么是幂等</h2><p>百度对 “幂等” 解释如下</p>
<blockquote>
<p>设f为一由X映射至X的一元运算，则f为幂等的，当对于所有在X内的x，<br>f(f(x)) = f(x).<br>特别的是，恒等函数一定是幂等的，且任一常数函数也都是幂等的。</p>
</blockquote>
<p>这里的关键是 <strong>f(f(x)) = f(x)</strong>， 翻译成通俗的解释就是：</p>
<p>如果有一个操作，多次执行与一次执行所产生的影响是相同的，我们就称这个操作是幂等的。</p>
<h2 id="关于消息幂等"><a href="#关于消息幂等" class="headerlink" title="关于消息幂等"></a>关于消息幂等</h2><p>基于上述的概念，结合消息消费的场景，我们能够很容易的总结出消息幂等的概念：</p>
<p>即：</p>
<blockquote>
<p>如果消息重试多次，消费者端对该重复消息消费多次与消费一次的结果是相同的，并且多次消费没有对系统产生副作用，那么我们就称这个过程是消息幂等的。</p>
</blockquote>
<p>例如：</p>
<p>支付场景下，消费者消费扣款消息，对一笔订单进行扣款操作，该扣款操作需要扣除10元。</p>
<p>这个扣款操作重复多次与执行一次的效果相同，只进行一次真实扣款，用户的扣款记录中对应该笔订单的只有一条扣款流水。不会多扣。那么我们就说这个扣款操作是符合要求的，这个消费过程是消息幂等的。</p>
<a id="more"></a>
<h2 id="需要进行消息幂等的场景"><a href="#需要进行消息幂等的场景" class="headerlink" title="需要进行消息幂等的场景"></a>需要进行消息幂等的场景</h2><p>首先我们回顾一下需要进行消息幂等的场景，也就是上一篇文章提到的消息重复的场景。</p>
<ol>
<li><p>发送时重复：</p>
<p>生产者发送消息时，消息成功投递到broker，但此时发生网络闪断或者生产者down掉，导致broker发送ACK失败。此时生产者由于未能收到消息发送响应，认为发送失败，因此尝试重新发送消息到broker。当消息发送成功后，在broker中就会存在两条相同内容的消息，最终消费者会拉取到两条内容一样并且Message ID也相同的消息。因此造成了消息的重复。</p>
</li>
<li><p>消费时重复：</p>
<p>消费消息时同样会出现重复消费的情况。当消费者在处理业务完成返回消费状态给broker时，由于网络闪断等异常情况导致未能将消费完成的CONSUME_SUCCESS状态返回给broker。broker为了保证消息被至少消费一次的语义，会在网络环境恢复之后再次投递该条被处理的消息，最终造成消费者多次收到内容一样并且Message ID也相同的消息，造成了消息的重复。</p>
</li>
</ol>
<p>可以看到，无论是发送时重复还是消费时重复，最终的效果均为消费者消费时收到了重复的消息，那么我们就知道：只需要在消费者端统一进行幂等处理就能够实现消息幂等。</p>
<h2 id="实现消息幂等"><a href="#实现消息幂等" class="headerlink" title="实现消息幂等"></a>实现消息幂等</h2><p>那么如何才能实现消息幂等呢？</p>
<p>首先我们要定义消息幂等的两要素：</p>
<ol>
<li>幂等令牌</li>
<li>处理唯一性的确保</li>
</ol>
<p>我们必须保证存在幂等令牌的情况下保证业务处理结果的唯一性，才认为幂等实现是成功的。</p>
<p>接下来分别解释这两个要素</p>
<h3 id="幂等令牌"><a href="#幂等令牌" class="headerlink" title="幂等令牌"></a>幂等令牌</h3><p>幂等令牌是生产者和消费者两者中的既定协议，在业务中通常是具备唯一业务标识的字符串，如：订单号、流水号等。且一般由生产者端生成并传递给消费者端。</p>
<h3 id="处理唯一性的确保"><a href="#处理唯一性的确保" class="headerlink" title="处理唯一性的确保"></a>处理唯一性的确保</h3><p>即服务端应当采用一定的策略保证同一个业务逻辑一定不会重复执行成功多次。如：使用支付宝进行支付，买一个产品支付多次只会成功一笔。</p>
<p>较为常用的方式是采用缓存去重并且通过对业务标识添加数据库的唯一索引实现幂等。</p>
<p>具体的思路为：如支付场景下，支付的发起端生成了一个支付流水号，服务端处理该支付请求成功后，数据持久化成功。由于表中对支付流水添加了唯一索引，因此当重复支付时会因为唯一索引的存在报错 <strong>duplicate entry</strong>，服务端的业务逻辑捕获该异常并返回调用侧“重复支付”提示。这样就不会重复扣款。</p>
<p>在上面场景的基础上，我们还可以引入Redis等缓存组件实现去重：当支付请求打到服务端，首先去缓存进行判断，根据key=“支付流水号”去get存储的值，如果返回为空，表明是首次进行支付操作同时将当前的支付流水号作为key、value可以为任意字符串通过set(key,value,expireTime)存储在redis中。</p>
<p>当重复的支付请求到来时，尝试进行get(支付流水号)操作，这个操作会命中缓存，因此我们可以认为该请求是重复的支付请求，服务端业务将重复支付的业务提示返回给请求方。</p>
<p>由于我们一般都会在缓存使用过程中设置过期时间，缓存可能会失效从而导致请求穿透到持久化存储中（如：MySQL）。因此不能因为引入缓存而放弃使用唯一索引，将二者结合在一起是一个比较好的方案。</p>
<h3 id="RocketMQ场景下如何处理消息幂等"><a href="#RocketMQ场景下如何处理消息幂等" class="headerlink" title="RocketMQ场景下如何处理消息幂等"></a>RocketMQ场景下如何处理消息幂等</h3><p>了解了两个要素及典型案例之后，我们回到消息消费的场景。</p>
<p>作为一款高性能的消息中间件，RocketMQ能够保证消息不丢失但不保证消息不重复。如果在RocketMQ中实现消息去重实际也是可以的，但是考虑到高可用以及高性能的需求，如果做了服务端的消息去重，RocketMQ就需要对消息做额外的rehash、排序等操作，这会花费较大的时间和空间等资源代价，收益并不明显。RocketMQ考虑到正常情况下出现重复消息的概率其实是很小的，因此RocketMQ将消息幂等操作交给了业务方处理。</p>
<p>实际上上述问题的本质在于：网络调用本身存在不确定性，也就是既不成功也不失败的第三种状态，即所谓的 <strong>处理中</strong> 状态，因此会有重复的情况发生。这个问题是很多其他的MQ产品同样会遇到的，通常的方法就是要求消费方在消费消息时进行去重，也就是本文我们说的消费幂等性。</p>
<p>对RocketMQ有一定使用经验的读者可能注意到，每条消息都有一个MessageID，那么我们能否使用该ID作为去重依据，也就是上面提到的幂等令牌呢？</p>
<p>答案是否定的，因为MessageID可能出现冲突的情况，因此不建议通过MessageID作为处理依据而应当使用业务唯一标识如：订单号、流水号等作为幂等处理的关键依据。</p>
<p>上面也提到了，幂等依据应当由消息生产者生成，在发送消息时候，我们能够通过消息的key设置该id，对应的API为 <strong>org.apache.rocketmq.common.message.setKeys(String keys)</strong> 代码如下：</p>
<pre><code>Message sendMessage = new Message(
                MessageProtocolConst.WALLET_PAY_TOPIC.getTopic(),
                message.getBytes());

sendMessage.setKeys(&quot;OD0000000001&quot;);
</code></pre><p>当消息消费者收到该消息时，根据该消息的key做幂等处理，API为 <strong>org.apache.rocketmq.common.message.getKeys()</strong> 代码如下：</p>
<pre><code>(msgs, context) -&gt; {
    try {
        // 默认msgs只有一条消息
        for (MessageExt msg : msgs) {
            String key = msg.getKeys();
            return walletCharge(msg);
        }
        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
    } catch (Exception e) {
        LOGGER.error(&quot;钱包扣款消费异常,e={}&quot;, e);
        return ConsumeConcurrentlyStatus.RECONSUME_LATER;
    }
}
</code></pre><p>消费者通过getKeys()能够读取到生产者设置的幂等依据（如：订单号等），然后业务逻辑围绕该id进行幂等处理即可。</p>
<p>如果你觉得每次都需要在生产者侧setkey，在消费者侧getkey，有点繁琐。也可以将该幂等依据设置在消息协议中，消费者接收到消息后解析该id进行幂等操作也是可以的。只需要消息的生产者和消费者约定好如何解析id的协议即可。</p>
<p>具体的幂等逻辑视使用的场景而定，我在这里尝试从我的经验进行一些总结。</p>
<h3 id="消费端常见的幂等操作"><a href="#消费端常见的幂等操作" class="headerlink" title="消费端常见的幂等操作"></a>消费端常见的幂等操作</h3><ol>
<li><p>业务操作之前进行状态查询</p>
<p>消费端开始执行业务操作时，通过幂等id首先进行业务状态的查询，如：修改订单状态环节，当订单状态为成功/失败则不需要再进行处理。那么我们只需要在消费逻辑执行之前通过订单号进行订单状态查询，一旦获取到确定的订单状态则对消息进行提交，通知broker消息状态为：<strong>ConsumeConcurrentlyStatus.CONSUME_SUCCESS</strong> 。</p>
</li>
<li><p>业务操作前进行数据的检索</p>
<p>逻辑和第一点相似，即消费之前进行数据的检索，如果能够通过业务唯一id查询到对应的数据则不需要进行再后续的业务逻辑。如：下单环节中，在消费者执行异步下单之前首先通过订单号查询订单是否已经存在，这里可以查库也可以查缓存。如果存在则直接返回消费成功，否则进行下单操作。</p>
</li>
<li><p>唯一性约束保证最后一道防线</p>
<p> 上述第二点操作并不能保证一定不出现重复的数据，如：并发插入的场景下，如果没有乐观锁、分布式锁作为保证的前提下，很有可能出现数据的重复插入操作，因此我们务必要对幂等id添加唯一性索引，这样就能够保证在并发场景下也能保证数据的唯一性。</p>
</li>
<li><p>引入锁机制</p>
<p> 上述的第一点中，如果是并发更新的情况，没有使用悲观锁、乐观锁、分布式锁等机制的前提下，进行更新，很可能会出现多次更新导致状态的不准确。如：对订单状态的更新，业务要求订单只能从初始化-&gt;处理中，处理中-&gt;成功，处理中-&gt;失败，不允许跨状态更新。如果没有锁机制，很可能会将初始化的订单更新为成功，成功订单更新为失败等异常的情况。<br> 高并发下，建议通过状态机的方式定义好业务状态的变迁，通过乐观锁、分布式锁机制保证多次更新的结果是确定的，悲观锁在并发环境不利于业务吞吐量的提高因此不建议使用。</p>
</li>
<li><p>消息记录表</p>
<p> 这种方案和业务层做的幂等操作类似，由于我们的消息id是唯一的，可以借助该id进行消息的去重操作，间接实现消费的幂等。<br> 首先准备一个消息记录表，在消费成功的同时插入一条已经处理成功的消息id记录到该表中，注意一定要 <strong>与业务操作处于同一个事物</strong> 中，当新的消息到达的时候，根据新消息的id在该表中查询是否已经存在该id，如果存在则表明消息已经被消费过，那么丢弃该消息不再进行业务操作即可。<br>…..</p>
</li>
</ol>
<p>肯定还有更多的场景我没有涉及到，这里说到的操作均是互相之间有关联的，将他们配合使用更能够保证消费业务的幂等性。</p>
<p>不论怎样，请牢记一个原则：<strong>缓存是不可靠的，查询是不可靠的</strong> 。</p>
<p>在高并发的场景下，一定要通过持久化存储的唯一索引以及引入锁机制作为共同保障数据准确性和完整性的最后一道防线！</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要讲解了何为幂等及消息消费场景下如何传递唯一幂等id，并进一步分析了如何保证消息幂等的思路以及总结了常见的消息幂等处理方式。</p>
<p>套路是多变的，关键是掌握思路和方法，我们的原则就是 <strong>不管执行多少次，业务表现出来的行为是统一的</strong> ， 在这个前提下，我们引入了操作前查库、操作前查缓存、乐观锁/分布式锁机制、加入唯一索引等多重防重放策略，通过这些策略的综合作用，最终达到了消息幂等的目的。</p>
<p>最后有句话分享，有道无术术可求。有术无道止于术。相信聪明的你一定会在技术的道路上结合实际场景将各种技术手段融会贯通，从而走的越来越远。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上篇中，我们了解了RocketMQ中的消息重试机制以及如何在Producer、Consumer两端对重试消息进行处理。&lt;/p&gt;
&lt;p&gt;RocketMQ会在消息消费时，按照一定规则推送消息到消费者端进行消息重试。这里涉及到了消息幂等的概念。&lt;/p&gt;
&lt;p&gt;首先我们了解一下什么是幂等，以及何为消息幂等。&lt;/p&gt;
&lt;h2 id=&quot;什么是幂等&quot;&gt;&lt;a href=&quot;#什么是幂等&quot; class=&quot;headerlink&quot; title=&quot;什么是幂等&quot;&gt;&lt;/a&gt;什么是幂等&lt;/h2&gt;&lt;p&gt;百度对 “幂等” 解释如下&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;设f为一由X映射至X的一元运算，则f为幂等的，当对于所有在X内的x，&lt;br&gt;f(f(x)) = f(x).&lt;br&gt;特别的是，恒等函数一定是幂等的，且任一常数函数也都是幂等的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这里的关键是 &lt;strong&gt;f(f(x)) = f(x)&lt;/strong&gt;， 翻译成通俗的解释就是：&lt;/p&gt;
&lt;p&gt;如果有一个操作，多次执行与一次执行所产生的影响是相同的，我们就称这个操作是幂等的。&lt;/p&gt;
&lt;h2 id=&quot;关于消息幂等&quot;&gt;&lt;a href=&quot;#关于消息幂等&quot; class=&quot;headerlink&quot; title=&quot;关于消息幂等&quot;&gt;&lt;/a&gt;关于消息幂等&lt;/h2&gt;&lt;p&gt;基于上述的概念，结合消息消费的场景，我们能够很容易的总结出消息幂等的概念：&lt;/p&gt;
&lt;p&gt;即：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果消息重试多次，消费者端对该重复消息消费多次与消费一次的结果是相同的，并且多次消费没有对系统产生副作用，那么我们就称这个过程是消息幂等的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;p&gt;支付场景下，消费者消费扣款消息，对一笔订单进行扣款操作，该扣款操作需要扣除10元。&lt;/p&gt;
&lt;p&gt;这个扣款操作重复多次与执行一次的效果相同，只进行一次真实扣款，用户的扣款记录中对应该笔订单的只有一条扣款流水。不会多扣。那么我们就说这个扣款操作是符合要求的，这个消费过程是消息幂等的。&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之消息重试</title>
    <link href="http://wuwenliang.net/2019/03/28/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E9%87%8D%E8%AF%95/"/>
    <id>http://wuwenliang.net/2019/03/28/跟我学RocketMQ之消息重试/</id>
    <published>2019-03-28T01:35:10.000Z</published>
    <updated>2019-03-28T08:07:24.492Z</updated>
    
    <content type="html"><![CDATA[<p>本文中，我将讲解RocketMQ使用过程中，如何进行消息重试。</p>
<p>首先，我们需要明确，只有当消费模式为 <strong>MessageModel.CLUSTERING(集群模式)</strong> 时，Broker才会自动进行重试，对于广播消息是不会重试的。</p>
<p>集群消费模式下，当消息消费失败，RocketMQ会通过消息重试机制重新投递消息，努力使该消息消费成功。</p>
<p>当消费者消费该重试消息后，需要返回结果给broker，告知broker消费成功（ConsumeConcurrentlyStatus.CONSUME_SUCCESS）或者需要重新消费（ConsumeConcurrentlyStatus.RECONSUME_LATER）。</p>
<p>这里有个问题，如果消费者业务本身故障导致某条消息一直无法消费成功，难道要一直重试下去吗？</p>
<p>答案是显而易见的，并不会一直重试。</p>
<p>事实上，对于一直无法消费成功的消息，RocketMQ会在达到最大重试次数之后，将该消息投递至死信队列。然后我们需要关注死信队列，并对该死信消息业务做人工的补偿操作。</p>
<a id="more"></a>
<blockquote>
<p>那如何返回消息消费失败呢？</p>
</blockquote>
<p>RocketMQ规定，以下三种情况统一按照消费失败处理并会发起重试。</p>
<ol>
<li>业务消费方返回ConsumeConcurrentlyStatus.RECONSUME_LATER</li>
<li>业务消费方返回null</li>
<li>业务消费方主动/被动抛出异常</li>
</ol>
<p>前两种情况较容易理解，当返回ConsumeConcurrentlyStatus.RECONSUME_LATER或者null时，broker会知道消费失败，后续就会发起消息重试，重新投递该消息。</p>
<p><strong>注意</strong>  对于抛出异常的情况，只要我们在业务逻辑中显式抛出异常或者非显式抛出异常，broker也会重新投递消息，如果业务对异常做了捕获，那么该消息将不会发起重试。因此对于需要重试的业务，消费方在捕获异常的时候要注意返回ConsumeConcurrentlyStatus.RECONSUME_LATER或null并输出异常日志，打印当前重试次数。（推荐返回<strong>ConsumeConcurrentlyStatus.RECONSUME_LATER</strong>）</p>
<h3 id="RocketMQ重试时间窗"><a href="#RocketMQ重试时间窗" class="headerlink" title="RocketMQ重试时间窗"></a>RocketMQ重试时间窗</h3><p>这里介绍一下Apache RocketMQ的重试时间窗，当消息需要重试时，会按照该规则进行重试。</p>
<p>我们可以在RocketMQ的broker.conf配置文件中配置Consumer侧重试次数及时间间隔, 配置如下</p>
<pre><code>messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h
</code></pre><p>次数与重试时间间隔对应关系表如下：</p>
<table>
<thead>
<tr>
<th style="text-align:left">重试次数</th>
<th style="text-align:left">距离第一次发送的时间间隔</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left">1s</td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:left">5s</td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td style="text-align:left">10s</td>
</tr>
<tr>
<td style="text-align:left">4</td>
<td style="text-align:left">30s</td>
</tr>
<tr>
<td style="text-align:left">5</td>
<td style="text-align:left">1m</td>
</tr>
<tr>
<td style="text-align:left">6</td>
<td style="text-align:left">2m</td>
</tr>
<tr>
<td style="text-align:left">7</td>
<td style="text-align:left">3m</td>
</tr>
<tr>
<td style="text-align:left">8</td>
<td style="text-align:left">4m</td>
</tr>
<tr>
<td style="text-align:left">9</td>
<td style="text-align:left">5m</td>
</tr>
<tr>
<td style="text-align:left">10</td>
<td style="text-align:left">6m</td>
</tr>
<tr>
<td style="text-align:left">11</td>
<td style="text-align:left">7m</td>
</tr>
<tr>
<td style="text-align:left">12</td>
<td style="text-align:left">8m</td>
</tr>
<tr>
<td style="text-align:left">13</td>
<td style="text-align:left">9m</td>
</tr>
<tr>
<td style="text-align:left">14</td>
<td style="text-align:left">10m</td>
</tr>
<tr>
<td style="text-align:left">15</td>
<td style="text-align:left">20m</td>
</tr>
<tr>
<td style="text-align:left">16</td>
<td style="text-align:left">30m</td>
</tr>
<tr>
<td style="text-align:left">17</td>
<td style="text-align:left">1h</td>
</tr>
<tr>
<td style="text-align:left">18</td>
<td style="text-align:left">2h</td>
</tr>
</tbody>
</table>
<p>可以看到，RocketMQ采用了“时间衰减策略”进行消息的重复投递，即重试次数越多，消息消费成功的可能性越小。</p>
<p>默认的处理机制中，如果我们只对消息做重复消费，达到最大重试次数之后消息就进入死信队列了。</p>
<h3 id="死信的业务处理方式"><a href="#死信的业务处理方式" class="headerlink" title="死信的业务处理方式"></a>死信的业务处理方式</h3><p>我们也可以根据业务的需要，定义消费的最大重试次数，每次消费的时候判断当前消费次数是否等于最大重试次数的阈值。</p>
<p>如：重试三次就认为当前业务存在异常，继续重试下去也没有意义了，那么我们就可以将当前的这条消息进行提交，返回broker状态<strong>ConsumeConcurrentlyStatus.CONSUME_SUCCES</strong>，让消息不再重发，同时将该消息存入我们业务自定义的死信消息表，将业务参数入库，相关的运营通过查询死信表来进行对应的业务补偿操作。</p>
<h3 id="发送失败如何重试"><a href="#发送失败如何重试" class="headerlink" title="发送失败如何重试"></a>发送失败如何重试</h3><p>上文中，我们讲解了对于消费失败的重试策略，这个章节中我们来了解下消息发送失败如何进行重试。</p>
<p>当发生网络抖动等异常情况，Producer生产者侧往broker发送消息失败，即：生产者侧没收到broker返回的ACK，导致Consumer无法进行消息消费，这时RocketMQ会进行发送重试。</p>
<p>使用DefaultMQProducer进行普通消息发送时，我们可以设置消息发送失败后最大重试次数，并且能够灵活的配合超时时间进行业务重试逻辑的开发，使用的API如下：</p>
<pre><code>/**设置消息发送失败时最大重试次数*/
public void setRetryTimesWhenSendFailed(int retryTimesWhenSendFailed) {
    this.retryTimesWhenSendFailed = retryTimesWhenSendFailed;
}

/**同步发送消息，并指定超时时间*/
public SendResult send(Message msg,
                    long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    return this.defaultMQProducerImpl.send(msg, timeout);
}
</code></pre><p>通过API可以看出，生产者侧的重试是比较简单的，例如：设置生产者在3s内没有发送成功则重试3次的代码如下：</p>
<pre><code>/**同步发送消息，如果3秒内没有发送成功，则重试3次*/
DefaultMQProducer producer = new DefaultMQProducer(&quot;DefaultProducerGroup&quot;);
producer.setRetryTimesWhenSendFailed(3);
producer.send(msg, 3000L);
</code></pre><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文中，我们主要介绍了RocketMQ的消息重试机制，该机制能够最大限度的保证业务能够往我们期望的方向流转。</p>
<p>这里还需要注意，业务重试的时候我们的消息消费端需要保证消费的 <strong>幂等性</strong>， 关于消息消费的幂等如何处理，我们在后续的文章会展开讲解。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文中，我将讲解RocketMQ使用过程中，如何进行消息重试。&lt;/p&gt;
&lt;p&gt;首先，我们需要明确，只有当消费模式为 &lt;strong&gt;MessageModel.CLUSTERING(集群模式)&lt;/strong&gt; 时，Broker才会自动进行重试，对于广播消息是不会重试的。&lt;/p&gt;
&lt;p&gt;集群消费模式下，当消息消费失败，RocketMQ会通过消息重试机制重新投递消息，努力使该消息消费成功。&lt;/p&gt;
&lt;p&gt;当消费者消费该重试消息后，需要返回结果给broker，告知broker消费成功（ConsumeConcurrentlyStatus.CONSUME_SUCCESS）或者需要重新消费（ConsumeConcurrentlyStatus.RECONSUME_LATER）。&lt;/p&gt;
&lt;p&gt;这里有个问题，如果消费者业务本身故障导致某条消息一直无法消费成功，难道要一直重试下去吗？&lt;/p&gt;
&lt;p&gt;答案是显而易见的，并不会一直重试。&lt;/p&gt;
&lt;p&gt;事实上，对于一直无法消费成功的消息，RocketMQ会在达到最大重试次数之后，将该消息投递至死信队列。然后我们需要关注死信队列，并对该死信消息业务做人工的补偿操作。&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>跟我学shardingjdbc之自定义分库分表策略-复合分片算法自定义实现</title>
    <link href="http://wuwenliang.net/2019/03/26/%E8%B7%9F%E6%88%91%E5%AD%A6shardingjdbc%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E7%AD%96%E7%95%A5-%E5%A4%8D%E5%90%88%E5%88%86%E7%89%87%E7%AE%97%E6%B3%95%E8%87%AA%E5%AE%9A%E4%B9%89%E5%AE%9E%E7%8E%B0/"/>
    <id>http://wuwenliang.net/2019/03/26/跟我学shardingjdbc之自定义分库分表策略-复合分片算法自定义实现/</id>
    <published>2019-03-26T07:51:16.000Z</published>
    <updated>2019-03-26T16:41:30.109Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文是 “跟我学Sharding-JDBC” 系列的第四篇，我将带领读者一起了解下Sharding-JDBC的数据分片规则并通过实例实现自定义分片策略的开发实现。</p>
</blockquote>
<p>Sharding-JDBC中的分片策略有两个维度，分别是：数据源分片策略（DatabaseShardingStrategy）、表分片策略（TableShardingStrategy）。</p>
<p>其中，数据源分片策略表示：数据路由到的物理目标数据源，表分片策略表示数据被路由到的目标表。</p>
<p>特别的，表分片策略是依赖于数据源分片策略的，也就是说要先分库再分表。</p>
<p>这里贴一张盗来的图</p>
<p><img src="/2019/03/26/跟我学shardingjdbc之自定义分库分表策略-复合分片算法自定义实现/./sharding.png" alt="Sharding-JDBC分片策略代码架构"></p>
<a id="more"></a>
<h2 id="了解Sharding-JDBC的数据分片策略"><a href="#了解Sharding-JDBC的数据分片策略" class="headerlink" title="了解Sharding-JDBC的数据分片策略"></a>了解Sharding-JDBC的数据分片策略</h2><p>Sharding-JDBC的分片策略包含了分片键和分片算法。由于分片算法与业务实现紧密相关，因此Sharding-JDBC没有提供内置的分片算法，而是通过分片策略将各种场景提炼出来，提供了高层级的抽象，通过提供接口让开发者自行实现分片算法。</p>
<p>以下内容引用自官方文档。<a href="https://shardingsphere.apache.org/document/legacy/3.x/document/cn/features/sharding/concept/sharding/" target="_blank" rel="external">官方文档</a></p>
<p>首先介绍四种分片算法。</p>
<blockquote>
<p>通过分片算法将数据分片，支持通过=、BETWEEN和IN分片。<br>分片算法需要应用方开发者自行实现，可实现的灵活度非常高。</p>
<p>目前提供4种分片算法。由于分片算法和业务实现紧密相关，<br>因此并未提供内置分片算法，而是通过分片策略将各种场景提炼出来，<br>提供更高层级的抽象，并提供接口让应用开发者自行实现分片算法。</p>
</blockquote>
<h3 id="精确分片算法–PreciseShardingAlgorithm"><a href="#精确分片算法–PreciseShardingAlgorithm" class="headerlink" title="精确分片算法–PreciseShardingAlgorithm"></a>精确分片算法–PreciseShardingAlgorithm</h3><p>用于处理使用单一键作为分片键的=与IN进行分片的场景。需要配合StandardShardingStrategy使用。</p>
<h3 id="范围分片算法–RangeShardingAlgorithm"><a href="#范围分片算法–RangeShardingAlgorithm" class="headerlink" title="范围分片算法–RangeShardingAlgorithm"></a>范围分片算法–RangeShardingAlgorithm</h3><p>用于处理使用单一键作为分片键的BETWEEN AND进行分片的场景。需要配合StandardShardingStrategy使用。</p>
<h3 id="复合分片算法–ComplexKeysShardingAlgorithm"><a href="#复合分片算法–ComplexKeysShardingAlgorithm" class="headerlink" title="复合分片算法–ComplexKeysShardingAlgorithm"></a>复合分片算法–ComplexKeysShardingAlgorithm</h3><p>用于处理使用多键作为分片键进行分片的场景，包含多个分片键的逻辑较复杂，需要应用开发者自行处理其中的复杂度。需要配合ComplexShardingStrategy使用。</p>
<p><strong>注</strong> ： 我们在业务开发中，经常有根据用户id 查询某用户的记录列表，又有根据某个业务主键查询该用户的某记录的需求，这就需要用到复合分片算法。比如，订单表中，我们既需要查询某个userId的某时间段内的订单列表数据，又需要根据orderId查询某条订单数据。这里，orderId与userId就属于复合分片键。</p>
<h3 id="Hint分片算法–HintShardingAlgorithm"><a href="#Hint分片算法–HintShardingAlgorithm" class="headerlink" title="Hint分片算法–HintShardingAlgorithm"></a>Hint分片算法–HintShardingAlgorithm</h3><p>Hint分片指的是对于分片字段非SQL决定，而由其他外置条件决定的场景，可以通过使用SQL Hint灵活注入分片字段。</p>
<p>Hint分片策略是绕过SQL解析的，因此能够通过实现该算法来实现Sharding-JDBC不支持的语法限制。</p>
<p>用于处理使用Hint行分片的场景。需要配合HintShardingStrategy使用。</p>
<blockquote>
<p>接着介绍下五种分片策略。</p>
</blockquote>
<h3 id="标准分片策略–StandardShardingStrategy"><a href="#标准分片策略–StandardShardingStrategy" class="headerlink" title="标准分片策略–StandardShardingStrategy"></a>标准分片策略–StandardShardingStrategy</h3><p>提供对SQL语句中的=, IN和BETWEEN AND的分片操作支持。StandardShardingStrategy只支持单分片键，提供PreciseShardingAlgorithm和RangeShardingAlgorithm两个分片算法。PreciseShardingAlgorithm是必选的，用于处理=和IN的分片。RangeShardingAlgorithm是可选的，用于处理BETWEEN AND分片，如果不配置RangeShardingAlgorithm，SQL中的BETWEEN AND将按照全库路由处理。</p>
<h3 id="复合分片策略–ComplexShardingStrategy"><a href="#复合分片策略–ComplexShardingStrategy" class="headerlink" title="复合分片策略–ComplexShardingStrategy"></a>复合分片策略–ComplexShardingStrategy</h3><p>提供对SQL语句中的=, IN和BETWEEN AND的分片操作支持。ComplexShardingStrategy支持多分片键，由于多分片键之间的关系复杂，因此并未进行过多的封装，而是直接将分片键值组合以及分片操作符透传至分片算法，完全由应用开发者实现，提供最大的灵活度。</p>
<p>这里体现出框架设计者对设计原则的透彻理解，将变更点暴露给用户，将不变的封装在内部，明确的划分了抽象和实现的界限，这是值得我们学习的。</p>
<h3 id="行表达式分片策略–InlineShardingStrategy"><a href="#行表达式分片策略–InlineShardingStrategy" class="headerlink" title="行表达式分片策略–InlineShardingStrategy"></a>行表达式分片策略–InlineShardingStrategy</h3><p>使用Groovy的表达式，提供对SQL语句中的=和IN的分片操作支持，只支持单分片键。对于简单的分片算法，可以通过简单的配置使用，从而避免繁琐的Java代码开发，如: t<em>user</em>$-&gt;{u_id % 8} 表示t_user表根据u_id模8，而分成8张表，表名称为t_user_0到t_user_7。</p>
<p>上一篇文章中，我就是使用这个方式进行了demo的开发和讲解，对于快速体验Sharding-JDBC的魅力是很有意义的，但是这种方式对于复杂的业务支持程度就差一些，因此实际的业务开发中还是推荐使用复合分片策略–ComplexShardingStrategy。</p>
<h3 id="Hint分片策略–HintShardingStrategy"><a href="#Hint分片策略–HintShardingStrategy" class="headerlink" title="Hint分片策略–HintShardingStrategy"></a>Hint分片策略–HintShardingStrategy</h3><p>通过Hint而非SQL解析的方式分片的策略。</p>
<h3 id="不分片策略–NoneShardingStrategy"><a href="#不分片策略–NoneShardingStrategy" class="headerlink" title="不分片策略–NoneShardingStrategy"></a>不分片策略–NoneShardingStrategy</h3><p>该策略为不分片的策略。</p>
<h2 id="实战–自定义复合分片策略"><a href="#实战–自定义复合分片策略" class="headerlink" title="实战–自定义复合分片策略"></a>实战–自定义复合分片策略</h2><p>由于目的为贴近实战，因此着重讲解如何实现复杂分片策略，即实现ComplexShardingStrategy接口定制生产可用的分片策略。</p>
<h3 id="场景回顾"><a href="#场景回顾" class="headerlink" title="场景回顾"></a>场景回顾</h3><p>首先回顾一下业务场景，我们对订单进行分库分表，分为4库8表，复合分片键为user_id及order_id。</p>
<p>对用户进行分库分表，分为4库16表，分片键为user_id。</p>
<p>对订单表进行分库分表，分为4库8表，分片键为order_id，查询条件为user_id、order_id。</p>
<blockquote>
<p>我们的业务流程如下：</p>
</blockquote>
<ol>
<li>根据一个外部路由id(如：支付宝uid、微信openId等)生成系统内部的用户user_id</li>
<li>根据系统内部user_id生成业务id，如：order_id、account_id等</li>
<li>根据外部id查询，获得系统内部user_id</li>
<li>根据系统内部user_id查询用户的所有订单信息</li>
<li>根据订单号order_id查询单条订单明细数据</li>
</ol>
<p>在上篇文章 <a href="http://wuwenliang.net/2019/03/25/%E8%B7%9F%E6%88%91%E5%AD%A6shardingjdbc%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%BB%E9%94%AE%E5%8F%8A%E5%85%B6%E8%87%AA%E5%AE%9A%E4%B9%89/">跟我学shardingjdbc之分布式主键及其自定义</a> 中，我们完成了自定义分布式主键的生成，本节中，我将基于该分布式主键生成规则，配合Sharding-JDBC的复合分片策略接口，开发符合上述业务流程的复合分片规则，该规则已经在我们线上稳定运行，读者朋友可以借鉴并运用到自己的生产环境。</p>
<h3 id="开发自定义复合分库策略"><a href="#开发自定义复合分库策略" class="headerlink" title="开发自定义复合分库策略"></a>开发自定义复合分库策略</h3><blockquote>
<p>我们需要开发复合分库、分表两个策略，首先开发分库策略。</p>
</blockquote>
<p>定义自定义复合分库策略实现类：SnoWalkerComplexShardingDB.java，实现 <strong>ComplexKeysShardingAlgorithm</strong>  接口。需要重写其 <strong>doSharding(Collection availableTargetNames, Collection shardingValues)</strong> 方法。</p>
<blockquote>
<p> <strong>doSharding(Collection availableTargetNames, Collection shardingValues)</strong>  方法返回值为：物理数据源、物理表分片结果，如：ds0, t_user_0000，Sharding-JDBC会将数据路由至物理分片。</p>
</blockquote>
<h4 id="核心逻辑"><a href="#核心逻辑" class="headerlink" title="核心逻辑"></a>核心逻辑</h4><blockquote>
<p>这里是方法的关键逻辑</p>
</blockquote>
<pre><code>/**
 * @param availableTargetNames 可用数据源集合
 * @param shardingValues   分片键
 * @return sharding results for data sources or tables&apos;s names
 */
@Override
public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; availableTargetNames, Collection&lt;ShardingValue&gt; shardingValues) {

    // 0. 打印数据源集合 及 分片键属性集合
    log.info(&quot;availableTargetNames:&quot; + JSON.toJSONString(availableTargetNames) + &quot;,shardingValues:&quot; + JSON.toJSONString(shardingValues));
    // availableTargetNames:[&quot;ds0&quot;,&quot;ds1&quot;,&quot;ds2&quot;,&quot;ds3&quot;],
    // shardingValues:[{&quot;columnName&quot;:&quot;user_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;UD020003011903261545436593200002&quot;]},
    //                {&quot;columnName&quot;:&quot;order_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;OD000000011903261545475143200001&quot;]}]
    List&lt;String&gt; shardingResults = new ArrayList&lt;&gt;();

    // 1. 遍历分片键集合，匹配数据源
    for (ShardingValue var : shardingValues) {

        ListShardingValue&lt;String&gt; listShardingValue = (ListShardingValue&lt;String&gt;)var;
        List&lt;String&gt; shardingValue = (List&lt;String&gt;)listShardingValue.getValues();

        // shardingValue:[&quot;UD020003011903261545436593200002&quot;]
        log.info(&quot;shardingValue:&quot; + JSON.toJSONString(shardingValue));

        // 2. 获取数据源索引值
        String index = getIndex(listShardingValue.getLogicTableName(),
                                listShardingValue.getColumnName(),
                                shardingValue.get(0));

        // 3. 循环匹配数据源，匹配到则退出循环
        for (String name : availableTargetNames) {
            // 4. 获取逻辑数据源索引后缀，即 0，1，2，3
            String nameSuffix = name.substring(ShardingConstant.LOGIC_DB_PREFIX_LENGTH);
            // 5. 当且仅当availableTargetNames中的数据源索引与路由值对应的分片索引相同退出循环
            if (nameSuffix.equals(index)) {
                // 6. 添加到分片结果集合
                shardingResults.add(name);
                break;
            }
        }

        //匹配到一种路由规则就可以退出
        if (shardingResults.size() &gt; 0) {
            break;
        }
    }

    return shardingResults;
}
</code></pre><h4 id="核心逻辑解析"><a href="#核心逻辑解析" class="headerlink" title="核心逻辑解析"></a>核心逻辑解析</h4><blockquote>
<p>梳理一下逻辑，首先介绍一下该方法的入参</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">参数名</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">availableTargetNames</td>
<td style="text-align:left">有效的物理数据源，即配置文件中的 ds0,ds1,ds2,ds3</td>
</tr>
<tr>
<td style="text-align:left">shardingValues</td>
<td style="text-align:left">分片属性，如：{“columnName”:”user_id”,”logicTableName”:”t_new_order”,”values”:[“UD020003011903261545436593200002”]} ，包含：分片列名，逻辑表名，当前列的具体分片值</td>
</tr>
</tbody>
</table>
<p>该方法返回值为 </p>
<table>
<thead>
<tr>
<th style="text-align:left">参数名</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Collection＜String＞</td>
<td style="text-align:left">分片结果，可以是目标数据源，也可以是目标数据表，此处为数据源</td>
</tr>
</tbody>
</table>
<p>接着回来看业务逻辑，伪代码如下</p>
<ol>
<li><p>首先打印了一下数据源集合 availableTargetNames 以及 分片属性 shardingValues的值，执行测试用例后，日志输出为：</p>
<pre><code>availableTargetNames:[&quot;ds0&quot;,&quot;ds1&quot;,&quot;ds2&quot;,&quot;ds3&quot;],
shardingValues:[{&quot;columnName&quot;:&quot;user_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;UD020003011903261545436593200002&quot;]},
                {&quot;columnName&quot;:&quot;order_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;OD000000011903261545475143200001&quot;]}]
</code></pre></li>
</ol>
<blockquote>
<p>从日志可以看出，我们可以在该路由方法中取到配置时的物理数据源列表，以及在运行时获取本次执行时的路由属性及其值</p>
</blockquote>
<p>完整的逻辑流程如下：</p>
<ol>
<li>定义一个集合用于放置最终匹配好的路由数据源，接着对shardingValues进行遍历，目的为至少命中一个路由键</li>
<li>遍历shardingValues循环体中，打印了当前循环的shardingValue，即实际的分片键的数值，如：订单号、用户id等。通过getIndex方法，获取该分片键值中包含的物理数据源索引</li>
<li>接着遍历数据源列表availableTargetNames，截取当前循环对应availableTargetName的索引值，（eg: ds0则取0，ds1则取1…以此类推）将该配置的物理数据源索引与 <strong>第2步</strong> 中解析到的数据源路由索引进行比较，两者相等则表名我们期望将该数据路由到该匹配到的数据源。</li>
<li>执行这个过程，直到匹配到一个路由键则停止循环，之所以这么做是因为我们是复合分片，至少要匹配到一个路由规则，才能停止循环，最终将路由到的物理数据源（ds0/ds1/ds2/ds3）通过add方法添加到事先定义好的集合中并返回给框架。</li>
<li>逻辑结束。</li>
</ol>
<p>可能读者朋友对如何从shardingValue中解析数据源的索引不理解，这里讲解一下。</p>
<p>上一篇文章中，我们在自定义全局业务id时，定义了一个主键枚举，并在枚举中定义了主键中库、表索引存放的位置，详细内容请移步 <a href="http://wuwenliang.net/2019/03/25/%E8%B7%9F%E6%88%91%E5%AD%A6shardingjdbc%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%BB%E9%94%AE%E5%8F%8A%E5%85%B6%E8%87%AA%E5%AE%9A%E4%B9%89/">跟我学shardingjdbc之分布式主键及其自定义</a> , 到这里就简单了，Sharding-JDBC框架已经通过 <strong>doSharding(Collection availableTargetNames, Collection shardingValues)</strong> 方法将当前的路由键的值给了我们，也就是我们通过KeyGenerator生成的业务主键，我们只需要解析该主键，获取其中的库索引即可，代码逻辑如下：</p>
<pre><code>/**
 * 根据分片键计算分片节点
 * @param logicTableName
 * @param columnName
 * @param shardingValue
 * @return
 */
public String getIndex(String logicTableName, String columnName, String shardingValue) {
    String index = &quot;&quot;;
    if (StringUtils.isBlank(shardingValue)) {
        throw new IllegalArgumentException(&quot;分片键值为空&quot;);
    }
    //截取分片键值-下标循环主键规则枚举类，匹配主键列名得到规则
    for (DbAndTableEnum targetEnum : DbAndTableEnum.values()) {

        /**目标表路由
         * 如果逻辑表命中，判断路由键是否与列名相同
         */
        if (targetEnum.getTableName().equals(logicTableName)) {
            //目标表的目标主键路由-例如：根据订单id查询订单信息
            if (targetEnum.getShardingKey().equals(columnName)) {
                index = getDbIndexBySubString(targetEnum, shardingValue);
            }else{
                //目标表的非目标主键路由-例如：根据内部用户id查询订单信息-内部用户id路由-固定取按照用户表库表数量
                //兼容且仅限根据外部id路由 查询用户信息
                index = getDbIndexByMod(targetEnum, shardingValue);
            }
            break;
        }
    }
    if (StringUtils.isBlank(index)) {
        String msg = &quot;从分片键值中解析数据库索引异常：logicTableName=&quot; + logicTableName + &quot;|columnName=&quot; + columnName + &quot;|shardingValue=&quot; + shardingValue;
        throw new IllegalArgumentException(msg);
    }
    return index;
}
</code></pre><p> 分析一下逻辑：</p>
<ol>
<li>由于我们无法直接将当前的逻辑表对应到定义好的分库分表规则枚举，因此对  DbAndTableEnum进行遍历，这里用到了枚举的 <strong>values()</strong> 方法 ，对该方法的解析，放在了文章的 <a href="#end">附录</a> 中。</li>
<li>在每一轮循环中，我们将枚举规则中定义的逻辑表名与ShardingValue中的逻辑表名比较，相等表名路由是正确的，则继续比对路由ShardingValue中的路由键key与枚举中定义的key是否相等（如：order_id），相等则通过String.subString(int beginIndex, int endIndex)方法截取当前分片键值（如：OD000000011903261545475143200001）中的数据库的索引，注意去掉前面补位的0。结束循环并将该库索引返回</li>
<li>如果匹配逻辑表成功，匹配分片键失败，我们认为是使用了外部主键（如：使用用户user_id查询了订单信息）则通过取模方式进行取库下标操作。这样就同时支持了通过主键、外部id的方式进行查询。</li>
</ol>
<h3 id="开发自定义复合分表策略"><a href="#开发自定义复合分表策略" class="headerlink" title="开发自定义复合分表策略"></a>开发自定义复合分表策略</h3><blockquote>
<p>完成了数据源的路由，我们接着实现对数据表的路由策略。</p>
</blockquote>
<p>方法基本和实现数据源路由相同，也是要实现 <strong>ComplexKeysShardingAlgorithm</strong>  接口。需要重写其 <strong>doSharding(Collection availableTargetNames, Collection shardingValues)</strong> 方法。</p>
<p>区别在于分表策略的目的是选择物理表索引，最终告知Sharding-JDBC将数据发往分片的那个物理分表上。</p>
<p>建立复合分表策略SnoWalkerComplexShardingTB.java，代码实现如下：</p>
<pre><code>@Override
public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; availableTargetNames, Collection&lt;ShardingValue&gt; shardingValues) {
    // 1. 打印物理分表集合 及 分片键属性集合
    log.info(&quot;availableTargetNames:&quot; + JSON.toJSONString(availableTargetNames) + &quot;,shardingValues:&quot; + JSON.toJSONString(shardingValues));

    // availableTargetNames:[&quot;t_new_order_0000&quot;,&quot;t_new_order_0001&quot;],
    // shardingValues:[{&quot;columnName&quot;:&quot;order_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;OD010001011903261549424993200011&quot;]},{&quot;columnName&quot;:&quot;user_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;UD030001011903261549424973200007&quot;]}]
    Collection&lt;String&gt; collection = new ArrayList&lt;&gt;();
    // 2. 遍历分片键集合
    for (ShardingValue var : shardingValues) {
        // 2.1 逻辑与分库逻辑相同，转换ShardingValue为ListShardingValue
        ListShardingValue&lt;String&gt; listShardingValue = (ListShardingValue&lt;String&gt;)var;
        List&lt;String&gt; shardingValue = (List&lt;String&gt;)listShardingValue.getValues();
        // 3. 打印当前分片键的真实值
        // shardingValue:[&quot;OD010001011903261549424993200011&quot;]
        log.info(&quot;shardingValue:&quot; + JSON.toJSONString(shardingValue));

        // 4. 根据分片键的真实值获取数据分表索引值
        String index = getIndex(listShardingValue.getLogicTableName(),                              listShardingValue.getColumnName(),
                                   shardingValue.get(0));
        // 5. 循环匹配数据表，通过String.endsWith(String suffix)
        // 判断第4步中获取到的索引是否包含在当前循环的物理分表中，
        // （如：判断t_new_order_0000中是否包含“_0000”）
        // 从而证明当前数据匹配物理分表成功。
        for (String availableTargetName : availableTargetNames) {
            if (availableTargetName.endsWith(&quot;_&quot; + index)) {
                collection.add(availableTargetName);
                break;
            }
        }
        // 6. 只要匹配成功一种路由规则就退出
        if (collection.size() &gt; 0) {
            break;
        }
    }
    // 7. 返回表路由结果
    return collection;
}   
</code></pre><h4 id="核心逻辑解析-1"><a href="#核心逻辑解析-1" class="headerlink" title="核心逻辑解析"></a>核心逻辑解析</h4><p>可以看到基本上和物理分片路由规则相似，区别在于此处是选取物理分表，注释中已经写得比较详细了，着重讲一下第四、五步。</p>
<p>第四步中，通过和之前物理分片取索引的相同算法取到分片键中的分表值，然后通过 <strong>String.endsWith(String suffix)</strong> 判断availableTargetName是否以 “_” + 分表索引值 结尾，如果是，则表明匹配物理分表成功，将该物理分表的完整表名（如：t_new_order_0000）添加到事先定义好的路由集合中，返回给Sharding-JDBC供其回调。</p>
<p>此处再贴一下getIndex方法，以便加深读者理解。</p>
<pre><code>/**
 * 根据分片键计算分片节点
 * @param logicTableName
 * @param columnName
 * @param shardingValue
 * @return
 */
public String getIndex(String logicTableName,String columnName,String shardingValue) {
    String index = &quot;&quot;;
    if (StringUtils.isBlank(shardingValue)) {
        throw new IllegalArgumentException(&quot;分片键值为空&quot;);
    }
    //截取分片键值-下标循环主键规则枚举类，匹配主键列名得到规则
    for (DbAndTableEnum targetEnum : DbAndTableEnum.values()) {
        //目标表路由
        if (targetEnum.getTableName().equals(logicTableName)) {
            //目标表的目标主键路由-例如：根据订单id查询订单信息
            if (targetEnum.getShardingKey().equals(columnName)) {
                index = getTbIndexBySubString(targetEnum, shardingValue);
            }else{
                //目标表的非目标主键路由-例如：根据内部用户id查询订单信息-内部用户id路由-固定取按照用户表库表数量
                //兼容且仅限根据外部id查询用户信息
                index = getTbIndexByMod(targetEnum, shardingValue);
            }
            break;
        }
    }
    if (StringUtils.isBlank(index)) {
        String msg = &quot;从分片键值中解析表索引异常：logicTableName=&quot; + logicTableName + &quot;|columnName=&quot; + columnName + &quot;|shardingValue=&quot; + shardingValue;
        throw new IllegalArgumentException(msg);
    }
    return index;
}
</code></pre><p>完整的代码请移步 <a href="https://github.com/TaXueWWL/snowalker-shardingjdbc-demo" target="_blank" rel="external">snowalker-shardingjdbc-demo</a> ，分库分表策略代码路径如下：</p>
<pre><code>## 自定义分库策略实现类路径
com.snowalker.shardingjdbc.snowalker.demo.complex.sharding
    .strategy.SnoWalkerComplexShardingTB
## 自定义分表策略实现类路径
com.snowalker.shardingjdbc.snowalker.demo.complex.sharding
    .strategy.SnoWalkerComplexShardingDB
</code></pre><p>到这里，我们就完成了自定义复合分库分表策略的开发，接下来就写几个测试用例实际测试一下。</p>
<h3 id="测试前置–配置自定义分库分表策略"><a href="#测试前置–配置自定义分库分表策略" class="headerlink" title="测试前置–配置自定义分库分表策略"></a>测试前置–配置自定义分库分表策略</h3><blockquote>
<p>这里以订单表t_new_order_0000 – t_new_order_0001的配置为例，在分片配置文件中添加如下配置项，将分库、分表策略指向我们定义好的策略类。</p>
</blockquote>
<pre><code>###############################################################
#
#                    shardingjdbc--分片规则--复合分片--订单表
#           根据user_id取模分库, 且根据order_id取模分表的两库两表的配置。
#
###############################################################
#订单表多分片键策略配置
sharding.jdbc.config.sharding.tables.t_new_order.actualDataNodes
    =ds$-&gt;{0..3}.t_new_order_000$-&gt;{0..1}
#指定分库分片键
sharding.jdbc.config.sharding.tables.t_new_order.databaseStrategy.complex.shardingColumns
    =user_id,order_id
#指定自定义分库策略类
sharding.jdbc.config.sharding.tables.t_new_order.databaseStrategy.complex.algorithmClassName
    =com.snowalker.shardingjdbc.snowalker.demo.complex.sharding.strategy.SnoWalkerComplexShardingDB
#指定分表分片键
sharding.jdbc.config.sharding.tables.t_new_order.tableStrategy.complex.shardingColumns
    =user_id,order_id
#指定自定义分表策略类
sharding.jdbc.config.sharding.tables.t_new_order.tableStrategy.complex.algorithmClassName
    =com.snowalker.shardingjdbc.snowalker.demo.complex.sharding.strategy.SnoWalkerComplexShardingTB
</code></pre><p><strong>注意</strong> 指定分片实现类时，一定要使用全限定名。Sharding-JDBC会解析配置文件后帮我们加载自定义的分片策略。</p>
<h3 id="测试用例A–新增订单数据"><a href="#测试用例A–新增订单数据" class="headerlink" title="测试用例A–新增订单数据"></a>测试用例A–新增订单数据</h3><p>测试用例代码如下：</p>
<pre><code>/**
 * 测试订单入库
 */
@Test
public void testNewOrderInsert() {
    // 支付宝或者微信uid
    String outId = &quot;1232132131241241243126&quot;;
    LOGGER.info(&quot;获取id开始&quot;);
    String innerUserId = keyGenerator.generateKey(DbAndTableEnum.T_USER, outId);
    LOGGER.info(&quot;外部id={},内部用户={}&quot;, outId, innerUserId);
    String orderId = keyGenerator.generateKey(DbAndTableEnum.T_NEW_ORDER, innerUserId);
    LOGGER.info(&quot;外部id={},内部用户={},订单={}&quot;, outId, innerUserId, orderId);
    OrderNewInfoEntity orderInfo = new OrderNewInfoEntity();
    orderInfo.setUserName(&quot;snowalker&quot;);
    orderInfo.setUserId(innerUserId);
    orderInfo.setOrderId(orderId);
    orderNewSerivce.addOrder(orderInfo);

}
</code></pre><p>执行用例，日志打印如下：</p>
<pre><code>2019-03-26 21:25:31.296  INFO 12996 --- [           main] nowalkerShardingjdbcDemoApplicationTests : 
    获取id开始
2019-03-26 21:25:34.755  INFO 12996 --- [           main] nowalkerShardingjdbcDemoApplicationTests : 
外部id=12321321312412412431260,内部用户=UD020000011903262125313013200040
2019-03-26 21:25:34.758  INFO 12996 --- [           main] nowalkerShardingjdbcDemoApplicationTests : 
外部id=12321321312412412431260,内部用户=UD020000011903262125313013200040,订单=OD000000011903262125347553200121
2019-03-26 21:25:34.758  INFO 12996 --- [           main] c.s.s.s.d.c.s.service.OrderNewSerivce    : 
订单入库开始，orderinfo=OrderNewInfoEntity{id=null, userId=&apos;UD020000011903262125313013200040&apos;, orderId=&apos;OD000000011903262125347553200121&apos;, userName=&apos;snowalker&apos;}
2019-03-26 21:25:34.921  INFO 12996 --- [           main] s.s.s.d.c.s.s.SnoWalkerComplexShardingDB : 
availableTargetNames:[&quot;ds0&quot;,&quot;ds1&quot;,&quot;ds2&quot;,&quot;ds3&quot;],shardingValues:[{&quot;columnName&quot;:&quot;user_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;UD020000011903262125313013200040&quot;]},{&quot;columnName&quot;:&quot;order_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;OD000000011903262125347553200121&quot;]}]
2019-03-26 21:25:34.921  INFO 12996 --- [           main] s.s.s.d.c.s.s.SnoWalkerComplexShardingDB : 
shardingValue:[&quot;UD020000011903262125313013200040&quot;]
2019-03-26 21:25:34.921  INFO 12996 --- [           main] s.s.s.d.c.s.s.SnoWalkerComplexShardingTB : 
availableTargetNames:[&quot;t_new_order_0000&quot;,&quot;t_new_order_0001&quot;],shardingValues:[{&quot;columnName&quot;:&quot;user_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;UD020000011903262125313013200040&quot;]},{&quot;columnName&quot;:&quot;order_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;OD000000011903262125347553200121&quot;]}]
2019-03-26 21:25:34.921  INFO 12996 --- [           main] s.s.s.d.c.s.s.SnoWalkerComplexShardingTB : 
shardingValue:[&quot;UD020000011903262125313013200040&quot;]
2019-03-26 21:25:34.928  INFO 12996 --- [           main] Sharding-Sphere-SQL                      : Rule Type: sharding
2019-03-26 21:25:34.928  INFO 12996 --- [           main] Sharding-Sphere-SQL                      : 
    Logic SQL: insert into t_new_order(
            user_id,
            order_id,
            user_name
        )
        values
        (
            ?,
            ?,
            ?
        )
......
2019-03-26 21:25:34.928  INFO 12996 --- [           main] Sharding-Sphere-SQL                      : 
Actual SQL: ds0 ::: insert into t_new_order_0000(
        user_id,
        order_id,
        user_name
    )
    values
    (
        ?,
        ?,
        ?
    ) ::: [[UD020000011903262125313013200040, OD000000011903262125347553200121, snowalker]]
</code></pre><p>可以看到，我们生成的订单号OD000000011903262125347553200121被路由到ds0的t_new_order_0000表，这和我们的订单号中的第四位到第九位的 00（库）0000（表）吻合，表明我们的策略配合主键生成器生效了且是符合预期要求的。</p>
<h3 id="测试用例B–通过订单号查询订单明细"><a href="#测试用例B–通过订单号查询订单明细" class="headerlink" title="测试用例B–通过订单号查询订单明细"></a>测试用例B–通过订单号查询订单明细</h3><p>测试用例代码如下：</p>
<pre><code>/**
 * 测试订单明细查询
 */
@Test
public void testQueryNewOrderById() {
    String orderId = &quot;OD010001011903261549424993200011&quot;;
    String userId = &quot;UD030001011903261549424973200007&quot;;
    OrderNewInfoEntity orderInfo = new OrderNewInfoEntity();
    orderInfo.setOrderId(orderId);
    orderInfo.setUserId(userId);
    System.out.println(orderNewSerivce.queryOrderInfoByOrderId(orderInfo));
}
</code></pre><p>我们要查询订单号为OD010001011903261549424993200011，用户id=UD030001011903261549424973200007的订单明细，执行该测试用例，日志打印如下：</p>
<pre><code>2019-03-26 21:32:16.459  INFO 16140 --- [           main] s.s.s.d.c.s.s.SnoWalkerComplexShardingDB : 
availableTargetNames:[&quot;ds0&quot;,&quot;ds1&quot;,&quot;ds2&quot;,&quot;ds3&quot;],shardingValues:[{&quot;columnName&quot;:&quot;order_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;OD010001011903261549424993200011&quot;]},{&quot;columnName&quot;:&quot;user_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;UD030001011903261549424973200007&quot;]}]
2019-03-26 21:32:16.459  INFO 16140 --- [           main] s.s.s.d.c.s.s.SnoWalkerComplexShardingDB : 
shardingValue:[&quot;OD010001011903261549424993200011&quot;]
2019-03-26 21:32:16.466  INFO 16140 --- [           main] s.s.s.d.c.s.s.SnoWalkerComplexShardingTB : 
availableTargetNames:[&quot;t_new_order_0000&quot;,&quot;t_new_order_0001&quot;],shardingValues:[{&quot;columnName&quot;:&quot;order_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;OD010001011903261549424993200011&quot;]},{&quot;columnName&quot;:&quot;user_id&quot;,&quot;logicTableName&quot;:&quot;t_new_order&quot;,&quot;values&quot;:[&quot;UD030001011903261549424973200007&quot;]}]
2019-03-26 21:32:16.466  INFO 16140 --- [           main] s.s.s.d.c.s.s.SnoWalkerComplexShardingTB : 
shardingValue:[&quot;OD010001011903261549424993200011&quot;]
2019-03-26 21:32:16.474  INFO 16140 --- [           main] Sharding-Sphere-SQL                      : Rule Type: sharding
2019-03-26 21:32:16.475  INFO 16140 --- [           main] Sharding-Sphere-SQL                      : 
Logic SQL: select
            t.id as id,
            t.user_id as userId,
            t.order_id as orderId,
            t.user_name as userName
        from t_new_order t
        where t.order_id=?
        and t.user_id=?
......
2019-03-26 21:32:16.476  INFO 16140 --- [           main] Sharding-Sphere-SQL                      : 
Actual SQL: ds1 ::: select
            t.id as id,
            t.user_id as userId,
            t.order_id as orderId,
            t.user_name as userName
        from t_new_order_0001 t
        where t.order_id=?
        and t.user_id=? ::: [[OD010001011903261549424993200011, UD030001011903261549424973200007]]
OrderNewInfoEntity{id=1249, userId=&apos;UD030001011903261549424973200007&apos;, orderId=&apos;OD010001011903261549424993200011&apos;, userName=&apos;snowalker&apos;}
</code></pre><p>sql中传入了两个查询条件，首先匹配到的是order_id，因此先按照order_id进行路由，找到ds1的t_new_order_0001表，在该表中执行真实查询SQL如下</p>
<pre><code>select
    t.id as id,
    t.user_id as userId,
    t.order_id as orderId,
    t.user_name as userName
from t_new_order_0001 t
where t.order_id=?
and t.user_id=? ::: [[OD010001011903261549424993200011, UD030001011903261549424973200007]]
</code></pre><p>查询结果为</p>
<pre><code>OrderNewInfoEntity{id=1249, 
    userId=&apos;UD030001011903261549424973200007&apos;, orderId=&apos;OD010001011903261549424993200011&apos;, 
    userName=&apos;snowalker&apos;}
</code></pre><p>可以看到，依旧满足我们的要求，表明我们的复合路由策略是正确的。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文中，我们结合之前的自定义分布式主键，完成了Sharding-JDBC中复合分片路由算法的自定义实现，并经过测试验证符合预期。</p>
<p>该实现方案在生产上已经经历过考验，读者可以借鉴并运用到自己的项目中。</p>
<p>定义分片路由策略的核心还是要熟悉ComplexKeysShardingAlgorithm，对如何解析 doSharding(Collection<string> availableTargetNames, Collection<shardingvalue> shardingValues)的参数有明确的认识，最简单的方法就是实际打印一下参数，相信会让你更加直观的感受到作者优良的接口设计能力，站在巨人的肩膀上我们能看到更远。</shardingvalue></string></p>
<p>到此，跟我学Sharding-JDBC系列就告一段落，后续待笔者功力精进，会对该框架的源码做进一步的解析，让我们不见不散。</p>
<p><a href="https://github.com/TaXueWWL/snowalker-shardingjdbc-demo" target="_blank" rel="external">跟我学Sharding-JDBC源码github地址</a></p>
<h2 id="附录：解析枚举类的values-方法"><a href="#附录：解析枚举类的values-方法" class="headerlink" title="附录：解析枚举类的values()方法"></a><a name="end">附录：解析枚举类的values()方法</a></h2><blockquote>
<p>枚举的 <strong>values()</strong> 方法 是编译器生成的static方法，因此在Enum类中并没出现values()方法，它是编译器编译枚举类后添加的。values()方法的作用就是获取枚举类中的所有变量，并作为数组返回。</p>
<p>注意，由于values()方法是编译器插入到枚举类中的static方法，所以如果我们将枚举实例向上转型为Enum，则values()方法将无法被调用，因为Enum类中并没有values()方法，valueOf()方法也是同样的道理，注意是一个参数的。</p>
</blockquote>
<p>参考链接：</p>
<p><a href="https://www.cnblogs.com/alter888/p/9163612.html" target="_blank" rel="external">深入理解Java枚举类型(enum)</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文是 “跟我学Sharding-JDBC” 系列的第四篇，我将带领读者一起了解下Sharding-JDBC的数据分片规则并通过实例实现自定义分片策略的开发实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Sharding-JDBC中的分片策略有两个维度，分别是：数据源分片策略（DatabaseShardingStrategy）、表分片策略（TableShardingStrategy）。&lt;/p&gt;
&lt;p&gt;其中，数据源分片策略表示：数据路由到的物理目标数据源，表分片策略表示数据被路由到的目标表。&lt;/p&gt;
&lt;p&gt;特别的，表分片策略是依赖于数据源分片策略的，也就是说要先分库再分表。&lt;/p&gt;
&lt;p&gt;这里贴一张盗来的图&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/03/26/跟我学shardingjdbc之自定义分库分表策略-复合分片算法自定义实现/./sharding.png&quot; alt=&quot;Sharding-JDBC分片策略代码架构&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Sharding-JDBC" scheme="http://wuwenliang.net/categories/Sharding-JDBC/"/>
    
    
      <category term="Sharding-JDBC" scheme="http://wuwenliang.net/tags/Sharding-JDBC/"/>
    
  </entry>
  
  <entry>
    <title>跟我学shardingjdbc之分布式主键及其自定义</title>
    <link href="http://wuwenliang.net/2019/03/25/%E8%B7%9F%E6%88%91%E5%AD%A6shardingjdbc%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%BB%E9%94%AE%E5%8F%8A%E5%85%B6%E8%87%AA%E5%AE%9A%E4%B9%89/"/>
    <id>http://wuwenliang.net/2019/03/25/跟我学shardingjdbc之分布式主键及其自定义/</id>
    <published>2019-03-25T02:38:42.000Z</published>
    <updated>2019-03-26T06:11:18.999Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文是 “跟我学Sharding-JDBC” 系列的第三篇，我将带领读者一起了解下Sharding-JDBC的分布式主键，并实现业务性更强的自定义主键。</p>
</blockquote>
<p>首先了解下，什么是分布式主键。</p>
<p>传统的关系型数据库，如MySQL中，数据库本身自带自增主键生成机制，但在分布式环境下，由于分库分表导致数据水平拆分后无法使用单表自增主键，因此我们需要一种全局唯一id生成策略作为分布式主键。</p>
<p>当前业界已经有不少成熟的方案能够解决分布式主键的生成问题，如：UUID、SnoWflake算法（Twitter）、Leaf算法（美团点评）等。</p>
<a id="more"></a>
<h2 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h2><blockquote>
<p>UUID是Universally Unique Identifier的缩写，它是在一定的范围内（从特定的名字空间到全球）唯一的机器生成的标识符。</p>
</blockquote>
<p>UUID具有如下特点：</p>
<ol>
<li>经由一定的算法机器生成，算法定义了网卡MAC地址、时间戳、名字空间（Namespace）、随机或伪随机数、时序等元素，以及从这些元素生成UUID的算法。UUID的复杂特性在保证了其唯一性的同时，意味着只能由计算机生成。</li>
<li>非人工指定，非人工识别。UUID的复杂性决定了“一般人“不能直接从一个UUID知道哪个对象和它关联。</li>
<li>在特定的范围内重复的可能性极小。</li>
</ol>
<p>UUID能够保证最少在3000+年内不会重复。因此它的唯一性是很可靠的。但也有不足之处，就是可读性差，不能直接用来做分片键并进行取模分库表的操作，需要进行额外的开发，如：转换UUID为unicode/ASCII码，对数字进行叠加后取模。</p>
<h2 id="SnoWflake"><a href="#SnoWflake" class="headerlink" title="SnoWflake"></a>SnoWflake</h2><p>雪花算法（SnoWflake）是Twitter公布的分布式主键生成算法，也是ShardingSphere默认提供的配置分布式主键生成策略方式。在ShardingSphere的类路径为：<strong>io.shardingsphere.core.keygen.DefaultKeyGenerator</strong></p>
<p>SnoWflake能够保证不同进程主键的不重复性，以及相同进程内主键的有序性。</p>
<p>在同一个进程中，SnoWflake首先是通过时间位保证不重复，如果时间相同则是通过序列位保证。 同时由于时间位是单调递增的，且各个服务器如果大体做了时间同步，那么生成的主键在分布式环境可以认为是总体有序的，这就保证了对索引字段的插入的高效性。例如MySQL的Innodb存储引擎的主键。</p>
<p>雪花算法生成的主键的二进制表示形式包含4部分，从高位到低位分别为：1bit符号位、41bit时间戳位、10bit工作进程位以及12bit序列号位。</p>
<p>雪花算法能够保证全局唯一，同时也存在一些问题，如时钟回拨可能导致产生重复序列。为了解决这个问题，ShardingSphere默认分布式主键生成器提供了一个最大容忍的时钟回拨毫秒数。</p>
<p>如果时钟回拨的时间超过最大容忍的毫秒数阈值，则程序报错；如果在可容忍的范围内，默认分布式主键生成器会等待时钟同步到最后一次主键生成的时间后再继续工作。 最大容忍的时钟回拨毫秒数的默认值为0，可通过调用静态方法<strong>DefaultKeyGenerator.setMaxTolerateTimeDifferenceMilliseconds()</strong>设置。</p>
<h2 id="其他方案"><a href="#其他方案" class="headerlink" title="其他方案"></a>其他方案</h2><blockquote>
<p>这里再简单介绍下其他的分布式主键生成的方案。</p>
</blockquote>
<h3 id="Leaf算法"><a href="#Leaf算法" class="headerlink" title="Leaf算法"></a>Leaf算法</h3><p>对Leaf算法，推荐访问这个链接 <a href="https://tech.meituan.com/2017/04/21/mt-leaf.html" target="_blank" rel="external">Leaf——美团点评分布式ID生成系统</a></p>
<h3 id="Redis计数器"><a href="#Redis计数器" class="headerlink" title="Redis计数器"></a>Redis计数器</h3><p>我们还可以通过第三方的组件的特性二次开发自己的分布式id生成器。如：使用Redis的 <strong>INCR key</strong>自增计数器，它是 Redis 的原子性自增操作最直观的模式，其原理相当简单：每当某个操作发生时，向 Redis 发送一个 INCR 命令。</p>
<p>比如在一个 web 应用中，想知道用户在一年中每天的点击量，那么只要将用户ID及相关的日期信息作为键，并在每次用户点击页面时，执行一次自增操作即可。</p>
<p>它有着多种扩展模式，如：</p>
<ol>
<li>通过组合使用 INCR 和 EXPIRE达到只在规定的生存时间内进行计数(counting)的目的</li>
<li>客户端通过使用 GETSET 命令<strong>原子性</strong>地获取计数器当前值并将计数器清零，更多信息请参考 GETSET 命令。</li>
<li>通过用其他自增/自减操作，比如 DECR 和 INCRBY ，用户可以在完成业务操作之后增加或减少计数器的值，如在游戏中的记分器就是一个典型的场景。</li>
</ol>
<p>它的优点在于：</p>
<ol>
<li>不依赖数据库且性能优于数据库。</li>
<li>ID天然有序，对分页或者需要排序的场景很友好。</li>
</ol>
<p>但是它还存在如下的缺点：</p>
<ol>
<li>如果系统中没有Redis需要引入Redis增加了系统复杂度。</li>
<li>需要额外的编码和配置工作。</li>
</ol>
<p>但总体来讲，这是个不错的方案，分布式环境下，我们通过集群Redis能够保证生成器高可用运行，集群之间通过复制能够保证序列生成不会有单点故障。</p>
<h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h3><p>通过利用zookeeper的持久顺序节点特性，多个客户端同时创建同一节点，zk可以保证有序的创建，创建成功并返回的path类似于/root/generateid0000000001这样的节点，能够看到是顺序有规律的。利用这个特性，我们能够实现基于zk的分布式id生成器。</p>
<p>不过一般我们很少会使用zookeeper来生成唯一ID。主要是由于需要依赖zookeeper，并且是多步调用API，如果在竞争较大的情况下，需要考虑使用分布式锁。因此，在高并发的分布式环境下，性能不甚理想。</p>
<h3 id="MySQL自增id"><a href="#MySQL自增id" class="headerlink" title="MySQL自增id"></a>MySQL自增id</h3><p>这种方式很好理解，就是建立一张序列表，执行插入操作，并获取记录的id值。</p>
<p>它的优点如下：</p>
<ol>
<li>容易理解，开发量不多，且性能可以接受。</li>
<li>通过自增主键生成的ID天然排序，对分页或者需要排序的结果很有帮助。</li>
</ol>
<p>同时它存在如下的缺点：</p>
<ol>
<li>不同数据库语法的和实现不同，如果需要切换数据库或多数据库版本支持的时候需要在每个库中单独处理。</li>
<li>在单数据库或读写分离或一主多从的情况下，只有一个主库可以生成。有单点故障风险。</li>
<li>id的生成与数据库的性能强关联。</li>
<li>如果存在数据的迁移，则id序列表也需要同步迁移。</li>
<li>分表分库场景下会有麻烦。</li>
</ol>
<p>当然这些问题都有针对的解决方案：</p>
<ol>
<li>对于不同的数据库，只需要将id的生成作为单独的服务开发，不同的业务通过接口调用id生成，屏蔽后方的实现细节</li>
<li>针对主库单点，可以改造为多Master架构</li>
<li>如果条件允许，使用高性能磁盘及主机部署数据库</li>
<li>通过双写操作的方式进行数据迁移</li>
<li>分库分表场景下，只需要在每个数据分片上设置对应表的序列生成表即可，序列表与业务表使用相同的分片规则，这样就能保证序列与业务是一一对应的，在每个片上，都是唯一且自增的。</li>
</ol>
<h2 id="我的选择"><a href="#我的选择" class="headerlink" title="我的选择"></a>我的选择</h2><p>通过了解各种分布式主键生成策略，我最终选择了Redis的计数器作为自定义分布式主键的核心技术方案。</p>
<p>原因如下：</p>
<ol>
<li>业务id如果直接使用UUID、snowflake等可读性较差，需要有业务属性，最好能直观的看到分片属性</li>
<li>业务中本身就引入了Redis集群，不需要额外的依赖</li>
<li>Redis方案开发简单且可靠性强</li>
</ol>
<h2 id="基于Redis的分布式主键的自定义开发"><a href="#基于Redis的分布式主键的自定义开发" class="headerlink" title="基于Redis的分布式主键的自定义开发"></a>基于Redis的分布式主键的自定义开发</h2><blockquote>
<p>到此，我们对主流的分布式主键的生成策略进行了分析后选定了使用Redis的计数器进行开发，接下来就讲解下如何实现业务友好的自定义分布式主键。</p>
</blockquote>
<h3 id="id格式解析"><a href="#id格式解析" class="headerlink" title="id格式解析"></a>id格式解析</h3><p>首先解析一下最终生成的ID的格式，举个例子，如：生成订单号如下：</p>
<pre><code>OD00000101201903251029141503200002
</code></pre><p>从左往右依次为：</p>
<pre><code>业务编码(2位) + 库下标（2位）+ 表下标（4位）
+ 序列版本号（默认为01，2位）+ 时间戳（yyMMddHHmmssSSS，精确到毫秒，15位）
+ 机器id（2位）
+ 序列号（5位）
</code></pre><p>共32位。</p>
<p>这个格式的id对于业务而言，可读性更好，能够直观的看到是哪个业务的id，分布在哪个片上，是哪个时间生成的，比纯数字的更加直观。</p>
<h3 id="开发过程-01-定义分布式主键格式"><a href="#开发过程-01-定义分布式主键格式" class="headerlink" title="开发过程-01-定义分布式主键格式"></a>开发过程-01-定义分布式主键格式</h3><p>首先，我们定义分布式主键的格式，这里通过枚举实现。</p>
<p>新建名为 DbAndTableEnum 的库表规则枚举类，根据上述id的格式，分别定义属性如下</p>
<pre><code>public enum DbAndTableEnum {

    /**
    * 用户信息表 UD+db+table+01+yyMMddHHmmssSSS+机器id+序列号id
    * 例如：UD000000011902261230103345300002 共 2+6+2+15+2+5=32位
    */
    T_USER(&quot;t_user&quot;, &quot;user_id&quot;, &quot;01&quot;, &quot;01&quot;, &quot;UD&quot;, 2, 2, 4, 4, 16, &quot;用户数据表枚举&quot;),

    T_NEW_ORDER(&quot;t_new_order&quot;, &quot;order_id&quot;, &quot;01&quot;, &quot;01&quot;, &quot;OD&quot;, 2,2, 4, 4, 8, &quot;订单数据表枚举&quot;);

    /**分片表名*/
    private String tableName;
    /**分片键*/
    private String shardingKey;
    /**系统标识*/
    private String bizType;
    /**主键规则版本*/
    private String idVersion;
    /**表名字母前缀*/
    private String charsPrefix;
    /**分片键值中纯数字起始下标索引，第一位是0,第二位是1，依次类推*/
    private int numberStartIndex;
    /**数据库索引位开始下标索引*/
    private int dbIndexBegin;
    /**表索引位开始下标索引*/
    private int tbIndexBegin;
    /**分布所在库数量*/
    private int dbCount;
    /**分布所在表数量-所有库中表数量总计*/
    private int tbCount;
    /**描述*/
    private String desc;
    ...省略getter  setter 构造方法...
</code></pre><p>这里我根据属性，定义了我的demo中需要使用的两个枚举，分别为用户表、订单表的主键枚举。以用户表举例：</p>
<pre><code>T_USER(&quot;t_user&quot;,                // 用户逻辑表名
        &quot;user_id&quot;,              // 用户表分片键
        &quot;01&quot;,                   // 系统标识默认为01
        &quot;01&quot;,                   // 主键规则默认为01 
        &quot;UD&quot;,                   // 用户表前缀
        2,                      // 分片键值中纯数字起始下标，默认为2
        2,                      // 数据库索引位开始下标索引，同上，默认第二位
        4,                      // 分片数量，eg：分4库
        4,                      // 每个分片中分表数量，每个片上4表
        16,                     // 所有分片的分表总数
        &quot;用户数据表枚举&quot;),        // 描述
</code></pre><p>在不同的业务中，可以根据对应的业务定义对应的id枚举，原则是：开发阶段一定能够知道当前id是为哪个业务准备的，也能够事先预估好数据的容量。</p>
<h3 id="开发过程-02-定义序列生成器接口并实现"><a href="#开发过程-02-定义序列生成器接口并实现" class="headerlink" title="开发过程-02-定义序列生成器接口并实现"></a>开发过程-02-定义序列生成器接口并实现</h3><blockquote>
<p>定义一个抽象序列接口，方便扩展</p>
</blockquote>
<pre><code>public interface SequenceGenerator {


    /**
      * @param targetEnum
      * @param dbIndex
      * @param tbIndex
      * @return
      */
    String getNextVal(DbAndTableEnum targetEnum, int dbIndex, int tbIndex);
}
</code></pre><p>由于我们使用了Redis作为序列生成器，因此只需要编写SequenceGenerator的实现类，利用Redis的计数器实现序列生成操作getNextVal()即可。</p>
<pre><code>@Component(value = &quot;redisSequenceGenerator&quot;)
public class RedisSequenceGenerator implements SequenceGenerator {

    /**序列生成器key前缀*/
    public static String LOGIC_TABLE_NAME = &quot;sequence:redis:&quot;;
    /**序列长度=5，不足5位的用0填充*/
    public static int SEQUENCE_LENGTH = 5;
    /**序列最大值=90000*/
    public static int sequence_max = 90000;

    @Autowired
    StringRedisTemplate stringRedisTemplate;

    /**
    * redis序列获取实现方法
    * @param targetEnum
    * @param dbIndex
    * @param tbIndex
    * @return
    */
    @Override
    public String getNextVal(DbAndTableEnum targetEnum, int dbIndex, int tbIndex) {

        //拼接key前缀
        String redisKeySuffix = new StringBuilder(targetEnum.getTableName())
                .append(&quot;_&quot;)
                .append(&quot;dbIndex&quot;)
                .append(StringUtil.fillZero(String.valueOf(dbIndex), ShardingConstant.DB_SUFFIX_LENGTH))
                .append(&quot;_tbIndex&quot;)
                .append(StringUtil.fillZero(String.valueOf(tbIndex), ShardingConstant.TABLE_SUFFIX_LENGTH))
                .append(&quot;_&quot;)
                .append(targetEnum.getShardingKey()).toString();

        String increKey = new StringBuilder(LOGIC_TABLE_NAME).append(redisKeySuffix).toString();
        long sequenceId = stringRedisTemplate.opsForValue().increment(increKey);
        //达到指定值重置序列号，预留后10000个id以便并发时缓冲
        if (sequenceId == sequence_max) {
            stringRedisTemplate.delete(increKey);
        }
        // 返回序列值，位数不够前补零
        return StringUtil.fillZero(String.valueOf(sequenceId), SEQUENCE_LENGTH);
    }
}
</code></pre><p>由于用到了StringRedisTemplate作为Redis操作工具，因此需要引入Redis并配置对应的参数，具体方法此处不赘述，请移步我的另一篇文章 <a href="http://wuwenliang.net/2018/07/23/springboot%E6%95%B4%E5%90%88redis%E5%B0%8F%E7%BB%93/">《springboot整合redis小结》</a>。</p>
<p>分析一下代码逻辑，首先拼接了序列在redis中的key，将当前记录所在的库、表下标以及当前的表名和分片键名称拼接在一起，在最前面拼接好当前key的功能，最终生成的key如下：</p>
<pre><code>sequence:redis:t_new_order_dbIndex00_tbIndex0001_order_id
</code></pre><p>这个key表示：redis生成的sequence序列，序列所属表为t_new_order，分片键为order_id，序列所属库下标为00库，所属表下标为0001表。</p>
<h3 id="开发过程-03-实现自定义的KeyGen自定义主键生成器"><a href="#开发过程-03-实现自定义的KeyGen自定义主键生成器" class="headerlink" title="开发过程-03-实现自定义的KeyGen自定义主键生成器"></a>开发过程-03-实现自定义的KeyGen自定义主键生成器</h3><p>上面的操作中，我们实现了核心的自增序列生成器，下面的内容中我们着手开发对业务暴露的生成器KeyGenerator的核心逻辑。</p>
<p>新建一个类，KeyGenerator.java标记为spring的一个Component。由于我们的业务基本上使用了Spring Boot框架，因此我开发的时候均通过Spring Bean的方式进行类定义。如果你要在非Spring框架中使用，需要自行完成Redis的连接等操作。</p>
<p>由于此处的逻辑较多，我只放核心的业务，完整的代码烦请移步github的项目页，本节的代码已经上传，sql脚本也同步更新了。<a href="https://github.com/TaXueWWL/snowalker-shardingjdbc-demo" target="_blank" rel="external">项目地址：snowalker-shardingjdbc-demo</a></p>
<pre><code>/**
 * 根据路由id生成内部系统主键id，
 * 路由id可以是内部其他系统主键id，也可以是外部第三方用户id
 * @param targetEnum 待生成主键的目标表规则配置
 * @param relatedRouteId  路由id或外部第三方用户id
 * @return
 */
public String generateKey(DbAndTableEnum targetEnum, String relatedRouteId) {

    if (StringUtils.isBlank(relatedRouteId)) {
        throw new IllegalArgumentException(&quot;路由id参数为空&quot;);
    }

    StringBuilder key = new StringBuilder();
    /** 1.id业务前缀*/
    String idPrefix = targetEnum.getCharsPrefix();
    /** 2.id数据库索引位*/
    String dbIndex = getDbIndexAndTbIndexMap(targetEnum, relatedRouteId).get(&quot;dbIndex&quot;);
    /** 3.id表索引位*/
    String tbIndex = getDbIndexAndTbIndexMap(targetEnum, relatedRouteId).get(&quot;tbIndex&quot;);
    /** 4.id规则版本位*/
    String idVersion = targetEnum.getIdVersion();
    /** 5.id时间戳位*/
    String timeString = DateUtil.formatDate(new Date());
    /** 6.id分布式机器位 2位*/
    String distributedIndex = getDistributedId(2);
    /** 7.随机数位*/
    String sequenceId = sequenceGenerator.getNextVal(targetEnum, Integer.parseInt(dbIndex), Integer.parseInt(tbIndex));
    /** 库表索引靠前*/
    return key.append(idPrefix)
            .append(dbIndex)
            .append(tbIndex)
            .append(idVersion)
            .append(timeString)
            .append(distributedIndex)
            .append(sequenceId).toString();
}
</code></pre><p>该方法为外部业务调用的生成主键的核心API，方法声明为：</p>
<pre><code>generateKey(DbAndTableEnum targetEnum, String relatedRouteId)
</code></pre><p>第一个参数为需要生成id的目标表的数据源/数据表枚举，第二个参数为相对路由id。</p>
<blockquote>
<p>这里解释一下相对路由id的含义。</p>
</blockquote>
<p>在实际开发中，我们需要将外部的id转换为内部的id使用，这样既可以保证数据的分布均匀，又有利于数据安全。如：根据支付宝uid生成系统内部的用户id。对外交互使用支付宝uid，内部统一使用内部的用户id。</p>
<p>继续我们的逻辑，当我们有了内部的用户id之后，通过内部用户id生成业务表id，如：账户id、订单id等。由于账户id、用户id使用同一个相对路由id（内部用户id），账户信息与订单信息使用了相同的路由规则，因此它们会位于同一个数据分片上，这样就能在业务上保证同一个用户的业务信息都在同一个数据分片上，单库事务得以继续使用，同库内的join操作也能够支持。由于所有的数据都在一个数据分片上，因此少了跨片join及跨片的归并操作，查询效率大幅度提升。</p>
<p>代码逻辑很清晰，就是按位填充对应的参数，其中时间戳使用SimpleDateFormat的format方法获取，这里使用ThreadLocal包装SimpleDateFormat保证线程安全。</p>
<p>我们着重看下如何获取库表索引及分布式机器位，</p>
<h4 id="获取库表索引"><a href="#获取库表索引" class="headerlink" title="获取库表索引"></a>获取库表索引</h4><p>通过方法 <strong>getDbIndexAndTbIndexMap</strong> 获取数据库的库表下标，代码如下：</p>
<pre><code>/**
 * 根据已知路由id取出库表索引，外部id和内部id均 进行ASCII转换后再对库表数量取模
 * @param targetEnum 待生成主键的目标表规则配置
 * @param relatedRouteId 路由id
 * @return
 */
private Map&lt;String, String&gt; getDbIndexAndTbIndexMap(DbAndTableEnum targetEnum,String relatedRouteId) {
    Map&lt;String, String&gt; map = new HashMap&lt;&gt;();
    /** 获取库索引*/
    String preDbIndex = String.valueOf(
                            getDbIndexByMod(
                                relatedRouteId,
                                targetEnum.getDbCount(),
                                targetEnum.getTbCount()));
    String dbIndex = StringUtil.fillZero(preDbIndex,    ShardingConstant.DB_SUFFIX_LENGTH);
    /** 获取表索引*/
    String preTbIndex = String
            .valueOf(StringUtil.getTbIndexByMod(relatedRouteId,targetEnum.getDbCount(),targetEnum.getTbCount()));
    String tbIndex = StringUtil
            .fillZero(preTbIndex,ShardingConstant.TABLE_SUFFIX_LENGTH);
    map.put(&quot;dbIndex&quot;, dbIndex);
    map.put(&quot;tbIndex&quot;, tbIndex);
    return map;
}

public static long getDbIndexByMod(Object obj,int dbCount,int tbCount) {
    long tbRange = getModValue(obj, tbCount);
    BigDecimal bc = new BigDecimal(tbRange);
    BigDecimal[] results = bc.divideAndRemainder(new BigDecimal(dbCount));
    return (long)results[0].intValue();
}

/**
 * 先对指定对象取ASCII码后取模运算
 * @param obj
 * @param num
 * @return
 */
public static long getModValue(Object obj,long num) {
    String str = getAscII(obj == null?&quot;&quot;:obj.toString());
    BigDecimal bc = new BigDecimal(str);
    BigDecimal[] results = bc.divideAndRemainder(new BigDecimal(num));
    return (long)results[1].intValue();
}
</code></pre><p>首先转换外部id为ASCII码，通过该ASCII码对库取商，对表取余，得到库表下标，并拼接到主键中，如图：</p>
<p><img src="/2019/03/25/跟我学shardingjdbc之分布式主键及其自定义/./dbmod.png" alt="分片原理"></p>
<p>此方案是针对ShardingJDBC的分片模式的，在ShardingJDBC中，每个分片中的数据库表的结构是相同的，如：</p>
<pre><code>db_00--
    |--t_order_0000
    |--t_order_0001
db_01--
    |--t_order_0000
    |--t_order_0001
db_02--
    |--t_order_0000
    |--t_order_0001
db_03--
    |--t_order_0000
    |--t_order_0001
</code></pre><h4 id="获取分布式机器id"><a href="#获取分布式机器id" class="headerlink" title="获取分布式机器id"></a>获取分布式机器id</h4><p>接着看下如何获取分布式机器id。</p>
<pre><code>/**
 * 生成id分布式机器位
 * @return 分布式机器id
 * length与hostCount位数相同
 */
private String getDistributedId(int length, int hostCount) {
    return StringUtil
            .fillZero(String.valueOf(getIdFromHostName() % hostCount), length);
}


/**
 * 适配分布式环境，根据主机名生成id
 * 分布式环境下，如：Kubernates云环境下，集群内docker容器名是唯一的
 * 通过 @See org.apache.commons.lang3.SystemUtils.getHostName()获取主机名
 * @return
 */
private Long getIdFromHostName(){
    //unicode code point
    int[] ints = StringUtils.toCodePoints(SystemUtils.getHostName());
    int sums = 0;
    for (int i: ints) {
        sums += i;
    }
    return (long)(sums);
}
</code></pre><p>这里我们通过StringUtils.toCodePoints(SystemUtils.getHostName());获取到当前主机名的unicode值，并将每个字符的unicode值相加，这里只要保证我们服务器的名称是唯一的，则codePoint值就是唯一的。例如：使用K8S进行部署的环境下，生成的docker容器的名称是集群内唯一的，保证了getIdFromHostName()返回值的唯一性。</p>
<p>我们用主机名生成的codePoint值对全局主机数量进行取模操作，即可获取当前id位于哪台机器上。</p>
<p>又由于在整个序列中添加了精确到毫秒的时间戳以及使用了Redis的计数器，能够大幅度的支撑高并发环境下的主键生成策略。只要不存在时钟回拨，系统稳定的情况下，不存在主键碰撞的情况。</p>
<h3 id="加餐：关于codePoint"><a href="#加餐：关于codePoint" class="headerlink" title="加餐：关于codePoint"></a>加餐：关于codePoint</h3><p>我们之所以将主机名称转为CodePoint并叠加各个字符的CodePoint值，原因在于Unicode中每个字符的codePoint值是不同的，因此我们可以确定不同的主机名的CodePoint值也是不同的，因此可以根据该CodePoint的值去做机器节点的取模计算。</p>
<p>首先了解下什么是CodePoint，CodePoint(中文叫代码点). <a href="http://en.wikipedia.org/wiki/Code_point" target="_blank" rel="external">wiki上关于CodePoint的解释</a></p>
<p>CodePoint不同于pointCode, 前者是字符编码的术语。后者更类似IP地址，用于标志网络结点地址，<a href="http://en.wikipedia.org/wiki/Point_code" target="_blank" rel="external">wiki上关于PointCode的解释</a>。</p>
<p>ASCII字符集由于使用7bit表示字符，因此有128个CodePoint.</p>
<p>Extended ASCII字符集（扩展ASCII字符集）使用了8bit表示字符，因此有256个CodePoint.</p>
<p>而最新版Unicode6.2则拥有0x0~0x10FFFF个CodePoint. 总数可以达到1,114,112个，而目前全球只使用了110,182个来表示全世界所有语言的字符。这里可以看到Unicode的强大之处了，它真正做到了统一编码。</p>
<p>我们可以认为CodePoint就是不同字符集用来表示字符的所有整数的范围，且起点都是0.</p>
<h4 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h4><p>这里以一个实例进行讲解，准备这样一个字符串：<strong>snowalker朝闻道夕死可矣</strong></p>
<p>解析这个字符串每个字符的codePoint并叠加，代码如下：</p>
<pre><code>String snowalker = &quot;snowalker朝闻道夕死可矣&quot;;
int [] snowalkerCodePoints = StringUtils.toCodePoints(snowalker);

long sum = 0;
for (int i = 0; i &lt; snowalkerCodePoints.length; i++) {
    sum += snowalkerCodePoints[i];
    System.out.println(&quot;i=&quot; + i + &quot;--snowalkerCodePoints[&quot; + i + &quot;]=&quot; + snowalkerCodePoints[i]);
}
System.out.println(&quot;sum=&quot; + sum);

long sum2 = 0;
for (int i = 0; i &lt; snowalkerCodePoints.length; i++) {
    sum2 += snowalkerCodePoints[i];
    System.out.println(&quot;原生方式--i=&quot; + i + &quot;--snowalkerCodePoints[&quot; + i + &quot;]=&quot; + snowalker.codePointAt(i));
}

System.out.println(&quot;sum2=&quot; + sum2);
</code></pre><p>两种方式，分别为org.apache.commons.lang3.StringUtils.toCodePoints(String string) 以及 java.lang.String.codePointAt(int index)。</p>
<p>org.apache.commons.lang3.StringUtils.toCodePoints(String string)解析字符串后返回一个codePoint数组，遍历数组并叠加。</p>
<p>java.lang.String.codePointAt(int index)从字符串的起始下标开始到结束下标为止，遍历字符串的每个元素的codePoint并叠加。</p>
<p>运行程序，控制台打印如下：</p>
<pre><code>i=0--snowalkerCodePoints[0]=115
i=1--snowalkerCodePoints[1]=110
i=2--snowalkerCodePoints[2]=111
i=3--snowalkerCodePoints[3]=119
i=4--snowalkerCodePoints[4]=97
i=5--snowalkerCodePoints[5]=108
i=6--snowalkerCodePoints[6]=107
i=7--snowalkerCodePoints[7]=101
i=8--snowalkerCodePoints[8]=114
i=9--snowalkerCodePoints[9]=26397
i=10--snowalkerCodePoints[10]=38395
i=11--snowalkerCodePoints[11]=36947
i=12--snowalkerCodePoints[12]=22805
i=13--snowalkerCodePoints[13]=27515
i=14--snowalkerCodePoints[14]=21487
i=15--snowalkerCodePoints[15]=30691
sum=205219

原生方式--i=0--snowalkerCodePoints[0]=115
原生方式--i=1--snowalkerCodePoints[1]=110
原生方式--i=2--snowalkerCodePoints[2]=111
原生方式--i=3--snowalkerCodePoints[3]=119
原生方式--i=4--snowalkerCodePoints[4]=97
原生方式--i=5--snowalkerCodePoints[5]=108
原生方式--i=6--snowalkerCodePoints[6]=107
原生方式--i=7--snowalkerCodePoints[7]=101
原生方式--i=8--snowalkerCodePoints[8]=114
原生方式--i=9--snowalkerCodePoints[9]=26397
原生方式--i=10--snowalkerCodePoints[10]=38395
原生方式--i=11--snowalkerCodePoints[11]=36947
原生方式--i=12--snowalkerCodePoints[12]=22805
原生方式--i=13--snowalkerCodePoints[13]=27515
原生方式--i=14--snowalkerCodePoints[14]=21487
原生方式--i=15--snowalkerCodePoints[15]=30691
sum2=205219
</code></pre><p>可以看到，两种方式获取到的unicode的codePoint是相同的，通过这些方式我们就可以完成很多需求，如：本文中我们就是通过这种方式去解析主机名并转换为集群节点id。也可以通过这个方法，进行分片算法的开发，思路为：遍历主键的所有元素，叠加元素的codePoint并对库表取模，进行数据的分片。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><blockquote>
<p>到这里，我们就完成了自定义分布式主键的自定义操作，详细的代码请访问：</p>
<p><a href="https://github.com/TaXueWWL/snowalker-shardingjdbc-demo" target="_blank" rel="external">项目地址：snowalker-shardingjdbc-demo</a></p>
</blockquote>
<p>在本文中，我们分析了多种分布式主键的生成策略及其优缺点，最终选择了Redis作为序列的生成器。并基于Redis序列生成器开发了可读性更好的主键生成工具，在接下来的文章中，我将使用该主键生成器，配合Sharding-JDBC的自定义分库分表策略，将Sharding-JDBC的使用更加推向实战化。希望本文的思路能够对读者开发自己的主键生成组件有所启发。</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文是 “跟我学Sharding-JDBC” 系列的第三篇，我将带领读者一起了解下Sharding-JDBC的分布式主键，并实现业务性更强的自定义主键。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先了解下，什么是分布式主键。&lt;/p&gt;
&lt;p&gt;传统的关系型数据库，如MySQL中，数据库本身自带自增主键生成机制，但在分布式环境下，由于分库分表导致数据水平拆分后无法使用单表自增主键，因此我们需要一种全局唯一id生成策略作为分布式主键。&lt;/p&gt;
&lt;p&gt;当前业界已经有不少成熟的方案能够解决分布式主键的生成问题，如：UUID、SnoWflake算法（Twitter）、Leaf算法（美团点评）等。&lt;/p&gt;
    
    </summary>
    
      <category term="Sharding-JDBC" scheme="http://wuwenliang.net/categories/Sharding-JDBC/"/>
    
    
      <category term="Sharding-JDBC" scheme="http://wuwenliang.net/tags/Sharding-JDBC/"/>
    
  </entry>
  
  <entry>
    <title>我说云原生之容器化与应用无状态</title>
    <link href="http://wuwenliang.net/2019/03/18/%E6%88%91%E8%AF%B4%E4%BA%91%E5%8E%9F%E7%94%9F%E4%B9%8B%E5%AE%B9%E5%99%A8%E5%8C%96%E4%B8%8E%E5%BA%94%E7%94%A8%E6%97%A0%E7%8A%B6%E6%80%81/"/>
    <id>http://wuwenliang.net/2019/03/18/我说云原生之容器化与应用无状态/</id>
    <published>2019-03-18T07:48:58.000Z</published>
    <updated>2019-03-21T09:02:25.588Z</updated>
    
    <content type="html"><![CDATA[<p>“云计算”的概念从提出到现在已经过了十多年，经过了大量的实践之后早已不再是阳春白雪般不接地气的抽象理论。</p>
<p>随着微服务的提出到落地，分布式领域中又诞生了新的基于云的理论–“云原生（Cloud Native）”。</p>
<blockquote>
<p>“云原生”的概念由来自Pivotal的Matt Stine于2013年首次提出，被一直延续使用至今……(它涵盖的)内容非常多，包括<strong>DevOps</strong>、<strong>持续交付</strong>、<strong>微服务</strong>、<strong>敏捷基础设施</strong>以及<strong>12要素</strong>等几大主题。不但包括根据业务能力对公司进行文化、组织架构的重组与建设，也包括方法论与原则，还有具体的操作工具。    –《云原生技术架构实践》</p>
</blockquote>
<p>本文，我将主要介绍云原生的12要素，并着重讲解云原生中关于微服务的主题中的<strong>容器化与应用无状态</strong>的特性。</p>
<a id="more"></a>
<h2 id="什么是“12要素”"><a href="#什么是“12要素”" class="headerlink" title="什么是“12要素”"></a>什么是“12要素”</h2><blockquote>
<p>“12要素”（The Twelve-Factor App）, 起初是由Heroku的工程师整理的。它较为贴切的描述了软件应用的原型，并且解释了为何使用原生云应用架构的原因。</p>
</blockquote>
<p>这里，我将12要素的特点及解释通过表格的方式进行呈现。</p>
<table>
<thead>
<tr>
<th style="text-align:left">序号</th>
<th style="text-align:left">要素</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left">基准代码</td>
<td style="text-align:left">一份基准代码，多份部署</td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:left">依赖</td>
<td style="text-align:left">不隐式依赖系统级类库，应当通过依赖清单显式声明依赖关系</td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td style="text-align:left">配置</td>
<td style="text-align:left">通过环境变量/分布式配置中心等策略将配置排除在代码之外</td>
</tr>
<tr>
<td style="text-align:left">4</td>
<td style="text-align:left">后端服务</td>
<td style="text-align:left">将后端资源同等的看做附加资源，不用区分远程还是本地</td>
</tr>
<tr>
<td style="text-align:left">5</td>
<td style="text-align:left">构建、发布、运行</td>
<td style="text-align:left">应用应当严格区分构建、发布、运行三个阶段</td>
</tr>
<tr>
<td style="text-align:left">6</td>
<td style="text-align:left">进程</td>
<td style="text-align:left">应用进程必须<strong>无状态</strong>且<strong>无共享</strong>，必要的状态都需要被服务化到后端服务（如：缓存、对象存储中）；面向失败进行设计</td>
</tr>
<tr>
<td style="text-align:left">7</td>
<td style="text-align:left">端口绑定</td>
<td style="text-align:left">通过端口绑定提供服务，尽量避免通过本地文件或者进程来通信，服务间通过服务发现而服务</td>
</tr>
<tr>
<td style="text-align:left">8</td>
<td style="text-align:left">并发</td>
<td style="text-align:left">将进程看做一等公民，就可以通过水平扩展应用程序来实现并发性，通过进程模型进行扩展，即可具备无共享，水平分区等特性</td>
</tr>
<tr>
<td style="text-align:left">9</td>
<td style="text-align:left">易处理</td>
<td style="text-align:left">应用具备快速启动及优雅终止的健壮特性，应用架构设计能够支持随时销毁的特点。允许系统进行快速弹性扩缩容，快速改变部署和及时故障恢复的特性。</td>
</tr>
<tr>
<td style="text-align:left">10</td>
<td style="text-align:left">环境等价</td>
<td style="text-align:left">尽可能保持开发、测试、预发、线上环境的一致性</td>
</tr>
<tr>
<td style="text-align:left">11</td>
<td style="text-align:left">日志</td>
<td style="text-align:left">将日志作为事件流，并作为数据源，通过集中式的日志服务，执行日志收集、聚合、索引及分析等操作</td>
</tr>
<tr>
<td style="text-align:left">12</td>
<td style="text-align:left">管理进程</td>
<td style="text-align:left">后台的管理任务当作一次性进程运行，如：Kubernates中的Pod资源或者docker exec，能够随其他应用程序一同发布或在出现异常的情况需要诊断时，通过该一次性程序进行诊断管理等操作</td>
</tr>
</tbody>
</table>
<p>上述的12个特性基本上涵盖了云原生应用的特点，其中2、3、4、6、9、10等几点中，不约而同的提到了 <strong>应用无状态</strong>及<strong>无共享</strong>。</p>
<p>如果应用具有无状态，无共享的特点，则应用天然可扩展，没有对环境的依赖，可以快速的拉起或者销毁一个进程；可以在流量激增时分钟级，甚至秒级对集群进行扩容，使得我们的应用具备高可用的特性。</p>
<p>在传统的应用开发及部署过程中，我们的应用程序与环境是强耦合的，配置信息写在配置文件中，对于外部的依赖常常通过ip进行强指定，类似这样的配置方式就是将状态维护在了应用本地，集群内的每一个节点在实际环境中就很可能出现状态的不一致。当需要进行应用集群的迁移、扩缩容时就倍加痛苦。</p>
<p>因此直接通过物理机/虚拟机的方式对应用进行部署，并不能满足应用无状态的特点，也就是说这种方式开发的应用并不是云原生的。</p>
<p>那么，有没有一种方式能够较为全面的解决传统实体机/虚拟机部署应用的痛点呢？</p>
<p>容器技术就是我们的福音。</p>
<h2 id="容器化与无状态"><a href="#容器化与无状态" class="headerlink" title="容器化与无状态"></a>容器化与无状态</h2><p>事实上，任何应用都是有状态的，状态被存储在数据库、缓存、文件或其他形式的存储中。任何需要跨操作使用的状态变化都必须回写到存储中。</p>
<p>传统的开发、部署方式中，我们是将状态写在宿主机的内存、磁盘、文件中，这样就很容易出现跨节点之间的状态不一致的问题。</p>
<p>让我们换个方式，如果我们能够将程序的行为与数据分隔开，那么我们应用程序的组件是可以做到无状态的，只需要在它运行时动态的获取到数据即可。而容器化的目的之一就是将我们开发的程序组件与组件操作的数据进行隔离，从而达到无状态的目的。</p>
<p>这里先对应用程序可能维持的几种状态做一下枚举：</p>
<ol>
<li>持久状态</li>
<li>配置状态</li>
<li>会话状态   </li>
<li>网络连接状态  </li>
<li>集群状态等  </li>
</ol>
<h3 id="持久状态"><a href="#持久状态" class="headerlink" title="持久状态"></a>持久状态</h3><p>首先说一下如何隔离持久状态。</p>
<p>一般情况下，我们都会将数据持久化到数据库中，如果每个容器都带一个数据库的话，它将会是有状态的，并使系统故障的范围更大。如果出现应用程序实例或应用程序崩溃，可能会影响数据库。另一方面，如果容器down机重启或者集群扩缩容，那么数据库中的数据就会丢失，很不利于维护。</p>
<p>解决的方法很简单，只需要让容器集群操作同一个外部数据源即可，这里的数据源可以是对象存储，也可以是关系型数据库。这样，对数据库进行主从复制，也不需要跨网络层进行，更利于DBA对数据库进行维护。</p>
<p>这样我们就能保证每个容器均能读取到同一个数据源的全量数据。至于连接信息的配置，尽量采用域名或者环境变量注入的方式进行，不建议通过ip进行配置。详细的原因将会在下文展开。</p>
<p>PS: 一般情况下，我们只对应用层的组件容器化，对于类似MySQL这样的关系存储，建议还是采用物理部署或者直接购买云资源的方式进行部署，不建议进行容器化。对这个问题，可以看这篇文章：<a href="https://studygolang.com/articles/9436" target="_blank" rel="external">数据库不适合Docker及容器化的7大原因</a>，笔者对其中的大部分观点持赞同态度（软件开发没有银弹）。</p>
<h3 id="配置状态"><a href="#配置状态" class="headerlink" title="配置状态"></a>配置状态</h3><p>关于配置，尤其是分布式配置，可以展开说一天一夜，这里我们只对如何进行配置的无状态这一问题进行描述。</p>
<p>配置，一般分为系统配置和应用配置，进一步又可以分为可变配置和不可变配置。</p>
<h4 id="全局配置且配置可变"><a href="#全局配置且配置可变" class="headerlink" title="全局配置且配置可变"></a>全局配置且配置可变</h4><p>对于系统配置，也就是全局配置，集群内的每一个容器均使用相同的值，因此建议通过docker容器的-e环境变量的方式配置，如：</p>
<pre><code>docker run -d  --name devops-manage-ui -m 4g -p 8081:8081 \
            -e db_username=shardingtest \
            ......省略......
</code></pre><p>如果采用了Kubernates作为容器调度系统，那么可以通过values.yaml配置文件结合helm进行配置的设置等操作，values.yaml内容如下：</p>
<pre><code>secret:
  # 注意key不要使用减号&apos;-&apos;连接单词,如果需要一定使用下划线&apos;_&apos;
  # 因为模板会识别key名称，自动并将key对应的值映射到容器中与key名称相同的环境变量
  mysql_db_username: &apos;shardingtest&apos;
</code></pre><p>这里以数据库连接用户名的配置作为示例，一般而言，数据库连接的用户名在同一个应用集群内是统一的，因此我们通过系统环境变量进行配置是可行的。</p>
<h4 id="全局配置且配置不可变"><a href="#全局配置且配置不可变" class="headerlink" title="全局配置且配置不可变"></a>全局配置且配置不可变</h4><p>当然，我这里是从便于统一管理的角度出发的，如果你能保证某个配置是长期不变的，那么将其写死在程序内部，也是能够接受的。这样能够减少配置的数量，对于长期的维护有好处。我本人也同意“少既是好”的观点。</p>
<h4 id="应用配置且配置可变"><a href="#应用配置且配置可变" class="headerlink" title="应用配置且配置可变"></a>应用配置且配置可变</h4><p>对于应用层的可变配置，如果变更不频繁，如：测试环境的开关等配置，在正式上线就不会轻易更改，也可以配置在容器的环境变量中。方法与上述相同，即通过容器的-e或者K8s的values.yaml或者配置集等方式设置。</p>
<p>如果变更很频繁，比如：日志级别、流量阈值、抽奖开关等需要经常变更的配置，配置在环境变量中就不是一种合适的方式了。</p>
<p>原因在于环境变量中的值一旦设置，在容器的生命周期内就不能改变了，如果要更改只能重启应用，而这对于我们的业务的可用性而言是不能容忍的。</p>
<p>对于这个问题，我们一般会采用 <strong>分布式配置中心</strong> 来解决。</p>
<p>应用层通过连接统一的配置中心，将配置的变更交给配置中心。对于配置的修改，无需重启应用，配置能够动态生效，减少了运维成本和压力。业务人员对于配置的变更能够实时的推送至应用程序，应用程序本身也可以定时拉取配置，保证变更能够及时的反馈到应用内。</p>
<p>业界已经有成熟的配置中心实现，如：Apollo、Nacos、Diamond、Qconf等。</p>
<p>关于配置中心，我之前写过相关的文章，感兴趣的读者可以去阅读：</p>
<table>
<thead>
<tr>
<th style="text-align:left">配置中心文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/12/05/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83-%E5%8D%95%E6%9C%BA%E6%A8%A1%E5%BC%8F/">自己写分布式配置中心[上篇]-单机模式</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/02/22/springboot2-x%E6%95%B4%E5%90%88nacos%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E9%85%8D%E7%BD%AE%E8%8E%B7%E5%8F%96%E5%8F%8A%E5%88%B7%E6%96%B0/">springboot2.x整合nacos配置服务实现配置获取及刷新</a></td>
</tr>
</tbody>
</table>
<h4 id="应用配置且配置不可变"><a href="#应用配置且配置不可变" class="headerlink" title="应用配置且配置不可变"></a>应用配置且配置不可变</h4><p>对于应用层的不可变配置，也可以同系统级配置一样，设置到环境变量中。</p>
<p>根据前文中 <strong>“12要素”</strong> 提到的第三点–配置要素，</p>
<blockquote>
<p>通过环境变量/分布式配置中心等策略将配置排除在代码之外</p>
</blockquote>
<p>对于应用层的不可变配置，从同一管理的角度而言，放在环境变量中确实有助于代码逻辑与配置数据的分离。从而保证应用程序组件的无状态特性。</p>
<h3 id="会话状态"><a href="#会话状态" class="headerlink" title="会话状态"></a>会话状态</h3><p>web开发中，难免会涉及到用户的会话保持。</p>
<p>会话保持技术当前也很成熟了，如：进程内会话、Nginx等反向代理实现的会话粘滞以及分布式会话技术等。</p>
<p>首先是应用内会话保持，如果采用了该机制，集群内一定会有进程间数据不一致的情况出现。</p>
<p>Nginx等反向代理可以配置应用层实现会话粘滞，能够保证对于同一个会话id，每次请求都可以触达同一个后端服务。但是这也存在风险，试想，如果某个后端服务down机，那么也会出现进程间数据的不一致现象。</p>
<p>那采用何种方式才能既可以保持会话，又能让应用本身无状态呢？听起来很矛盾，其实解决方法还是蛮好理解的，那就是引入第三方存储机制，应用层通过该三方存储（如：Redis集群、Memcached集群等）进行进程间会话共享。</p>
<p>这也就是所谓的“分布式session共享”，在成熟的框架中如：Spring/Spring Boot中已经有现成的解决方案，名为：<strong>spring-session-data-redis</strong>，它集成了Spring Session模块，看源码能够很清晰的发现其对HttpSession进行了包装，遵循servlet规范，使用相同的方式获取session，对应用代码无侵入而且对开发者的使用是透明的。通过包装增强，将会话数据保存在Redis中。从而实现了跨进程的会话共享。</p>
<p>在文章的附录部分，我将详细的展示如何基于Spring Boot 2.1.2 Release进行 spring-session-data-redis 的整合，实现会话共享。</p>
<h3 id="网络连接状态"><a href="#网络连接状态" class="headerlink" title="网络连接状态"></a>网络连接状态</h3><p>传统的开发部署中，我们常常需要进行网络通信，以HTTP通信为例，我们需要制定目标的ip以及端口。</p>
<p>端口的话一般都是固定的，但是通过写死ip的方式进行调用也不利于无状态化的实现。如果远程更换了ip，那么通信链路就会断开，影响业务的正常运行。</p>
<p>因此，想要实现网络连接的无状态，更好的方法是采用域名的方式进行通信。</p>
<p>对于远程服务，直接通过域名调用即可，域名一般不会频繁变更，因此配置到环境变量中即可。</p>
<p>对于同一网络中的服务间的调用，可以通过架设内网DNS服务器，为每个应用分配一个唯一的名字，然后通过该域名进行通信，这样对于应用的横向扩展很有帮助。</p>
<p>这一思路在Kubernates中展现的淋漓尽致。</p>
<p>在Kubernates中，应用间通过service名进行通信，它是通过一个名为 <strong>kube-dns</strong> 的组件实现的。</p>
<p>Kubernates通过kube-dns进行服务发现，将Service的名称当做域名注册到kube-dns中，通过Service的名称即可访问其提供的服务。</p>
<p>如果你采用了Kubernates进行容器调度和管理，那么恭喜你，你离云原生其实很近。</p>
<h3 id="集群状态"><a href="#集群状态" class="headerlink" title="集群状态"></a>集群状态</h3><p>至于集群状态的维护，通常我们只需要将状态维护在一个三方组件，如：dubbo采用Zk作为注册中心、kafka采用Zk作为NameServer等 均是将集群状态维护给了三方，应用间不需要关心彼此的存活状态，这样只要保证三方组件的高可用，我们就能够做到对应用集群的生命周期的管理甚至进行服务治理了。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>我们提到了 <strong>“12要素”</strong> ，还讲到了如何保持上文提到的五种状态的无状态性，他们都是实现云原生的重要特征。</p>
<p>如果一个应用集群没有做到无状态，那么它一定不是云原生的，无状态的应用集群能够像“云”一样作为一个整体对外提供服务而无需关心其内部细节。</p>
<p>对无状态的一个更加现实的需求是：如果我们做到了应用的无状态，那么就会隔离环境的差异，做到一份代码，到处部署。变化都是配置，配置都在代码之外。无论是对于业务的扩展性还是运维的运维的维护量，开发的复杂度都会有明显的改善。</p>
<h2 id="实践无状态"><a href="#实践无状态" class="headerlink" title="实践无状态"></a>实践无状态</h2><p>说了这么多概念，那么如何做才能尽量的实现无状态呢？</p>
<p>首先，请拥抱容器，容器天然是为云而存在的，如果不用容器，我们的无状态之路会走的很辛苦。</p>
<p>容器的实现中，我推荐你选择成熟的Docker容器化技术，入门Docker可以看这个教程<br><a href="http://www.runoob.com/docker/docker-architecture.html" target="_blank" rel="external">docker-architecture</a></p>
<p>我假定你对Docker有基本的了解，能够编写简单的Dockerfile，完成镜像的打包运行停止等操作。</p>
<h3 id="SpringBoot项目中配置环境变量"><a href="#SpringBoot项目中配置环境变量" class="headerlink" title="SpringBoot项目中配置环境变量"></a>SpringBoot项目中配置环境变量</h3><p>这里我以连接数据库的配置为例进行讲解，项目基于Spring Boot 2.1.2 Release进行构建。</p>
<p>首先我们指定项目启动时，使用application-prod.properties配置。</p>
<ol>
<li><p>在application.properties中指定激活的配置为prod</p>
<pre><code>spring.profiles.active=dev
</code></pre></li>
<li><p>在application-prod.properties中配置数据库连接参数，使用 <strong>${}</strong> 方式进行环境变量的注入，大括号内为环境变量的参数值</p>
<pre><code>spring.datasource.url=${db_url}
spring.datasource.username=${db_username}
spring.datasource.password=${db_password}
</code></pre></li>
<li><p>在项目的根路径下放置 <strong>run.sh</strong>，用于docker容器启动时触发该脚本从而启动应用，内容为：</p>
<pre><code>#!/bin/bash
java -Xmx3000m -Xms3000m -Dspring.profiles.active=prod -jar /app/demo.jar
</code></pre></li>
<li><p>编写Dockerfile并放置在项目的根路径下，Dockerfile内容为</p>
<pre><code># 基础镜像
FROM docker.io/fiadliel/java8-jre   
# 创建jar包放置路径
RUN mkdir /app
# 将打包后的jar包复制到镜像/app下
ADD ./target/demo.jar /app/
# 复制启动脚本到可执行jar的同一级目录下并给予可执行权限
COPY ./run.sh /app/run.sh
RUN chmod u+x /app/run.sh
# WORKDIR指令用于指定容器的一个目录，容器启动时执行的命令会在该目录下执行，
# 相当于设置了容器的工作目录
WORKDIR /app
# 执行启动脚本
CMD [ &quot;/app/run.sh&quot; ]
# 暴露端口
EXPOSE 8080
</code></pre></li>
<li><p>在项目的pom.xml中添加docker打包支持</p>
</li>
</ol>
<pre><code>&lt;properties&gt;
        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;

        &lt;maven.repostory.host&gt;这里填写你的maven私服域名&lt;/maven.repostory.host&gt;
        &lt;docker.repostory&gt;这里填写你的docker仓库域名&lt;/docker.repostory&gt;
        &lt;docker.registry.name&gt;这里填写你的镜像仓库命名空间名&lt;/docker.registry.name&gt;
&lt;/properties&gt;

&lt;build&gt;
    &lt;finalName&gt;${project.name}&lt;/finalName&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
        &lt;/plugin&gt;
        &lt;!--docker配置--&gt;
        &lt;plugin&gt;
            &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt;
            &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;

            &lt;executions&gt;
                &lt;execution&gt;
                    &lt;id&gt;clean-images&lt;/id&gt;
                    &lt;phase&gt;deploy&lt;/phase&gt;
                    &lt;goals&gt;
                        &lt;goal&gt;exec&lt;/goal&gt;
                    &lt;/goals&gt;
                    &lt;configuration&gt;
                        &lt;workingDirectory&gt;${basedir}&lt;/workingDirectory&gt;
                        &lt;executable&gt;sh&lt;/executable&gt;
                        &lt;arguments&gt;
                            &lt;argument&gt;clean-images.sh&lt;/argument&gt;
                            &lt;argument&gt;${docker.repostory}/${docker.registry.name}/${project.name}:${project.version}&lt;/argument&gt;
                        &lt;/arguments&gt;
                    &lt;/configuration&gt;
                &lt;/execution&gt;

                &lt;execution&gt;
                    &lt;id&gt;build-images&lt;/id&gt;
                    &lt;phase&gt;deploy&lt;/phase&gt;
                    &lt;goals&gt;
                        &lt;goal&gt;exec&lt;/goal&gt;
                    &lt;/goals&gt;
                    &lt;configuration&gt;
                        &lt;workingDirectory&gt;${basedir}&lt;/workingDirectory&gt;
                        &lt;executable&gt;docker&lt;/executable&gt;
                        &lt;arguments&gt;
                            &lt;argument&gt;build&lt;/argument&gt;
                            &lt;argument&gt;-t&lt;/argument&gt;
                            &lt;argument&gt;${docker.repostory}/${docker.registry.name}/${project.name}:${project.version}&lt;/argument&gt;
                            &lt;argument&gt;.&lt;/argument&gt;
                        &lt;/arguments&gt;
                    &lt;/configuration&gt;
                &lt;/execution&gt;

                &lt;execution&gt;
                    &lt;id&gt;push-images&lt;/id&gt;
                    &lt;phase&gt;deploy&lt;/phase&gt;
                    &lt;goals&gt;
                        &lt;goal&gt;exec&lt;/goal&gt;
                    &lt;/goals&gt;
                    &lt;configuration&gt;
                        &lt;executable&gt;docker&lt;/executable&gt;
                        &lt;arguments&gt;
                            &lt;argument&gt;push&lt;/argument&gt;
                            &lt;argument&gt;${docker.repostory}/${docker.registry.name}/${project.name}:${project.version}&lt;/argument&gt;
                        &lt;/arguments&gt;
                    &lt;/configuration&gt;
                &lt;/execution&gt;
            &lt;/executions&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;
</code></pre><ol>
<li><p>打包项目，上传镜像至镜像仓库（如何搭建Harbor仓库，请看这篇 <a href="https://www.cnblogs.com/netsa/p/8124708.html" target="_blank" rel="external">开源仓库Harbor搭建及配置过程</a>）</p>
</li>
<li><p>在服务端运行docker run命令，并通过 <strong>-e</strong> 参数指定环境变量的值，注入容器中。</p>
<pre><code>docker run -d -v /log/snowalker/:/log --name demo \
            -m 4g \
            -p 8081:8081 \
            -e db_url=&quot;jdbc:mysql://127.0.0.1:3306/shardingtest_00?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=GMT%2B8&quot; \
            -e db_username=shardingtest \
            -e db_password=shardingtest \
            snowalker.io:5000/test/demo:1.0.1
</code></pre></li>
</ol>
<p>为了查看日志方便，我在启动时将业务日志挂载至宿主机的 /log下。</p>
<p>进入/log 目录，查看启动日志如下，表明数据库连接正常，启动完成。</p>
<pre><code>2019-03-19 10:22:59.782 [main] INFO org.springframework.boot.StartupInfoLogger.logStarted[StartupInfoLogger.java:59] - 
Started Application in 5.509 seconds (JVM running for 7.498)
2019-03-19 10:22:59.784 [main] INFO com.snowalker.devops.manage.ui.Application.main[Application.java:18] - 
[devops-manage-ui] BOOT SUCCESS
</code></pre><p>到此，我们就完成了基于SpringBoot的配置提取到环境变量的操作，并通过容器化的方式实现了环境变量参数的运行时注入操作。</p>
<p>我们可以随产品需求随时扩缩容集群的规模，无需担心配置的变更对应用启动的影响。</p>
<h3 id="Spring-Boot-2-1-2-Release-集成-spring-session-data-redis-实现分布式会话"><a href="#Spring-Boot-2-1-2-Release-集成-spring-session-data-redis-实现分布式会话" class="headerlink" title="Spring Boot 2.1.2 Release 集成 spring-session-data-redis 实现分布式会话"></a>Spring Boot 2.1.2 Release 集成 spring-session-data-redis 实现分布式会话</h3><p>这里总结下如何基于Spring Boot 2.1.2 Release 集成 spring-session-data-redis 实现分布式会话。</p>
<ol>
<li><p>首先引入spring-session-data-redis依赖，与Spring Boot版本保持一致即可，这里使用 2.1.2 Release</p>
<pre><code>&lt;!--框架依赖包--&gt;
&lt;parent&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
    &lt;version&gt;2.1.2.RELEASE&lt;/version&gt;
&lt;/parent&gt;

&lt;!--spring会话同步--&gt;
&lt;!-- https://mvnrepository.com/artifact/org.springframework.session/spring-session-data-redis --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;
    &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre></li>
</ol>
<p>由于会话基于Redis存储，因此需要引入Redis依赖如下，版本依旧与Spring Boot保持一致</p>
<pre><code>&lt;!--redis缓存支持--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><ol>
<li><p>编辑application.properties配置文件，插入Redis及session相关的配置如下</p>
<pre><code>###################################################################
#
#               session共享配置
#
###################################################################
spring.redis.host=127.0.0.1
spring.redis.port=6379
spring.redis.timeout=10000
spring.redis.password=123456
spring.redis.jedis.pool.max-active=8
spring.redis.jedis.pool.max-wait=-1
spring.redis.jedis.pool.max-idle=8
spring.redis.jedis.pool.min-idle=0
spring.redis.database=1
# session 存储类型为 Redis
spring.session.store-type=redis
</code></pre></li>
</ol>
<p>上述Redis为单机配置，对于集群和哨兵模式的配置如下</p>
<pre><code># （普通集群，不使用则不用开启）在群集中执行命令时要遵循的最大重定向数目。
# spring.redis.cluster.max-redirects=
# （普通集群，不使用则不用开启）以逗号分隔的“主机:端口”对列表进行引导。
# spring.redis.cluster.nodes=

#哨兵模式
# （哨兵模式，不使用则不用开启）Redis服务器的名称。
spring.redis.sentinel.master=
# （哨兵模式，不使用则不用开启）主机：端口对的逗号分隔列表。 
spring.redis.sentinel.nodes=
</code></pre><ol>
<li><p>在启动类上添加注解开启分布式session支持</p>
<pre><code>//开启redis session支持,并配置session过期时间，时间单位秒
@EnableRedisHttpSession(maxInactiveIntervalInSeconds= 1800) 
@SpringBootApplication
@Log4j2
public class Application extends WebMvcConfigurerAdapter {

    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
        log.info(&quot;[devops-manage-ui] BOOT SUCCESS&quot;);
    }
}
</code></pre></li>
</ol>
<p>到这里，我们就完成了Spring Boot 2.1.2 Release对spring-session-data-redis分布式会话实现的整合。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>云原生是一个大主题，涵盖了研发、运维、项目管理、组织架构、基础设施等多方面的要素。本文只是其中的冰山一角，希望本文能够成为读者朋友们了解云原生的一个指引。</p>
<p>纸上得来终觉浅，绝知此事要躬行。关于云原生的奥秘，我们还有很多路要走，我愿与你共同探秘，攀向技术山峰。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;“云计算”的概念从提出到现在已经过了十多年，经过了大量的实践之后早已不再是阳春白雪般不接地气的抽象理论。&lt;/p&gt;
&lt;p&gt;随着微服务的提出到落地，分布式领域中又诞生了新的基于云的理论–“云原生（Cloud Native）”。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“云原生”的概念由来自Pivotal的Matt Stine于2013年首次提出，被一直延续使用至今……(它涵盖的)内容非常多，包括&lt;strong&gt;DevOps&lt;/strong&gt;、&lt;strong&gt;持续交付&lt;/strong&gt;、&lt;strong&gt;微服务&lt;/strong&gt;、&lt;strong&gt;敏捷基础设施&lt;/strong&gt;以及&lt;strong&gt;12要素&lt;/strong&gt;等几大主题。不但包括根据业务能力对公司进行文化、组织架构的重组与建设，也包括方法论与原则，还有具体的操作工具。    –《云原生技术架构实践》&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文，我将主要介绍云原生的12要素，并着重讲解云原生中关于微服务的主题中的&lt;strong&gt;容器化与应用无状态&lt;/strong&gt;的特性。&lt;/p&gt;
    
    </summary>
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/categories/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/tags/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>跟我学shardingjdbc之使用jasypt加密数据库连接密码</title>
    <link href="http://wuwenliang.net/2019/03/14/%E8%B7%9F%E6%88%91%E5%AD%A6shardingjdbc%E4%B9%8B%E4%BD%BF%E7%94%A8jasypt%E5%8A%A0%E5%AF%86%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E5%AF%86%E7%A0%81/"/>
    <id>http://wuwenliang.net/2019/03/14/跟我学shardingjdbc之使用jasypt加密数据库连接密码/</id>
    <published>2019-03-14T05:28:53.000Z</published>
    <updated>2019-03-14T06:45:35.908Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>生产上我们对数据库连接密码一般都是配置密文，从源头上尽可能地保证安全性。</p>
</blockquote>
<p>本文中，我将介绍一款在Spring Boot中使用的自动加解密工具，对数据库连接密码进行加密操作。</p>
<p>该工具名为 <strong>jasypt-spring-boot-starter</strong> ，能够做到在Spring Boot 加载属性之前，对属性进行进行加解密操作。它使用对称加密方式进行加解密。</p>
<p>项目的Github为 <a href="https://github.com/ulisesbocchio/jasypt-spring-boot" target="_blank" rel="external">jasypt-spring-boot</a>, 感兴趣的可以去点个star支持下。</p>
<p>话不多说，进入正题。</p>
<a id="more"></a>
<h2 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h2><p>还是基于我们的demo工程，首先在项目的pom.xml中引入maven依赖。</p>
<pre><code>&lt;!-- 集成数据库密码加密工具jasypt  jdk8版本--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt;
    &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;1.14&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><h2 id="加密明文密码"><a href="#加密明文密码" class="headerlink" title="加密明文密码"></a>加密明文密码</h2><p>我们编写一个加密方法对密码明文进行加密操作。代码如下（需要依赖jasypt-spring-boot-starter包）</p>
<pre><code>import org.jasypt.util.text.BasicTextEncryptor;

public class JasyptUtil {

    /**
    * 加密方法
    * @param salt 盐值
    * @param targetString 待加密字符串
    * @return 密文
    */
    public static String encrypt(String salt, String targetString) {
        BasicTextEncryptor encryptor = new BasicTextEncryptor();
        encryptor.setPassword(salt);
        return encryptor.encrypt(targetString);
    }

    /**
    * 解密方法
    * @param salt 盐值
    * @param targetString 待解密字符串
    * @return 明文
    */
    public static String decrypt(String salt,String targetString) {
        BasicTextEncryptor encryptor = new BasicTextEncryptor();
        encryptor.setPassword(salt);
        return encryptor.decrypt(targetString);
    }

    public static void main(String[] args) {
        String salt = &quot;salt&quot;;
        String password = &quot;test&quot;;
        // 进行加密操作
        String encryptString1 = encrypt(salt, password);
        // 进行解密操作
        String decryptString1 = decrypt(salt, encryptString1);
        // 输出明文和密文
        System.out.println(&quot;encryptString1=&quot;+encryptString1);
        System.out.println(&quot;decryptString1=&quot;+decryptString1);
    }
}
</code></pre><p>运行main方法，输出如下:</p>
<pre><code>encryptString1=LIGKpRXjX0FD24N9E/kTsA==
decryptString1=root
</code></pre><p>解释一下，假设我们的数据库密码明文为：root，盐值为：salt，加密后的密文为：LIGKpRXjX0FD24N9E/kTsA==</p>
<h2 id="在程序中设置密文"><a href="#在程序中设置密文" class="headerlink" title="在程序中设置密文"></a>在程序中设置密文</h2><p>上一步中我们得到了连接数据库的密码密文，打开我们应用的配置文件application.properties，修改数据库连接密码为如下格式：</p>
<pre><code>sharding.jdbc.datasource.ds0.password=ENC(LIGKpRXjX0FD24N9E/kTsA==)
</code></pre><p>通过 <strong>ENC(密文)</strong> 的方式，在程序中获取到的sharding.jdbc.datasource.ds0.password会自动转换成明文内容（root）。</p>
<p>由于我们加密的时候设置了加密的盐值，因此需要在application.properties中添加盐值，用于解密</p>
<pre><code>#加密盐值
jasypt.encryptor.password=salt
</code></pre><h2 id="启动方法上配置自动加解密"><a href="#启动方法上配置自动加解密" class="headerlink" title="启动方法上配置自动加解密"></a>启动方法上配置自动加解密</h2><p>最后我们还需要在main方法上添加注解开启自动加解密，代码如下</p>
<pre><code>@SpringBootApplication
@MapperScan(basePackages = &quot;com.snowalker.shardingjdbc.snowalker.demo.mapper&quot;)
@EnableEncryptableProperties
public class SnowalkerShardingjdbcDemoApplication {

    public static void main(String[] args) {
        SpringApplication.run(SnowalkerShardingjdbcDemoApplication.class, args);
    }

}
</code></pre><p>注解 <strong>@EnableEncryptableProperties</strong> 即是开启自动加解密的关键。</p>
<h2 id="启动应用测试"><a href="#启动应用测试" class="headerlink" title="启动应用测试"></a>启动应用测试</h2><p>运行main方法，看到日志如下，表示配置生效~</p>
<pre><code>2019-03-14 14:05:44.853  INFO 25252 --- [           main] c.u.j.encryptor.DefaultLazyEncryptor     : Encryptor config not found for property jasypt.encryptor.stringOutputType, using default value: base64
2019-03-14 14:05:46.429  INFO 25252 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-1} inited
2019-03-14 14:05:46.552  INFO 25252 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-2} inited
2019-03-14 14:05:46.693  INFO 25252 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-3} inited
2019-03-14 14:05:46.818  INFO 25252 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-4} inited
2019-03-14 14:05:47.196  INFO 25252 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService &apos;applicationTaskExecutor&apos;
2019-03-14 14:05:48.865  INFO 25252 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8091 (http) with context path &apos;&apos;
2019-03-14 14:05:48.868  INFO 25252 --- [           main] s.d.SnowalkerShardingjdbcDemoApplication : Started SnowalkerShardingjdbcDemoApplication in 6.374 seconds (JVM running for 8.048)
</code></pre><p>生产环境我们一般使用docker进行应用的部署，因此需要将数据库密码配置为环境变量，只需要修改配置文件application.properties中的密码配置如下：</p>
<pre><code># 通过ENC(密文)开启密码解密，不使用加密算法时，直接输入原始密码
sharding.jdbc.datasource.ds0.password=${mysql_db_password}
</code></pre><p>在docker容器启动时候通过-e配置环境变量，我们线上使用了Kubernates管理docker集群，只需要在helm部署文件的valus.yaml中配置环境变量。原理其实是相同的。</p>
<p>docker启动时配置方式如下：</p>
<pre><code>docker run -d -v /log/snowalker/:/log --name sharding-jdbc-demo \
           -m 4g \
           -p 8081:8081 \
           -e db00_url=&quot;jdbc:mysql://127.0.0.1:3306/db_00?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=GMT%2B8&quot; \
           -e db01_url=&quot;jdbc:mysql://127.0.0.1:3306/db_01?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=GMT%2B8&quot; \
           -e db02_url=&quot;jdbc:mysql://127.0.0.1:3306/db_02?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=GMT%2B8&quot; \
           -e db03_url=&quot;jdbc:mysql://127.0.0.1:3306/db_03?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=GMT%2B8&quot; \
           -e db_username=root \
           -e db_password=&quot;ENC(LIGKpRXjX0FD24N9E/kTsA==)&quot; \
           镜像仓库域名:5000/命名空间/sharding-jdbc-demo:1.0.1
</code></pre><p>核心配置为 </p>
<pre><code>-e db_password=&quot;ENC(LIGKpRXjX0FD24N9E/kTsA==)&quot; \
</code></pre><p>注意添加双引号，否则会报错。</p>
<p>如果使用kubernates的helm方式部署，那么只需要在values.yaml中配置密码环境变量如下：</p>
<pre><code>secret:
# 注意key不要使用减号&apos;-&apos;连接单词,如果需要一定使用下划线&apos;_&apos;
# 因为模板会识别key名称，自动并将key对应的值映射到容器中与key名称相同的环境变量上,而环境变量名称不支持减号&apos;-&apos;
# mysql
db00_url: &apos;jdbc:mysql://127.0.0.1:3306/db_00?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=GMT%2B8&apos;
db01_url: &apos;jdbc:mysql://127.0.0.1:3306/db_01?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=GMT%2B8&apos;
db02_url: &apos;jdbc:mysql://127.0.0.1:3306/db_02?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=GMT%2B8&apos;
db03_url: &apos;jdbc:mysql://127.0.0.1:3306/db_03?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=GMT%2B8&apos;
mysql_db_username: &apos;root&apos;
mysql_db_password: &apos;ENC(LIGKpRXjX0FD24N9E/kTsA==)&apos;
</code></pre><p>一定要将整个解密表达式设置到环境变量，如果appliation.properties中密码环境变量设置为如下方式则会报错</p>
<p><b><font color="red">错误的配置！</font></b></p>
<pre><code>sharding.jdbc.datasource.ds0.password=ENC(${mysql_db_password})
</code></pre><p>这种配置方式下，‘${mysql_db_password}’不会被识别为环境变量，而是普通的密码字符串，从而报错。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>到这里，我们就将数据库连接密码从明文设置为密文，我还在文章后半段讲解了如何通过环境变量设置密文到程序中。这里涉及到分布式开发下的“应用无状态”概念，在后续的文章中我会详细讲解如何开发无状态的应用。</p>
<p>接下来的文章中，我将继续带领读者对Sharding-JDBC进行深入的学习，Keep Moving。</p>
<h2 id="附录：命令行方式使用Jasypt加解密"><a href="#附录：命令行方式使用Jasypt加解密" class="headerlink" title="附录：命令行方式使用Jasypt加解密"></a>附录：命令行方式使用Jasypt加解密</h2><p>这里再介绍一种命令行下利用Jasypt加解密的方式。</p>
<h3 id="生成密文"><a href="#生成密文" class="headerlink" title="生成密文"></a>生成密文</h3><p>首先通过jasypt jar包生成密文：</p>
<pre><code>D:\repository\org\jasypt\jasypt\1.9.2&gt;
java -cp D:\repository\org\jasypt\jasypt\1.9.2\jasypt-1.9.2.jar
 org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI input=&quot;root&quot;  
 password=salt algorithm=PBEWithMD5AndDES
</code></pre><p>jasypt需要设置用于加密明文的密钥password，它会对input内容加密。解释下参数：</p>
<table>
<thead>
<tr>
<th style="text-align:left">参数</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">input</td>
<td style="text-align:left">密码原文</td>
</tr>
<tr>
<td style="text-align:left">password</td>
<td style="text-align:left">加密的盐值</td>
</tr>
<tr>
<td style="text-align:left">algorithm</td>
<td style="text-align:left">加密策略，对称加密</td>
</tr>
</tbody>
</table>
<p>命令行下执行该命令，打印如下</p>
<pre><code>----ENVIRONMENT-----------------

Runtime: Oracle Corporation Java HotSpot(TM) 64-Bit Server VM 25.181-b13

----ARGUMENTS-------------------

algorithm: PBEWithMD5AndDES
input: root
password: salt

----OUTPUT----------------------
guEfhaqV1d6LTCfhqsk6pQ==
</code></pre><p>OUTPUT打印的部分就是加密后的密文。</p>
<p>除了通过application.properties方式配置加密的盐值，我们还可以通过启动参数设置该参数，命令如下：</p>
<pre><code>java -jar sharding-jdbc-demo.jar --jasypt.encryptor.password=salt
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;生产上我们对数据库连接密码一般都是配置密文，从源头上尽可能地保证安全性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文中，我将介绍一款在Spring Boot中使用的自动加解密工具，对数据库连接密码进行加密操作。&lt;/p&gt;
&lt;p&gt;该工具名为 &lt;strong&gt;jasypt-spring-boot-starter&lt;/strong&gt; ，能够做到在Spring Boot 加载属性之前，对属性进行进行加解密操作。它使用对称加密方式进行加解密。&lt;/p&gt;
&lt;p&gt;项目的Github为 &lt;a href=&quot;https://github.com/ulisesbocchio/jasypt-spring-boot&quot;&gt;jasypt-spring-boot&lt;/a&gt;, 感兴趣的可以去点个star支持下。&lt;/p&gt;
&lt;p&gt;话不多说，进入正题。&lt;/p&gt;
    
    </summary>
    
      <category term="Sharding-JDBC" scheme="http://wuwenliang.net/categories/Sharding-JDBC/"/>
    
    
      <category term="Sharding-JDBC" scheme="http://wuwenliang.net/tags/Sharding-JDBC/"/>
    
  </entry>
  
  <entry>
    <title>跟我学shardingjdbc之shardingjdbc入门</title>
    <link href="http://wuwenliang.net/2019/03/12/%E8%B7%9F%E6%88%91%E5%AD%A6shardingjdbc%E4%B9%8Bshardingjdbc%E5%85%A5%E9%97%A8/"/>
    <id>http://wuwenliang.net/2019/03/12/跟我学shardingjdbc之shardingjdbc入门/</id>
    <published>2019-03-12T08:05:48.000Z</published>
    <updated>2019-03-13T12:28:59.746Z</updated>
    
    <content type="html"><![CDATA[<p>在上文中，我们讲解了分布式环境下的分库分表，从概念及案例上分析了何为分库分表及其优缺点。</p>
<p><a href="http://wuwenliang.net/2019/03/11/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%B9%8B%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/">我说分布式之分库分表</a></p>
<p>从本文开始我们一起学习一下如何使用当前比较成熟的分库分表框架 Sharding-JDBC 实现分库分表。</p>
<h2 id="什么是Sharding-JDBC"><a href="#什么是Sharding-JDBC" class="headerlink" title="什么是Sharding-JDBC"></a>什么是Sharding-JDBC</h2><p>Sharding-JDBC是分布式数据中间件Sharding-Sphere中的重要组成部分，官方的介绍如下：</p>
<blockquote>
<p>Sharding-Sphere是一套开源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（计划中）这3款相互独立的产品组成。他们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。</p>
</blockquote>
<p>Sharding-JDBC 是Sharding-Sphere的第一款产品，也是最接近开发者的一款分库分表中间件，很有代表性，也值得我们深入的学习与应用。</p>
<p><a href="https://shardingsphere.apache.org/document/legacy/3.x/document/cn/quick-start/" target="_blank" rel="external">Sharding-JDBC官方文档地址</a> </p>
<p>这里我贴出官方的文档地址，版本为3.x，有问题先看文档是比较直接快速准确的trouble-shooting方式。</p>
<h2 id="如何使用Sharding-JDBC3-x-实现分库分表"><a href="#如何使用Sharding-JDBC3-x-实现分库分表" class="headerlink" title="如何使用Sharding-JDBC3.x 实现分库分表"></a>如何使用Sharding-JDBC3.x 实现分库分表</h2><p>简单了解一下背景之后，我们用一个案例先把它用起来，直观地感受一下Sharding-JDBC的魅力，后续我们会对它做进一步的讲解。</p>
<p>由于目前的后端Java开发主要以Spring Boot为主，因此我将主要依据Spring Boot的2.x进行讲解。</p>
<a id="more"></a>
<h3 id="建立数据库表"><a href="#建立数据库表" class="headerlink" title="建立数据库表"></a>建立数据库表</h3><p>首先建立一个4库8表的数据库结构。数据库名为db_00–db_03，建立一个简单的订单表名为t_order_0000-t_order_0001,每个库中两张表</p>
<p>表结构比较简单，因为我们的目的是尽快的将框架用起来，太复杂的表结构容易让我们陷入业务中而偏离了我们的主旨。</p>
<p>订单表t_order的建表语句如下：</p>
<pre><code>-- ----------------------------
-- Table structure for t_order_0000
-- ----------------------------
DROP TABLE IF EXISTS `t_order_0000`;
CREATE TABLE `t_order_0000` (
`id` int(11) NOT NULL AUTO_INCREMENT,
`user_id` bigint(20) DEFAULT NULL,
`order_id` bigint(20) DEFAULT NULL,
`user_name` varchar(255) DEFAULT NULL,
PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=1239 DEFAULT CHARSET=utf8;


-- ----------------------------
-- Table structure for t_order_0001
-- ----------------------------
DROP TABLE IF EXISTS `t_order_0001`;
CREATE TABLE `t_order_0001` (
`id` int(11) NOT NULL AUTO_INCREMENT,
`user_id` bigint(20) DEFAULT NULL,
`order_id` bigint(20) DEFAULT NULL,
`user_name` varchar(255) DEFAULT NULL,
PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=1239 DEFAULT CHARSET=utf8;
</code></pre><p>在每个分库中均建立表t_order_0000，t_order_0001</p>
<p>数据库结构如下</p>
<pre><code>db_00--
      |--t_order_0000
      |--t_order_0001
db_01--
      |--t_order_0000
      |--t_order_0001
db_02--
      |--t_order_0000
      |--t_order_0001
db_03--
      |--t_order_0000
      |--t_order_0001
</code></pre><p>宏观上我们就有了8个数据节点，如下：</p>
<pre><code>db_00.t_order_0000, db_00.t_order_0001
db_01.t_order_0000, db_01.t_order_0001
db_02.t_order_0000, db_02.t_order_0001
db_03.t_order_0000, db_03.t_order_0001 
</code></pre><h3 id="建立demo工程"><a href="#建立demo工程" class="headerlink" title="建立demo工程"></a>建立demo工程</h3><p>这里直接使用IDEA的spring-boot-initializer建立了一个demo工程，工程名为snowalker-shardingjdbc-demo，文章末尾会放上demo工程的github地址。</p>
<p>工程的结构如下：</p>
<p><img src="/2019/03/12/跟我学shardingjdbc之shardingjdbc入门/./project.png" alt="project.png"></p>
<p>引入sharding-jdbc-spring-boot-starter依赖如下</p>
<pre><code>&lt;!-- sharding-sphere --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;io.shardingsphere&lt;/groupId&gt;
    &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;3.0.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>数据库访问组件使用mybatis，这里直接使用了mybatis-spring-boot-starter</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;1.3.2&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>完整的pom.xml内容如下</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
        xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.snowalker.shardingjdbc&lt;/groupId&gt;
    &lt;artifactId&gt;snowalker-shardingjdbc-demo&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;name&gt;snowalker-shardingjdbc-demo&lt;/name&gt;
    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;

    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;
        &lt;mybatis-spring-boot-starter-version&gt;1.3.2&lt;/mybatis-spring-boot-starter-version&gt;
        &lt;druid-version&gt;1.1.6&lt;/druid-version&gt;
        &lt;sharding-jdbc-version&gt;3.0.0&lt;/sharding-jdbc-version&gt;
        &lt;jasypt-spring-boot-version&gt;1.14&lt;/jasypt-spring-boot-version&gt;
        &lt;fastjson-version&gt;1.2.28&lt;/fastjson-version&gt;
        &lt;common-lang3-version&gt;3.8&lt;/common-lang3-version&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;!-- sharding-sphere --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.shardingsphere&lt;/groupId&gt;
            &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;${sharding-jdbc-version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;${mybatis-spring-boot-starter-version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;druid&lt;/artifactId&gt;
            &lt;version&gt;${druid-version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;
</code></pre><h2 id="配置mybatis"><a href="#配置mybatis" class="headerlink" title="配置mybatis"></a>配置mybatis</h2><p>接着我们在application.properties中配置mybatis，指定mapper配置文件的位置</p>
<pre><code>########################################################################
#
#     mybatis配置
#
#########################################################################
mybatis.config-location=classpath:mybatis-config.xml
mybatis.mapper-locations=classpath:mapper/*.xml
</code></pre><p>这里我在resources下建立一个目录mapper，将mapper配置文件均放置在该目录下。</p>
<h2 id="配置基本分库分表规则"><a href="#配置基本分库分表规则" class="headerlink" title="配置基本分库分表规则"></a>配置基本分库分表规则</h2><p>由于我们使用了Spring Boot作为基础框架，因此只需要通过groovy表达式的方式进行分库分表规则的配置。</p>
<h3 id="引入分库分表配置文件"><a href="#引入分库分表配置文件" class="headerlink" title="引入分库分表配置文件"></a>引入分库分表配置文件</h3><p>这里在resources下建立一个application-db-config.properties配置，用于配置分库分表相关的配置项。 <strong>注意</strong> 一定要以application- 开头，否则不能正常的引入。<br>在application.properties中添加如下配置，引入分库分表的配置项</p>
<pre><code>spring.profiles.include=db-config
</code></pre><h3 id="application-db-config-properties分库分表配置项详解"><a href="#application-db-config-properties分库分表配置项详解" class="headerlink" title="application-db-config.properties分库分表配置项详解"></a>application-db-config.properties分库分表配置项详解</h3><p>这里使用druid作为数据库的连接池，我们需要在 application-db-config.properties 中配置数据源及分库分表的规则等信息。</p>
<h4 id="数据源分片详细配置"><a href="#数据源分片详细配置" class="headerlink" title="数据源分片详细配置"></a>数据源分片详细配置</h4><pre><code>###########################################################
#
#           数据源分片详细配置
#
###########################################################
#打印sql日志
sharding.jdbc.config.sharding.props.sql.show=true
#数据源名称，多数据源以逗号分隔
sharding.jdbc.datasource.names=ds0,ds1,ds2,ds3
###########################################################
#
#          数据源参数配置-druid
#
###########################################################
initialSize=5
minIdle=5
maxIdle=100
maxActive=20
maxWait=60000
timeBetweenEvictionRunsMillis=60000
minEvictableIdleTimeMillis=300000
</code></pre><p>这里主要配置了分片数据源及公共的数据源配置参数，我们通过<strong>sharding.jdbc.datasource.names</strong> 指定了ds0,ds1,ds2,ds3四个物理分片数据源</p>
<h4 id="默认分片规则配置"><a href="#默认分片规则配置" class="headerlink" title="默认分片规则配置"></a>默认分片规则配置</h4><p>一般在线上业务中，会有配置信息表，比如: 省市区编码字典表，错误码字典表 等类型的不需要进行分库分表的数据表，那么我们就可以将他们放置在默认的分片中，这样，当我们的sql执行对这些表的操作，Sharding-JDBC的sql解析器解析这些sql时会路由到默认的数据源进行对应的操作。</p>
<pre><code>###########################################################
#
#                       默认分片规则配置--字典表使用
#
###########################################################
#未配置分片规则的表将通过默认数据源定位-适用于单库单表，该表无需配置分片规则
sharding.jdbc.config.sharding.defaultDataSourceName=ds0
</code></pre><p>通过 <strong>sharding.jdbc.config.sharding.defaultDataSourceName</strong> 指定我们在上文中配置的分片中的某一个数据源别名作为默认数据源</p>
<h4 id="数据源详细配置"><a href="#数据源详细配置" class="headerlink" title="数据源详细配置"></a>数据源详细配置</h4><p>这里是对上述四个数据源的详细配置，篇幅可能较长，我先以一个详细的配置进行讲解</p>
<pre><code>###########################################################
#
#                       数据源详细配置
#
###########################################################
#################### 00库配置 ##############################
sharding.jdbc.datasource.ds0.type=com.alibaba.druid.pool.DruidDataSource
sharding.jdbc.datasource.ds0.driver-class-name=com.mysql.cj.jdbc.Driver
sharding.jdbc.datasource.ds0.url=jdbc:mysql://127.0.0.1:3306/db_00?useUnicode=true&amp;characterEncoding=utf8
&amp;useSSL=true&amp;serverTimezone=GMT%2B8
sharding.jdbc.datasource.ds0.username=xxxxxxx
sharding.jdbc.datasource.ds0.password=xxxxxxx
# 连接池的配置信息
# 初始化大小，最小，最大
sharding.jdbc.datasource.ds0.initialSize=${initialSize}
# 只需配置minIdle最小连接池数量，maxIdle已经不再使用，配置了也没效果
sharding.jdbc.datasource.ds0.minIdle=${minIdle}
# 最大连接池数量
sharding.jdbc.datasource.ds0.maxActive=${maxActive}
# 配置获取连接等待超时的时间
sharding.jdbc.datasource.ds0.maxWait=${maxWait}
# 用来检测连接是否有效的sql
sharding.jdbc.datasource.ds0.validationQuery=SELECT 1 FROM DUAL
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
sharding.jdbc.datasource.ds0.timeBetweenEvictionRunsMillis=${timeBetweenEvictionRunsMillis}
# 配置一个连接在池中最小生存的时间，单位是毫秒
sharding.jdbc.datasource.ds0.minEvictableIdleTimeMillis=${minEvictableIdleTimeMillis}
</code></pre><p>由于使用了Sharding-JDBC，因此我们需要使用它的数据源配置，配置数据源为druid，配置数据库连接地址及用户名密码。</p>
<p><strong>注意</strong>：</p>
<ol>
<li>由于我们使用的Spring Boot2.x默认使用的mysql驱动为8.x，因此将驱动设置为： <strong>com.mysql.cj.jdbc.Driver</strong></li>
<li>数据库连接串中需要显式的指定当前的时区，这里我们使用东八区，即 <strong>serverTimezone=GMT%2B8</strong></li>
<li>生产环境数据库的密码应当使用加密方式，这块儿的详细配置我会在下一篇文章中展开详述</li>
</ol>
<p>关于mysql驱动及时区，可以看我之前写的文章</p>
<p><a href="http://wuwenliang.net/2019/02/19/com-mysql-jdbc-Driver-%E5%92%8C-com-mysql-cj-jdbc-Driver%E7%9A%84%E5%8C%BA%E5%88%AB-serverTimezone%E8%AE%BE%E5%AE%9A/">com.mysql.jdbc.Driver 和 com.mysql.cj.jdbc.Driver的区别 serverTimezone设定</a></p>
<p>其余的数据源分片的配置是类似的，嫌太长的读者可以直接跳过。</p>
<pre><code>#################### 01库配置 ##############################
sharding.jdbc.datasource.ds1.type=com.alibaba.druid.pool.DruidDataSource
sharding.jdbc.datasource.ds1.driver-class-name=com.mysql.cj.jdbc.Driver
sharding.jdbc.datasource.ds1.url=jdbc:mysql://127.0.0.1:3306/db_01?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=true
&amp;serverTimezone=GMT%2B8
sharding.jdbc.datasource.ds1.username=xxxxxxx
sharding.jdbc.datasource.ds1.password=xxxxxxx
# 连接池的配置信息
# 初始化大小，最小，最大
sharding.jdbc.datasource.ds1.initialSize=${initialSize}
# 只需配置minIdle最小连接池数量，maxIdle已经不再使用，配置了也没效果
sharding.jdbc.datasource.ds1.minIdle=${minIdle}
# 最大连接池数量
sharding.jdbc.datasource.ds1.maxActive=${maxActive}
# 配置获取连接等待超时的时间
sharding.jdbc.datasource.ds1.maxWait=${maxWait}
# 用来检测连接是否有效的sql
sharding.jdbc.datasource.ds1.validationQuery=SELECT 1 FROM DUAL
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
sharding.jdbc.datasource.ds1.timeBetweenEvictionRunsMillis=${timeBetweenEvictionRunsMillis}
# 配置一个连接在池中最小生存的时间，单位是毫秒
sharding.jdbc.datasource.ds1.minEvictableIdleTimeMillis=${minEvictableIdleTimeMillis}
#################### 02库配置 ##############################
sharding.jdbc.datasource.ds2.type=com.alibaba.druid.pool.DruidDataSource
sharding.jdbc.datasource.ds2.driver-class-name=com.mysql.cj.jdbc.Driver
sharding.jdbc.datasource.ds2.url=jdbc:mysql://127.0.0.1:3306/db_02?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=true
&amp;serverTimezone=GMT%2B8
sharding.jdbc.datasource.ds2.username=xxxxxxx
sharding.jdbc.datasource.ds2.password=xxxxxxx
# 连接池的配置信息
# 初始化大小，最小，最大
sharding.jdbc.datasource.ds2.initialSize=${initialSize}
# 只需配置minIdle最小连接池数量，maxIdle已经不再使用，配置了也没效果
sharding.jdbc.datasource.ds2.minIdle=${minIdle}
# 最大连接池数量
sharding.jdbc.datasource.ds2.maxActive=${maxActive}
# 配置获取连接等待超时的时间
sharding.jdbc.datasource.ds2.maxWait=${maxWait}
# 用来检测连接是否有效的sql
sharding.jdbc.datasource.ds2.validationQuery=SELECT 1 FROM DUAL
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
sharding.jdbc.datasource.ds2.timeBetweenEvictionRunsMillis=${timeBetweenEvictionRunsMillis}
# 配置一个连接在池中最小生存的时间，单位是毫秒
sharding.jdbc.datasource.ds2.minEvictableIdleTimeMillis=${minEvictableIdleTimeMillis}
#################### 03库配置 ##############################
sharding.jdbc.datasource.ds3.type=com.alibaba.druid.pool.DruidDataSource
sharding.jdbc.datasource.ds3.driver-class-name=com.mysql.cj.jdbc.Driver
sharding.jdbc.datasource.ds3.url=jdbc:mysql://127.0.0.1:3306/db_03?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=true
&amp;serverTimezone=GMT%2B8
sharding.jdbc.datasource.ds3.username=xxxxxxx
sharding.jdbc.datasource.ds3.password=xxxxxxx
# 连接池的配置信息
# 初始化大小，最小，最大
sharding.jdbc.datasource.ds3.initialSize=${initialSize}
# 只需配置minIdle最小连接池数量，maxIdle已经不再使用，配置了也没效果
sharding.jdbc.datasource.ds3.minIdle=${minIdle}
# 最大连接池数量
sharding.jdbc.datasource.ds3.maxActive=${maxActive}
# 配置获取连接等待超时的时间
sharding.jdbc.datasource.ds3.maxWait=${maxWait}
# 用来检测连接是否有效的sql
sharding.jdbc.datasource.ds3.validationQuery=SELECT 1 FROM DUAL
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
sharding.jdbc.datasource.ds3.timeBetweenEvictionRunsMillis=${timeBetweenEvictionRunsMillis}
# 配置一个连接在池中最小生存的时间，单位是毫秒
sharding.jdbc.datasource.ds3.minEvictableIdleTimeMillis=${minEvictableIdleTimeMillis}
</code></pre><h4 id="配置数据库表分片规则"><a href="#配置数据库表分片规则" class="headerlink" title="配置数据库表分片规则"></a>配置数据库表分片规则</h4><p>接下来讲解的数据库表分片规则是配置的重点，本文中我们使用默认的inline表达式作为讲解重点。</p>
<p>实战中，单纯使用inline表达式可能不满足我们的需求，这就需要我们对分片规则进行扩展，这块儿的内容会在系列的后半部分展开讲解。</p>
<p>首先看一下我们的配置详细内容</p>
<pre><code>###########################################################
#
#                    shardingjdbc--分片规则--订单表
#           根据user_id取模分库, 且根据order_id取模分表的两库两表的配置。
#
###########################################################
sharding.jdbc.config.sharding.default-database-strategy.inline.sharding-column
    =user_id
sharding.jdbc.config.sharding.default-database-strategy.inline.algorithm-expression
    =ds$-&gt;{user_id % 4}

sharding.jdbc.config.sharding.tables.t_order.actual-data-nodes
    =ds$-&gt;{0..3}.t_order_000$-&gt;{0..1}
sharding.jdbc.config.sharding.tables.t_order.table-strategy.inline.sharding-column
    =order_id
sharding.jdbc.config.sharding.tables.t_order.table-strategy.inline.algorithm-expression
    =t_order_000$-&gt;{order_id % 2}
</code></pre><p>订单表中保存了系统内部用户id，订单表主键order_id。实际的场景中，我们需要查询某一个用户的订单列表，因此需要将user_id作为查询条件，这里相信聪明的你已经猜到，需要将user_id作为数据库的分片键。</p>
<p>我们详细的看一下各个配置的含义</p>
<table>
<thead>
<tr>
<th style="text-align:left">配置项</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>sharding.jdbc.config.sharding.<br>default-database-strategy.inline.sharding-column</strong></td>
<td style="text-align:left">表示默认的分片列名称，我们用user_id作为分片列</td>
</tr>
<tr>
<td style="text-align:left"><strong>sharding.jdbc.config.sharding.<br>default-database-strategy.inline.algorithm-expression</strong></td>
<td style="text-align:left">表示inline表达式指定的分片策略，这里我们配置 <strong>ds$-&gt;{user_id % 4}</strong><br> 表示 <strong>对user_id进行模4操作，余数即为路由后的数据分片下标</strong>，这里要保证user_id为纯数字，需要我们自行实现一个唯一id生成器，这里我是自己实现一个简单的demo级别的KeyGenerator。关于如何实现生产可用的唯一id生成器，我也会在后续的文章中通过一个单独的专题进行讲解。</td>
</tr>
<tr>
<td style="text-align:left"><strong>sharding.jdbc.config.sharding.<br>tables.t_order.actual-data-nodes</strong></td>
<td style="text-align:left">这个配置是需要我们通过inline表达式指定所有的实际数据分片节点。其中，tables后需要指定逻辑数据表名，我们指定为t_order。<br> 这里我们配置的是<strong>ds＄-&gt;{0..3}.t_order_000＄-&gt;{0..1}</strong>,通过groovy的遍历语法将配置的四个数据分片中的所有表指定为实际的数据节点。(这里的$符号一定是英文半角)</td>
</tr>
<tr>
<td style="text-align:left"><strong>sharding.jdbc.config.sharding.<br>tables.t_order.table-strategy.inline.sharding-column</strong></td>
<td style="text-align:left">该配置表示表分片键，这里我们使用订单表的业务主键order_id作为表分片键，这样可以保证同一个用户的订单数据在同一个数据库分片中，但是不能保证在同一个数据表中。</td>
</tr>
<tr>
<td style="text-align:left"><strong>sharding.jdbc.config.sharding.<br>tables.t_order.table-strategy.inline.algorithm-expression</strong></td>
<td style="text-align:left">该配置为表分片策略的inline表达式，此处我们要对每个片上的所有订单表进行模2操作（2表示每个片有两个表节点），因此配置为<strong>t_order_000$-&gt;{order_id % 2}</strong></td>
</tr>
</tbody>
</table>
<p>到这里，我们就通过默认的inline表达式方式将分片的配置设置完毕。接着看下代码逻辑</p>
<h2 id="代码逻辑实现"><a href="#代码逻辑实现" class="headerlink" title="代码逻辑实现"></a>代码逻辑实现</h2><p>先简单看下订单实体属性，很简单，就是对数据库表字段的映射</p>
<h3 id="订单实体"><a href="#订单实体" class="headerlink" title="订单实体"></a>订单实体</h3><pre><code>public class OrderInfo {

    private String id;
    private Long userId;
    private Long orderId;
    private String userName;
    ...省略getter setter...
</code></pre><h3 id="OrderMapper订单数据库操作接口"><a href="#OrderMapper订单数据库操作接口" class="headerlink" title="OrderMapper订单数据库操作接口"></a>OrderMapper订单数据库操作接口</h3><p>Sharding-JDBC对我们使用何种数据库查询框架没有限制，可以是原生的JDBC，也可以是JDBCTemplate，或者mybatis均可。这体现出它设计上的高度抽象性。</p>
<pre><code>public interface OrderMapper {

    // 查询某个用户订单列表
    List&lt;OrderInfo&gt; queryOrderInfoList(OrderInfo orderInfo);

    // 通过订单号查询订单信息
    OrderInfo queryOrderInfoByOrderId(OrderInfo orderInfo);

    // 插入订单信息
    int addOrder(OrderInfo orderInfo);
}
</code></pre><p>很简单，就是一个插入操作，一个列表查询，一个通过主键查询，我们用来测试配置项是否生效。</p>
<h3 id="OrderServiceImpl订单操作业务实现类"><a href="#OrderServiceImpl订单操作业务实现类" class="headerlink" title="OrderServiceImpl订单操作业务实现类"></a>OrderServiceImpl订单操作业务实现类</h3><p>这里主要展示的是订单操作业务实现类，接口内容不再赘述</p>
<pre><code>@Service(value = &quot;orderService&quot;)
public class OrderServiceImpl implements OrderService {

    private static final Logger LOGGER = LoggerFactory.getLogger(OrderServiceImpl.class);

    @Autowired
    OrderMapper orderMapper;

    @Override
    public List&lt;OrderInfo&gt; queryOrderInfoList(OrderInfo orderInfo) {
        return orderMapper.queryOrderInfoList(orderInfo);
    }

    @Override
    public OrderInfo queryOrderInfoByOrderId(OrderInfo orderInfo) {
        return orderMapper.queryOrderInfoByOrderId(orderInfo);
    }

    @Override
    public int addOrder(OrderInfo orderInfo) {
        LOGGER.info(&quot;订单入库开始，orderinfo={}&quot;, orderInfo.toString());
        return orderMapper.addOrder(orderInfo);
    }
}
</code></pre><p>代码几乎没有什么理解难度，就是直接代理Mapper，将上层的参数直接传递给数据持久层。</p>
<h3 id="测试用例"><a href="#测试用例" class="headerlink" title="测试用例"></a>测试用例</h3><p>这里通过一个测试用例测试上述的三个数据库操作是否能够正确执行。</p>
<h4 id="测试数据插入"><a href="#测试数据插入" class="headerlink" title="测试数据插入"></a>测试数据插入</h4><pre><code>@RunWith(SpringRunner.class)
@SpringBootTest
public class SnowalkerShardingjdbcDemoApplicationTests {

    private static final Logger LOGGER = LoggerFactory.getLogger(SnowalkerShardingjdbcDemoApplicationTests.class);

    @Resource(name = &quot;orderService&quot;)
    OrderService orderService;

    @Test
    public void testInsertOrderInfo() {
        for (int i = 0; i &lt; 1000; i++) {
            long userId = i;
            long orderId = i + 1;
            OrderInfo orderInfo = new OrderInfo();
            orderInfo.setUserName(&quot;snowalker&quot;);
            orderInfo.setUserId(userId);
            orderInfo.setOrderId(orderId);
            int result = orderService.addOrder(orderInfo);
            if (1 == result) {
                LOGGER.info(&quot;入库成功,orderInfo={}&quot;, orderInfo);
            } else {
                LOGGER.info(&quot;入库失败,orderInfo={}&quot;, orderInfo);
            }
        }
    }
    .....
</code></pre><p>这里我们进行1000次入库操作，将每次的循环次数作为user_id,循环次数+1作为订单id，后续的文章中我会讲解如何自定义生产可用的主键生成策略。</p>
<p>将数据填充到POJO中后执行入库操作。</p>
<p>日志如下：</p>
<pre><code>2019-03-13 16:19:34.361  INFO 16388 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-1} inited
2019-03-13 16:19:34.450  INFO 16388 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-2} inited
2019-03-13 16:19:34.518  INFO 16388 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-3} inited
2019-03-13 16:19:34.582  INFO 16388 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-4} inited
2019-03-13 16:19:35.888  INFO 16388 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService &apos;applicationTaskExecutor&apos;
2019-03-13 16:19:37.103  INFO 16388 --- [           main] nowalkerShardingjdbcDemoApplicationTests : Started SnowalkerShardingjdbcDemoApplicationTests in 6.993 seconds (JVM running for 8.214)
2019-03-13 16:19:37.529  INFO 16388 --- [           main] c.s.s.s.demo.service.OrderServiceImpl    : 订单入库开始，orderinfo=OrderInfo{id=&apos;null&apos;, userId=0, orderId=1, userName=&apos;snowalker&apos;}
2019-03-13 16:19
......
2019-03-13 16:19:38.456  INFO 16388 --- [           main] nowalkerShardingjdbcDemoApplicationTests : 入库成功,orderInfo=OrderInfo{id=&apos;null&apos;, userId=0, orderId=1, userName=&apos;snowalker&apos;}
2019-03-13 16:19:38.456  INFO 16388 --- [           main] c.s.s.s.demo.service.OrderServiceImpl    : 订单入库开始，orderinfo=OrderInfo{id=&apos;null&apos;, userId=4, orderId=5, userName=&apos;snowalker&apos;}
2019-03-13 16:19:38.457  INFO 16388 --- [           main] Sharding-Sphere-SQL                      : Rule Type: sharding
2019-03-13 16:19:38.457  INFO 16388 --- [           main] Sharding-Sphere-SQL                      : Logic SQL: insert into t_order(
        user_id,
        order_id,
        user_name
    )
    values
    (
        ?,
        ?,
        ?
    )
2019-03-13 16:19:38.457  INFO 16388 --- [           main] Sharding-Sphere-SQL                      : SQLStatement: InsertStatement(super=DMLStatement(super=AbstractSQLStatement(type=DML, tables=Tables(tables=[Table(name=t_order, alias=Optional.absent())]), conditions=Conditions(orCondition=OrCondition(andConditions=[AndCondition(conditions=[Condition(column=Column(name=user_id, tableName=t_order), operator=EQUAL, positionValueMap={}, positionIndexMap={0=0}), Condition(column=Column(name=order_id, tableName=t_order), operator=EQUAL, positionValueMap={}, positionIndexMap={0=1})])])), sqlTokens=[TableToken(skippedSchemaNameLength=0, originalLiterals=t_order), io.shardingsphere.core.parsing.parser.token.InsertValuesToken@79be91eb], parametersIndex=3)), columns=[Column(name=user_id, tableName=t_order), Column(name=order_id, tableName=t_order), Column(name=user_name, tableName=t_order)], generatedKeyConditions=[], insertValues=InsertValues(insertValues=[InsertValue(type=VALUES, expression=(
        ?,
        ?,
        ?
    ), parametersCount=3)]), columnsListLastPosition=83, generateKeyColumnIndex=-1, insertValuesListLastPosition=142)
2019-03-13 16:19:38.457  INFO 16388 --- [           main] Sharding-Sphere-SQL                      : Actual SQL: ds0 ::: insert into t_order_0001(
        user_id,
        order_id,
        user_name
    )
    values
    (
        ?,
        ?,
        ?
    ) ::: [[4, 5, snowalker]]
</code></pre><p>可以看到，Sharding-JDBC帮助我们将逻辑sql及实际执行的sql均打印出来，这个配置在开发阶段能够帮助我们更快的定位数据的分布情况，生产环境设置为 <strong>sharding.jdbc.config.sharding.props.sql.show=false</strong> 关闭。</p>
<p>查看数据库，看到的效果如下：</p>
<p>首先找库，</p>
<pre><code>user_id mod 4 == 0 入 db_00,user_id mod 4 == 1 入 db_01
user_id mod 4 == 2 入 db_02,user_id mod 4 == 3 入 db_03
</code></pre><p>接着找表</p>
<pre><code>order_id mod 2 == 0 入 t_order_0000
order_id mod 2 == 1 入 t_order_0001
</code></pre><p>二者结合起来一共有八种组合</p>
<pre><code>user_id mod 4 == 0 入 db_00, order_id mod 2 == 0 入 t_order_0000
user_id mod 4 == 0 入 db_00, order_id mod 2 == 1 入 t_order_0001

user_id mod 4 == 1 入 db_01, order_id mod 2 == 0 入 t_order_0000
user_id mod 4 == 1 入 db_01, order_id mod 2 == 1 入 t_order_0001

user_id mod 4 == 2 入 db_02, order_id mod 2 == 0 入 t_order_0000
user_id mod 4 == 2 入 db_02, order_id mod 2 == 1 入 t_order_0001

user_id mod 4 == 3 入 db_03, order_id mod 2 == 0 入 t_order_0000
user_id mod 4 == 3 入 db_03, order_id mod 2 == 1 入 t_order_0001
</code></pre><p>这样，至少能够保证同一个用户的数据都在一个物理分片上。</p>
<h4 id="测试查询列表"><a href="#测试查询列表" class="headerlink" title="测试查询列表"></a>测试查询列表</h4><p>列表查询测试用例很简单，代码如下:</p>
<pre><code>/**
 * 默认规则跨片归并
 */
@Test
public void testQueryList() {
    List&lt;OrderInfo&gt; list = new ArrayList&lt;&gt;();
    OrderInfo orderInfo = new OrderInfo();
    orderInfo.setUserId(2l);
    list = orderService.queryOrderInfoList(orderInfo);
    LOGGER.info(list.toString());
}
</code></pre><p>这里我们查询一个user_id=21的用户的所有订单明细列表，21 mod 4 == 1, 该用户的所有数据分布在 db_01 片上，在该片上查询其所有的订单数据。</p>
<p>由于我们制定的默认分片策略是通过order_id mod 2，因此一定存在用户订单为奇数的分布在t_order_0001中，订单为偶数的分布在t_order_0000中。</p>
<p>这里就涉及到Sharding-JDBC的一个特性：<strong>结果归并</strong>。</p>
<blockquote>
<p>将从各个数据节点获取的多数据结果集，组合成为一个结果集并正确的返回至请求客户端，称为结果归并。</p>
</blockquote>
<p>归并方式分为如下几种方式：</p>
<table>
<thead>
<tr>
<th style="text-align:left">归并方式</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">遍历归并</td>
</tr>
<tr>
<td style="text-align:left">排序归并</td>
</tr>
<tr>
<td style="text-align:left">分组归并</td>
</tr>
<tr>
<td style="text-align:left">聚合归并</td>
</tr>
<tr>
<td style="text-align:left">分页归并</td>
</tr>
</tbody>
</table>
<p>对归并的详细的介绍，请查看官网的讲解 <a href="https://shardingsphere.apache.org/document/legacy/3.x/document/cn/features/sharding/principle/merge/" target="_blank" rel="external">归并引擎</a></p>
<p>这里我使用的是未排序的列表查询，sql语句如下：</p>
<pre><code>&lt;select id=&quot;queryOrderInfoList&quot; parameterType=&quot;com.snowalker.shardingjdbc.snowalker.demo.entity.OrderInfo&quot;
        resultType=&quot;com.snowalker.shardingjdbc.snowalker.demo.entity.OrderInfo&quot;&gt;
    select
        t.id as id,
        t.user_id as userId,
        t.order_id as orderId,
        t.user_name as userName
    from t_order t
    where t.user_id=#{userId}
&lt;/select&gt;
</code></pre><p>没有指定order by 字段，因此使用最简单的遍历归并。Sharding-JDBC的归并引擎会结合具体的查询sql进行分析，选取最合适的归并方式，这对我们应用层都是无感知的。</p>
<p>执行一下这个测试用例，日志打印如下：</p>
<pre><code>2019-03-13 17:23:06.928  INFO 16028 --- [           main] nowalkerShardingjdbcDemoApplicationTests : Started SnowalkerShardingjdbcDemoApplicationTests in 6.076 seconds (JVM running for 7.079)
2019-03-13 17:23:07.595  INFO 16028 --- [           main] Sharding-Sphere-SQL                      : Rule Type: sharding
2019-03-13 17:23:07.596  INFO 16028 --- [           main] Sharding-Sphere-SQL                      : 
Logic SQL: select
            t.id as id,
            t.user_id as userId,
            t.order_id as orderId,
            t.user_name as userName
        from t_order t
        where t.user_id=?
2019-03-13 17:23:07.596  INFO 16028 --- [           main] Sharding-Sphere-SQL                      : SQLStatement: SelectStatement(super=DQLStatement(super=AbstractSQLStatement(type=DQL, tables=Tables(tables=[Table(name=t_order, alias=Optional.of(t))]), conditions=Conditions(orCondition=OrCondition(andConditions=[AndCondition(conditions=[Condition(column=Column(name=user_id, tableName=t_order), operator=EQUAL, positionValueMap={}, positionIndexMap={0=0})])])), sqlTokens=[TableToken(skippedSchemaNameLength=0, originalLiterals=t_order)], parametersIndex=1)), containStar=false, selectListLastPosition=143, groupByLastPosition=0, items=[CommonSelectItem(expression=t.user_name, alias=Optional.of(userName)), CommonSelectItem(expression=t.id, alias=Optional.of(id)), CommonSelectItem(expression=t.user_id, alias=Optional.of(userId)), CommonSelectItem(expression=t.order_id, alias=Optional.of(orderId))], groupByItems=[], orderByItems=[], limit=null, subQueryStatement=null)
2019-03-13 17:23:07.596  INFO 16028 --- [           main] Sharding-Sphere-SQL                      : 
Actual SQL: ds2 ::: select
            t.id as id,
            t.user_id as userId,
            t.order_id as orderId,
            t.user_name as userName
        from t_order_0000 t
        where t.user_id=? ::: [[2]]
2019-03-13 17:23:07.596  INFO 16028 --- [           main] Sharding-Sphere-SQL                      : 
Actual SQL: ds2 ::: select
            t.id as id,
            t.user_id as userId,
            t.order_id as orderId,
            t.user_name as userName
        from t_order_0001 t
        where t.user_id=? ::: [[2]]
2019-03-13 17:23:08.200  INFO 16028 --- [           main] nowalkerShardingjdbcDemoApplicationTests : 
[OrderInfo{id=&apos;975&apos;, userId=2, orderId=2, userName=&apos;snowalker&apos;}, 
OrderInfo{id=&apos;1&apos;, userId=2, orderId=3, userName=&apos;snowalker&apos;}]
</code></pre><p>通过日志可以看出，逻辑sql被sql解析器解析后改写为两个实际的sql，在ds2的t_order_0000与t_order_0001上均执行了一次，查询的结果在应用层进行了归并。</p>
<p>这种结果归并的方式由于涉及到了跨片查询，应用层的合并，因此有性能的损耗，而且由于数据跨片，因此可能导致事务失效。这个问题也是有解决方法的，我们可以通过自定义主键生成策略，强制同一个用户的所有的业务数据分布在同一个片（数据源）的同一个节点（表）上。详细方式我会在后续文章中展开讲解。</p>
<h4 id="测试查询单条数据"><a href="#测试查询单条数据" class="headerlink" title="测试查询单条数据"></a>测试查询单条数据</h4><p>查询单条数据就很简单了，在sql中指定了user_id和order_id两个分片键，首先通过user_id<br>找到数据源，再通过order_id查找节点找到对应表，最后在确定的数据源的某个确定的数据表上执行sql将数据查询后返回即可。</p>
<p>测试用例代码如下：</p>
<pre><code>@Test
public void testQueryById() {
    OrderInfo queryParam = new OrderInfo();
    queryParam.setUserId(8l);
    queryParam.setOrderId(8l);
    OrderInfo queryResult = orderService.queryOrderInfoByOrderId(queryParam);
    if (queryResult != null) {
        LOGGER.info(&quot;查询结果:orderInfo={}&quot;, queryResult);
    } else {
        LOGGER.info(&quot;查无此记录&quot;);
    }
}
</code></pre><p>我们尝试查找user_id为8，order_id为8的订单记录，执行后查看日志如下：</p>
<pre><code>2019-03-13 17:34:42.975  INFO 15760 --- [           main] Sharding-Sphere-SQL                      : Rule Type: sharding
2019-03-13 17:34:42.975  INFO 15760 --- [           main] Sharding-Sphere-SQL                      : Logic SQL: select
            t.id as id,
            t.user_id as userId,
            t.order_id as orderId,
            t.user_name as userName
        from t_order t
        where t.order_id=?
        and t.user_id=?
2019-03-13 17:34:42.975  INFO 15760 --- [           main] Sharding-Sphere-SQL                      : SQLStatement: SelectStatement(super=DQLStatement(super=AbstractSQLStatement(type=DQL, tables=Tables(tables=[Table(name=t_order, alias=Optional.of(t))]), conditions=Conditions(orCondition=OrCondition(andConditions=[AndCondition(conditions=[Condition(column=Column(name=order_id, tableName=t_order), operator=EQUAL, positionValueMap={}, positionIndexMap={0=0}), Condition(column=Column(name=user_id, tableName=t_order), operator=EQUAL, positionValueMap={}, positionIndexMap={0=1})])])), sqlTokens=[TableToken(skippedSchemaNameLength=0, originalLiterals=t_order)], parametersIndex=2)), containStar=false, selectListLastPosition=143, groupByLastPosition=0, items=[CommonSelectItem(expression=t.user_name, alias=Optional.of(userName)), CommonSelectItem(expression=t.id, alias=Optional.of(id)), CommonSelectItem(expression=t.user_id, alias=Optional.of(userId)), CommonSelectItem(expression=t.order_id, alias=Optional.of(orderId))], groupByItems=[], orderByItems=[], limit=null, subQueryStatement=null)
2019-03-13 17:34:42.975  INFO 15760 --- [           main] Sharding-Sphere-SQL                      : 
Actual SQL: ds0 ::: select
            t.id as id,
            t.user_id as userId,
            t.order_id as orderId,
            t.user_name as userName
        from t_order_0000 t
        where t.order_id=?
        and t.user_id=? ::: [[8, 8]]
2019-03-13 17:34:43.467  INFO 15760 --- [           main] nowalkerShardingjdbcDemoApplicationTests : 
查询结果:orderInfo=OrderInfo{id=&apos;991&apos;, userId=8, orderId=8, userName=&apos;snowalker&apos;}
</code></pre><p>sql解析器查找到该数据分布在0库0表中，执行查询语句并将结果返回。</p>
<h2 id="遗留问题"><a href="#遗留问题" class="headerlink" title="遗留问题"></a>遗留问题</h2><ol>
<li>后续需要实现自定义分片策略，配合自定义唯一主键的生成，保证同一个用户的数据分布在同一个片的同一个节点上</li>
<li>需要实现自定义唯一主键的编写，实现字符串形式的主键生成策略。这样我们就可以定义主键的不同位数的含义，将业务属性代入其中。如： OD0120180313194640123000802000923，表示order表的主键，包含了时间戳（精确到毫秒），包含了库表的下标。这样可读性更好，支持不同业务场景对主键生成的需求。</li>
<li>通过上述1.2两点，能够明显的规避由于数据分布在不同片上，导致的归并查询，这样，单库事务就又可以使用了，尽可能的减少分布式事务的引入。（分布式事务能避免就避免），当然我们在后续的讲解中也可能会对Sharding-Sphere原生的Saga事务做讲解。</li>
</ol>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>到这里，我们就完成了对Sharding-JDBC 3.x与Spring Boot 2.x的整合，配置了默认分片策略，完成了一个单表的主键查询、新增、列表查询等的操作。过程中对关键的配置和名词进行了解析，相信会对读者有所帮助。</p>
<h2 id="工程地址，本系列中保持更新"><a href="#工程地址，本系列中保持更新" class="headerlink" title="工程地址，本系列中保持更新"></a>工程地址，本系列中保持更新</h2><p><a href="https://github.com/TaXueWWL/snowalker-shardingjdbc-demo" target="_blank" rel="external">snowalker-shardingjdbc-demo</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上文中，我们讲解了分布式环境下的分库分表，从概念及案例上分析了何为分库分表及其优缺点。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://wuwenliang.net/2019/03/11/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%B9%8B%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/&quot;&gt;我说分布式之分库分表&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;从本文开始我们一起学习一下如何使用当前比较成熟的分库分表框架 Sharding-JDBC 实现分库分表。&lt;/p&gt;
&lt;h2 id=&quot;什么是Sharding-JDBC&quot;&gt;&lt;a href=&quot;#什么是Sharding-JDBC&quot; class=&quot;headerlink&quot; title=&quot;什么是Sharding-JDBC&quot;&gt;&lt;/a&gt;什么是Sharding-JDBC&lt;/h2&gt;&lt;p&gt;Sharding-JDBC是分布式数据中间件Sharding-Sphere中的重要组成部分，官方的介绍如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sharding-Sphere是一套开源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（计划中）这3款相互独立的产品组成。他们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Sharding-JDBC 是Sharding-Sphere的第一款产品，也是最接近开发者的一款分库分表中间件，很有代表性，也值得我们深入的学习与应用。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://shardingsphere.apache.org/document/legacy/3.x/document/cn/quick-start/&quot;&gt;Sharding-JDBC官方文档地址&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;这里我贴出官方的文档地址，版本为3.x，有问题先看文档是比较直接快速准确的trouble-shooting方式。&lt;/p&gt;
&lt;h2 id=&quot;如何使用Sharding-JDBC3-x-实现分库分表&quot;&gt;&lt;a href=&quot;#如何使用Sharding-JDBC3-x-实现分库分表&quot; class=&quot;headerlink&quot; title=&quot;如何使用Sharding-JDBC3.x 实现分库分表&quot;&gt;&lt;/a&gt;如何使用Sharding-JDBC3.x 实现分库分表&lt;/h2&gt;&lt;p&gt;简单了解一下背景之后，我们用一个案例先把它用起来，直观地感受一下Sharding-JDBC的魅力，后续我们会对它做进一步的讲解。&lt;/p&gt;
&lt;p&gt;由于目前的后端Java开发主要以Spring Boot为主，因此我将主要依据Spring Boot的2.x进行讲解。&lt;/p&gt;
    
    </summary>
    
      <category term="Sharding-JDBC" scheme="http://wuwenliang.net/categories/Sharding-JDBC/"/>
    
    
      <category term="Sharding-JDBC" scheme="http://wuwenliang.net/tags/Sharding-JDBC/"/>
    
  </entry>
  
  <entry>
    <title>我说分布式之分库分表</title>
    <link href="http://wuwenliang.net/2019/03/11/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%B9%8B%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    <id>http://wuwenliang.net/2019/03/11/我说分布式之分库分表/</id>
    <published>2019-03-11T03:27:55.000Z</published>
    <updated>2019-03-11T06:22:54.378Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>分布式应用架构下，数据量及接口并发量大幅上升后，单数据库由于无法抗住大流量、高并发的请求，从而造成数据库查询缓慢，频繁锁记录等问题。</p>
</blockquote>
<p>为了解决上述的问题，在分布式环境下，常用的应对高并发、大流量场景的方案之一就是分库分表。</p>
<p>拆分主要分垂直和水平两种。<br><a id="more"></a></p>
<h2 id="垂直拆分"><a href="#垂直拆分" class="headerlink" title="垂直拆分"></a>垂直拆分</h2><p>首先说一下垂直拆分。核心思路是：通过 <strong>降低单库（表）的大小来提高性能</strong> 。</p>
<p>如，交易场景下，将用户数据、订单数据、流水数据单独建库，<br>应用层拆分为用户、订单、流水等微服务，每类型服务只对一个业务库做操作，从而在物理上将数据拆分开来，保证其中某一个业务挂掉对别的服务没有影响。也能够在一定程度上增加系统抗并发的能力。</p>
<p>上面这种主要提到的是分库的情况，至于分表，道理也相似。</p>
<p>核心思路就是，将一个大表根据功能，拆分成一个个的子表，如：用户表可以根据业务情况拆分成用户基础信息表，用户详细信息表。订单表可以根据具体场景拆分为：订单主表，订单流水表等。</p>
<h2 id="垂直拆分分析"><a href="#垂直拆分分析" class="headerlink" title="垂直拆分分析"></a>垂直拆分分析</h2><blockquote>
<p>这里我们对垂直拆分的优缺点进行分析</p>
</blockquote>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol>
<li>专库专用，业务更加简洁清晰；</li>
<li>有利于维护，某个业务的变更只和本业务库有关；</li>
<li>有利于实现读写分离，冷热数据的分离等。</li>
</ol>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ol>
<li>垂直拆分只是将对单库的访问拆分为对多库的访问，但随着访问量激增，单库的压力依旧很大；</li>
<li>由于拆分了数据库，各个业务之间无法通过sql进行关联查询，只能在应用层进行归并；</li>
<li>分布式事务下的数据一致性需要依赖最终一致性方案解决。</li>
</ol>
<p>PS: 关于分布式事务相关的知识和技术点，我在之前的系列中已经系统的描述过，详情可以看</p>
<p> <a href="http://wuwenliang.net/2019/02/28/%E3%80%90%E7%BD%AE%E9%A1%B6%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E9%9B%86%E5%90%88/">【置顶】分布式系列文章集合</a></p>
<h2 id="水平拆分"><a href="#水平拆分" class="headerlink" title="水平拆分"></a>水平拆分</h2><p>接着分析一下水平拆分。</p>
<p>​水平划分是根据一定规则，如时间或id序列值等进行数据的拆分。比如根据时间拆分不同的数据库。</p>
<p>每个数据库中的表结构一致，但是数据是拆分的，所有的分库数据合在一起才是所有的业务数据。这样将访问压力分摊至各个水平表中，从而提升性能。</p>
<p>又比如根据业务id的值，根据规则（如取模）分成若干个表。每个表结构一致,（这点与垂直拆分相反）。</p>
<h2 id="水平拆分分析"><a href="#水平拆分分析" class="headerlink" title="水平拆分分析"></a>水平拆分分析</h2><blockquote>
<p>我们对水平拆分进行优缺点的分析。</p>
</blockquote>
<h3 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h3><ol>
<li>由于进行了拆分，单库/表中的数据量较之未拆分前，大幅度减少，查询性能明显提高</li>
<li>系统的整体的稳定性和负载能力得到提高，某个持久化节点down掉不影响所有的业务</li>
<li>由于是水平拆分，不需要改动业务代码</li>
</ol>
<h3 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h3><ol>
<li>水平拆分需要定义拆分规则，该规则对业务层有侵入</li>
<li>数据量上升以后，系统扩容需要对分片数据进行迁移</li>
<li>由于水平拆分，之前对单表的维护变更为维护多表，对DBA的工作压力增加</li>
<li>与垂直拆分相同，由于数据分布到多个片上，依旧存在无法跨库join等的问题，同时仍旧存在分布式事务、数据一致性的问题。</li>
</ol>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>由于单纯使用垂直拆分或者水平拆分均有利有弊，因此我们可以针对业务的特性考虑同时采用垂直和水平两种拆分方式。</p>
<p>在业务层，通过垂直拆分将应用微服务化，对访问量大的数据库表进行单独拆分。对于业务属性强且数据量大的数据表进行水平拆分，如：订单表，订单流水表。让具有相关性的数据分表分布在同一个片上，从而实现既做了分库分表减轻了系统访问压力，还可以保证同一个用户的数据能够分布在同一个片上，尽量避免分布式事务。</p>
<p>举个例子：</p>
<ol>
<li>用户表的数据访问量大，但基本上不需要和其他的业务表做关联查询（因为互联网业务场景下，我们在表结构设计时一般都会进行数据字段的冗余，设计时最多进行到第二范式）。对于用户表、配置信息表这类的数据，我们一般可以采用取模的方式进行水平的拆分。</li>
<li>对于订单表、流水表这种需要业务上进行关联查询的数据表，我们尽量通过同一个分片键进行订单、流水的id生成及入库操作。在入库时，能够保证同一个用户的订单、流水等业务信息分布到一个片上，这样我们就可以继续使用单库事务。</li>
</ol>
<p>当前技术领域对分库分表已经有很多的成熟方案，能够让我们稍作规则定制即可开箱即用，不需要做针对性的开发，常见的有两种模式，代理模式，客户端模式。</p>
<table>
<thead>
<tr>
<th style="text-align:left">框架名</th>
<th style="text-align:left">模式</th>
<th style="text-align:left">简介</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">mycat</td>
<td style="text-align:left">代理模式</td>
<td style="text-align:left">基于阿里开源的Cobar产品而研发，代理模式，更新较慢。</td>
</tr>
<tr>
<td style="text-align:left">ShardingProxy</td>
<td style="text-align:left">代理模式</td>
<td style="text-align:left">开源套件ShardingSphere生态中的组件，社区活跃</td>
</tr>
<tr>
<td style="text-align:left">Shardingjdbc</td>
<td style="text-align:left">客户端模式</td>
<td style="text-align:left">开源套件ShardingSphere生态中的组件，社区活跃，使用较多</td>
</tr>
<tr>
<td style="text-align:left">Zdal</td>
<td style="text-align:left">客户端模式</td>
<td style="text-align:left">蚂蚁金服闭源分库分表套件，性能较好，github有较老的版本</td>
</tr>
</tbody>
</table>
<p>我们在业务开发中，大量使用成熟的客户端模式进行数据库层的操作。近年大火的数据库中间件ShardingSphere已经在业界有了很多的落地案例和最佳实践，因此在后续的文章中，我将展开讲解如何利用开源组件ShardingSphere中的Shardingjdbc进行分库分表，通过demo讲解和实战模拟的方式，较为系统的展示分布式场景下的数据访问层的开发，我们拭目以待。</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;分布式应用架构下，数据量及接口并发量大幅上升后，单数据库由于无法抗住大流量、高并发的请求，从而造成数据库查询缓慢，频繁锁记录等问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了解决上述的问题，在分布式环境下，常用的应对高并发、大流量场景的方案之一就是分库分表。&lt;/p&gt;
&lt;p&gt;拆分主要分垂直和水平两种。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/categories/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/tags/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>springboot2.x使用thymeleaf上传并显示本地图片</title>
    <link href="http://wuwenliang.net/2019/03/07/springboot2-x%E4%BD%BF%E7%94%A8thymeleaf%E4%B8%8A%E4%BC%A0%E5%B9%B6%E6%98%BE%E7%A4%BA%E6%9C%AC%E5%9C%B0%E5%9B%BE%E7%89%87/"/>
    <id>http://wuwenliang.net/2019/03/07/springboot2-x使用thymeleaf上传并显示本地图片/</id>
    <published>2019-03-07T14:35:41.000Z</published>
    <updated>2019-03-07T15:11:37.636Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文记录一下如何在springboot2.x环境下，使用thymeleaf上传并显示本地图片</p>
</blockquote>
<p>之所以写这个小结是因为今天想做一个运维小工具，用到了图片上传，但是使用了thymeleaf之后，图片无法正确显示。</p>
<p>查找资料之后，发现需要指定虚拟目录，具体步骤如下。</p>
<a id="more"></a>
<h2 id="springboot2-x下如何进行文件上传"><a href="#springboot2-x下如何进行文件上传" class="headerlink" title="springboot2.x下如何进行文件上传"></a>springboot2.x下如何进行文件上传</h2><p>文件上传部分没有什么变化，依旧是springmvc中的套路。</p>
<h3 id="编写文件上传表单"><a href="#编写文件上传表单" class="headerlink" title="编写文件上传表单"></a>编写文件上传表单</h3><p>首先引入依赖如下：</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>接着我们需要一个表单，用于选取本地文件。</p>
<pre><code>&lt;form action=&quot;insertTip&quot; method=&quot;POST&quot; enctype=&quot;multipart/form-data&quot;&gt;
    ......
    &lt;tr&gt;
        &lt;td&gt;缩略图片&lt;/td&gt;
        &lt;td&gt;&lt;input type=&quot;file&quot; name=&quot;tipImage&quot; class=&quot;form-control&quot; required=&quot;required&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    ......

    &lt;div class=&quot;modal-footer&quot;&gt;
        &lt;center&gt;
            &lt;input type=&quot;submit&quot; class=&quot;btn btn-primary&quot; value=&quot;提交&quot; /&gt;
            &lt;button type=&quot;button&quot; class=&quot;btn btn-warning&quot; data-dismiss=&quot;modal&quot;&gt;关闭&lt;/button&gt;
        &lt;/center&gt;
    &lt;/div&gt;
&lt;/form&gt;
</code></pre><p>需要注意的是，form表单需要添加属性  <strong>enctype=”multipart/form-data”</strong> 用于标记这是一次文件上传。</p>
<h3 id="编写文件上传的业务逻辑"><a href="#编写文件上传的业务逻辑" class="headerlink" title="编写文件上传的业务逻辑"></a>编写文件上传的业务逻辑</h3><p>java代码中解析参数，并进行文件的上传操作</p>
<pre><code>@RequestMapping(value = &quot;insertTip&quot;, method = {RequestMethod.POST})
    public String addTip(@RequestParam(&quot;tipImage&quot;) MultipartFile tipImage,
                        HttpServletRequest request) {
// 获取文件
String fileName = tipImage.getOriginalFilename();
// 文件后缀
String suffixName = fileName.substring(fileName.lastIndexOf(&quot;.&quot;));
// 重新生成唯一文件名，用于存储数据库
String newFileName = UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;) + suffixName;
//创建文件
File file = new File(filePath + newFileName);
String tipImageUrl = file.getAbsolutePath();
log.info(&quot;tipId={},新的文件名={},绝对路径={}&quot; , tipId, newFileName, tipImageUrl);
 // 异步线程上传文件
executorService.submit(() -&gt; {
    try {
        tipImage.transferTo(file);
        log.info(&quot;tipId={},新的文件名={},上传成功&quot; , tipId, newFileName);
    } catch (
        IOException e) {
        e.printStackTrace();
    }
});
</code></pre><p>核心业务为，获取了文件的绝对路径，将文件重命名后，通过 <strong>transferTo(file)</strong> 上传至指定的目录下。</p>
<p>这里，需要将文件名保存至数据库中，注意不要保存绝对路径，否则无法加载。</p>
<h3 id="配置文件上传路径"><a href="#配置文件上传路径" class="headerlink" title="配置文件上传路径"></a>配置文件上传路径</h3><p>在application.properties中添加如下配置，配置虚拟目录，以及文件上传的绝对路径，将在下面用到。</p>
<pre><code>file.upload.path=D://fileupload/
file.upload.path.relative=/images/**
</code></pre><h3 id="配置虚拟目录到物理路径的映射关系"><a href="#配置虚拟目录到物理路径的映射关系" class="headerlink" title="配置虚拟目录到物理路径的映射关系"></a>配置虚拟目录到物理路径的映射关系</h3><p>编写一个spring的bean，标注 <strong>@Configuration</strong></p>
<pre><code>@Configuration
public class UploadFileConfig extends WebMvcConfigurerAdapter {

    /**上传地址*/
    @Value(&quot;${file.upload.path}&quot;)
    private String filePath;
    /**显示相对地址*/
    @Value(&quot;${file.upload.path.relative}&quot;)
    private String fileRelativePath;

    @Override
    public void addResourceHandlers(ResourceHandlerRegistry registry) {
        registry.addResourceHandler(fileRelativePath).addResourceLocations(&quot;file:/&quot; + filePath);
        super.addResourceHandlers(registry);
    }
}
</code></pre><p>这里我们重写了WebMvcConfigurerAdapter的addResourceHandlers方法，将配置中的绝对地址与虚拟路径相对应，这样，我们就可以在thymeleaf的html页面中，通过 /images/xxxxx.xxx<br>的方式，加载文件系统的文件了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文记录一下如何在springboot2.x环境下，使用thymeleaf上传并显示本地图片&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;之所以写这个小结是因为今天想做一个运维小工具，用到了图片上传，但是使用了thymeleaf之后，图片无法正确显示。&lt;/p&gt;
&lt;p&gt;查找资料之后，发现需要指定虚拟目录，具体步骤如下。&lt;/p&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="http://wuwenliang.net/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="http://wuwenliang.net/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>【置顶】分布式系列文章集合</title>
    <link href="http://wuwenliang.net/2019/02/28/%E3%80%90%E7%BD%AE%E9%A1%B6%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E9%9B%86%E5%90%88/"/>
    <id>http://wuwenliang.net/2019/02/28/【置顶】分布式系列文章集合/</id>
    <published>2019-02-28T15:05:16.000Z</published>
    <updated>2019-05-13T08:29:29.307Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文为分布式系列文章的集锦汇总，长期保持置顶及更新，读者可以在本文中更好的学习到某个具体的系列。</p>
</blockquote>
<h2 id="我说分布式事务系列"><a href="#我说分布式事务系列" class="headerlink" title="我说分布式事务系列"></a>我说分布式事务系列</h2><table>
<thead>
<tr>
<th style="text-align:left">文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/11/20/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8BTCC/">我说分布式事务之TCC</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/12/06/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B%E6%9C%80%E5%A4%A7%E5%8A%AA%E5%8A%9B%E9%80%9A%E7%9F%A5%E5%9E%8B%E4%BA%8B%E5%8A%A1/">我说分布式事务之最大努力通知型事务</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/12/13/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B%E5%8F%AF%E9%9D%A0%E6%B6%88%E6%81%AF%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E4%BA%8B%E5%8A%A11-%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/">我说分布式事务之可靠消息最终一致性事务1-原理及实现</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/12/13/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B%E6%B6%88%E6%81%AF%E4%B8%80%E8%87%B4%E6%80%A7%E4%BA%8B%E5%8A%A12-rocketmq%E7%9A%84%E5%AE%9E%E7%8E%B0/">我说分布式事务之消息一致性事务2-rocketmq的实现</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/12/13/%E3%80%90%E6%B1%87%E6%80%BB%E3%80%91%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%B3%BB%E5%88%97/">【汇总】我说分布式事务系列</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2017/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B%E8%81%8A%E8%81%8ATCC/">分布式事务之聊聊TCC</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2017/04/09/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E5%B8%B8%E7%94%A8%E6%96%B9%E6%A1%88/">分布式事务最终一致性常用方案</a></td>
</tr>
</tbody>
</table>
<h2 id="跟我学RocketMQ"><a href="#跟我学RocketMQ" class="headerlink" title="跟我学RocketMQ"></a>跟我学RocketMQ</h2><table>
<thead>
<tr>
<th style="text-align:left">文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/01/09/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-1-%E4%B9%8B%E5%AE%89%E8%A3%85RocketMQ/">[1-1]安装RocketMQ</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/01/09/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-2-%E4%B9%8B%E5%AE%89%E8%A3%85RocketMQ-Console%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0/">[1-2]安装RocketMQ-Console管理平台</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/01/23/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-3-%E4%B9%8B%E5%8F%91%E9%80%81%E6%99%AE%E9%80%9A%E6%B6%88%E6%81%AF%E5%8F%8A%E5%B0%81%E8%A3%85DefaultMQProducer%E6%94%AF%E6%8C%81spring/">[1-3]发送普通消息及封装DefaultMQProducer支持spring</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/01/23/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-4-%E4%B9%8B%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%E5%8F%8A%E5%B0%81%E8%A3%85DefaultMQPushConsumer%E6%94%AF%E6%8C%81spring/">[1-4]消费消息及封装DefaultMQPushConsumer支持spring</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/01/23/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-5-%E4%B9%8B%E5%8F%91%E9%80%81%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%8F%8A%E5%B0%81%E8%A3%85TransactionMQProducer%E6%94%AF%E6%8C%81spring/">[1-5]发送事务消息实现分布式事务及封装TransactionMQProducer支持spring</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/03/28/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E9%87%8D%E8%AF%95/">[1-6]跟我学RocketMQ之消息重试</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/03/28/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89/">[1-7]跟我学RocketMQ之消息幂等</a></td>
</tr>
</tbody>
</table>
<a id="more"></a>
<h2 id="Dubbo"><a href="#Dubbo" class="headerlink" title="Dubbo"></a>Dubbo</h2><table>
<thead>
<tr>
<th style="text-align:left">文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2017/01/26/Dubbo%E6%A1%86%E6%9E%B6-1-Dubbo%E5%85%A5%E9%97%A8%E5%AE%9E%E4%BE%8B/">Dubbo框架(1)Dubbo入门实例</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/02/20/dubbo-springboot2-x%E6%95%B4%E5%90%88dubbo%E4%B9%8B%E4%BD%BF%E7%94%A8dubbo-spring-boot-starter/">springboot2.x整合dubbo之使用dubbo-spring-boot-starter</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/02/20/dubbo-springboot2-x%E6%95%B4%E5%90%88dubbo%E4%B9%8B%E6%95%B4%E5%90%88dubbo2-6-5/">springboot2.x整合dubbo之整合dubbo2.6.5</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2017/09/30/SpringBoot%E6%95%B4%E5%90%88Dubbo%E5%AE%9E%E7%8E%B0RPC-SOA/">SpringBoot整合Dubbo实现RPC+SOA</a></td>
</tr>
</tbody>
</table>
<h2 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h2><table>
<thead>
<tr>
<th style="text-align:left">文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/03/11/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%B9%8B%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/">我说分布式之分库分表</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/03/12/%E8%B7%9F%E6%88%91%E5%AD%A6shardingjdbc%E4%B9%8Bshardingjdbc%E5%85%A5%E9%97%A8/">跟我学shardingjdbc之shardingjdbc入门</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/03/14/%E8%B7%9F%E6%88%91%E5%AD%A6shardingjdbc%E4%B9%8B%E4%BD%BF%E7%94%A8jasypt%E5%8A%A0%E5%AF%86%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E5%AF%86%E7%A0%81/">跟我学shardingjdbc之使用jasypt加密数据库连接密码</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/03/25/%E8%B7%9F%E6%88%91%E5%AD%A6shardingjdbc%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%BB%E9%94%AE%E5%8F%8A%E5%85%B6%E8%87%AA%E5%AE%9A%E4%B9%89/#qrcode">跟我学shardingjdbc之分布式主键及其自定义</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/03/26/%E8%B7%9F%E6%88%91%E5%AD%A6shardingjdbc%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E7%AD%96%E7%95%A5-%E5%A4%8D%E5%90%88%E5%88%86%E7%89%87%E7%AE%97%E6%B3%95%E8%87%AA%E5%AE%9A%E4%B9%89%E5%AE%9E%E7%8E%B0/">跟我学shardingjdbc之自定义分库分表策略-复合分片算法自定义实现</a></td>
</tr>
</tbody>
</table>
<h2 id="Nacos"><a href="#Nacos" class="headerlink" title="Nacos"></a>Nacos</h2><table>
<thead>
<tr>
<th style="text-align:left">文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/02/22/springboot2-x%E6%95%B4%E5%90%88nacos%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E9%85%8D%E7%BD%AE%E8%8E%B7%E5%8F%96%E5%8F%8A%E5%88%B7%E6%96%B0/">springboot2.x整合nacos配置服务实现配置获取及刷新</a></td>
</tr>
</tbody>
</table>
<h2 id="自己写分布式组件系列"><a href="#自己写分布式组件系列" class="headerlink" title="自己写分布式组件系列"></a>自己写分布式组件系列</h2><table>
<thead>
<tr>
<th style="text-align:left">文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/09/03/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E6%A1%86%E6%9E%B61-TraceId-SpanId-ParentSpanId%E7%94%9F%E6%88%90%E5%8F%8A%E4%BC%A0%E9%80%92/">自己写分布式链路追踪框架1–TraceId/SpanId/ParentSpanId生成及传递</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/09/10/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E6%A1%86%E6%9E%B62-%E5%8C%85%E8%A3%85%E6%97%A5%E5%BF%97%E7%BB%84%E4%BB%B6%E8%87%AA%E5%8A%A8%E8%BE%93%E5%87%BAtraceId/">自己写分布式链路追踪框架2-包装日志组件自动输出traceId</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/02/21/%E8%87%AA%E5%B7%B1%E5%86%99dubbo%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E5%B7%A5%E5%85%B7%E5%8C%85-%E5%AE%9E%E7%8E%B0dubbo%E8%B0%83%E7%94%A8%E4%B8%AD%E4%BC%A0%E9%80%92%E6%89%93%E5%8D%B0TraceId-%E5%BC%80%E5%8F%91%E5%8F%8A%E5%8E%9F%E7%90%86%E7%AF%87/">自己写dubbo链路追踪工具包-实现dubbo调用中传递打印TraceId[开发及原理篇]</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/02/21/%E8%87%AA%E5%B7%B1%E5%86%99dubbo%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E5%B7%A5%E5%85%B7%E5%8C%85-%E5%AE%9E%E7%8E%B0dubbo%E8%B0%83%E7%94%A8%E4%B8%AD%E4%BC%A0%E9%80%92%E6%89%93%E5%8D%B0TraceId-%E5%AE%9E%E6%88%98%E6%95%B4%E5%90%88%E7%AF%87/">自己写dubbo链路追踪工具包-实现dubbo调用中传递打印TraceId[实战整合篇]</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/12/07/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81-%E5%9F%BA%E4%BA%8Eredission/">自己写分布式锁–基于redission</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/12/05/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83-%E5%8D%95%E6%9C%BA%E6%A8%A1%E5%BC%8F/">自己写分布式配置中心[上篇]-单机模式</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/10/27/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81%E7%BB%84%E4%BB%B6-%E5%9F%BA%E4%BA%8ERedis%E7%9A%84RateLimter/">自己写分布式限流组件-基于Redis的RateLimter</a></td>
</tr>
</tbody>
</table>
<h2 id="Skywalking"><a href="#Skywalking" class="headerlink" title="Skywalking"></a>Skywalking</h2><table>
<thead>
<tr>
<th style="text-align:left">文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/02/14/SkyWalking%E5%88%86%E5%B8%83%E5%BC%8F%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E9%83%A8%E7%BD%B2%E5%88%9D%E6%8E%A2/">SkyWalking分布式链路追踪部署初探</a></td>
</tr>
</tbody>
</table>
<h2 id="JDK源码解析"><a href="#JDK源码解析" class="headerlink" title="JDK源码解析"></a>JDK源码解析</h2><table>
<thead>
<tr>
<th style="text-align:left">文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/12/JUC%E4%B9%8BAQS-CountDownLatch%E5%B0%8F%E7%BB%93/">JUC之AQS-CountDownLatch小结</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/15/JUC%E4%B9%8BAQS-Semaphore%E5%B0%8F%E7%BB%93/">JUC之AQS-Semaphore小结</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/15/JUC%E4%B9%8BAQS-CyclicBarrier%E5%B0%8F%E7%BB%93/">JUC之AQS-CyclicBarrier小结</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/29/JDK%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-4-ThreadLocal/">JDK源码解析[4]-ThreadLocal</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/22/JDK%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-3-Thread/">JDK源码解析[3]-Thread</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/15/JDK%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-2-String/">JDK源码解析[2]-String</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/08/JDK%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-1-Object/">JDK源码解析[1]-Object</a></td>
</tr>
</tbody>
</table>
<h2 id="开发技巧及编码规范"><a href="#开发技巧及编码规范" class="headerlink" title="开发技巧及编码规范"></a>开发技巧及编码规范</h2><table>
<thead>
<tr>
<th style="text-align:left">文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/03/%E4%BB%A3%E7%A0%81%E5%BF%83%E5%BE%97-spring%E5%85%A8%E5%B1%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E7%AE%80%E5%8C%96%E4%BB%A3%E7%A0%81%E9%80%BB%E8%BE%91/">代码心得–spring全局异常处理简化代码逻辑</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2017/04/07/%E6%A6%82%E8%BF%B0facade%E5%B1%82-service%E5%B1%82-domain%E5%B1%82-dao%E5%B1%82%E8%AE%BE%E8%AE%A1/">概述facade层,service层,domain层,dao层设计</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/04/17/%E8%B7%9F%E6%88%91%E5%AD%A6SPI%E4%B9%8BSPI%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%AE%9E%E6%88%98/">跟我学SPI之SPI详解及实战</a></td>
</tr>
</tbody>
</table>
<h2 id="Springboot进阶"><a href="#Springboot进阶" class="headerlink" title="Springboot进阶"></a>Springboot进阶</h2><table>
<thead>
<tr>
<th style="text-align:left">文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/05/Spring-Boot-%E9%85%8D%E7%BD%AE%E4%BC%98%E5%85%88%E7%BA%A7%E9%A1%BA%E5%BA%8F/">Spring Boot 配置优先级顺序</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/10/Springboot%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E9%AD%94%E6%B3%95%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89starter/">Springboot自动配置魔法之自定义starter</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2017/11/19/Spring%C2%80%C2%80%C2%80%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD%E5%B1%9E%E6%80%A7%E5%92%8C%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/">Spring事务传播属性和隔离级别</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2017/11/06/springboot%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6properties%E8%8E%B7%E5%8F%96pom-xml%E4%B8%AD%E7%9A%84%E5%B1%9E%E6%80%A7/">springboot配置文件properties获取pom.xml中的属性</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2017/11/19/Spring%C2%80%C2%80%C2%80%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD%E5%B1%9E%E6%80%A7%E5%92%8C%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/">Spring事务传播属性和隔离级别</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/23/springboot%E6%95%B4%E5%90%88redis%E5%B0%8F%E7%BB%93/">springboot整合redis小结</a></td>
</tr>
</tbody>
</table>
<h2 id="高并发技术点-我说分布式、云原生"><a href="#高并发技术点-我说分布式、云原生" class="headerlink" title="高并发技术点/我说分布式、云原生"></a>高并发技术点/我说分布式、云原生</h2><table>
<thead>
<tr>
<th style="text-align:left">文章链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2017/04/11/%E6%B5%85%E8%B0%88MVCC/">浅谈MVCC</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2017/03/28/%E4%B9%90%E8%A7%82%E9%94%81%E5%92%8C%E6%82%B2%E8%A7%82%E9%94%81%E7%AE%80%E4%BB%8B/">乐观锁和悲观锁简介</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2017/04/07/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%B9%82%E7%AD%89%E6%80%A7/">高并发系统数据幂等性</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2018/07/08/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%A4%9A%E7%A7%8D%E5%AE%9E%E7%8E%B0/">我说分布式之分布式锁的多种实现</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/03/18/%E6%88%91%E8%AF%B4%E4%BA%91%E5%8E%9F%E7%94%9F%E4%B9%8B%E5%AE%B9%E5%99%A8%E5%8C%96%E4%B8%8E%E5%BA%94%E7%94%A8%E6%97%A0%E7%8A%B6%E6%80%81/">我说云原生之容器化与应用无状态</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://wuwenliang.net/2019/05/13/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%B9%8BGossip%E5%8D%8F%E8%AE%AE%E4%B8%8ERaft%E7%AE%97%E6%B3%95%E6%A6%82%E8%A7%88/">我说分布式之Gossip协议与Raft算法概览</a></td>
</tr>
</tbody>
</table>
<h2 id="后端开发参考书籍–Java分布式开发技术栈"><a href="#后端开发参考书籍–Java分布式开发技术栈" class="headerlink" title="后端开发参考书籍–Java分布式开发技术栈"></a>后端开发参考书籍–Java分布式开发技术栈</h2><blockquote>
<p>持续更新，排名不分先后</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">书名</th>
<th style="text-align:left">介绍</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">《Java并发编程之美》</td>
<td style="text-align:left">近期出版的新书，从源码层次去讲解并发相关的知识，很实战。</td>
</tr>
<tr>
<td style="text-align:left">《从零开始学架构》</td>
<td style="text-align:left">原本是极客时间的一个专栏，后来出了书，不多说，读了这本书基本上对分布式架构会有一个较为系统的认知。谁读谁知道</td>
</tr>
<tr>
<td style="text-align:left">《设计模式之禅》</td>
<td style="text-align:left">面向对象企业级编程，不学设计模式就谈不上熟练，这本书是读过的关于设计模式比较良心的一本，可读性和可操作性都蛮不错，建议常备</td>
</tr>
<tr>
<td style="text-align:left">《Java编程的逻辑》</td>
<td style="text-align:left">从源码层学习core  Java的一本好书，对于集合框架、JUC框架都讲解的很深入</td>
</tr>
<tr>
<td style="text-align:left">《精通Spring4.x企业应用开发实战》</td>
<td style="text-align:left">学习Spring框架，这本书就足够了。</td>
</tr>
<tr>
<td style="text-align:left">《SpringBoot编程思想》</td>
<td style="text-align:left">光会用SpringBoot，可能勉强算入门。懂原理，读过源码，才能自信的说熟悉了吧。建议有追求的同学们读一下这本书</td>
</tr>
<tr>
<td style="text-align:left">《Effective Java第三版》</td>
<td style="text-align:left">Java编程规范中的圣经，第三版都出了，不赶紧入一本吗</td>
</tr>
<tr>
<td style="text-align:left">《Java8实战》</td>
<td style="text-align:left">还在用Java7甚至以下版本？那你可落后了，JDK12都出了，快学学函数式编程吧</td>
</tr>
<tr>
<td style="text-align:left">《从Paxos到zookeeper分布式一致性原理与实战》</td>
<td style="text-align:left">学习zookeeper的必备圣经，读过这本书，基本对zk就不会发怵了</td>
</tr>
<tr>
<td style="text-align:left">《Kubernates权威指南 纪念版》</td>
<td style="text-align:left">K8S圣经级别的书，建议想学K8S的同学备一本，买的话直接入纪念版吧，不会吃亏。</td>
</tr>
<tr>
<td style="text-align:left">《SpringBoot实战》汪云飞著</td>
<td style="text-align:left">学SpringBoot这本可以瞅瞅，不过建议直接官方文档走起吧，不行还有中文版文档不是</td>
</tr>
<tr>
<td style="text-align:left">《深入理解Java虚拟机第二版》</td>
<td style="text-align:left">如何提升对JVM的理解，如何开始调优之路，如何优雅的和他人交(zhuang)流(bi)，读过这本书两次，你会感谢我。</td>
</tr>
<tr>
<td style="text-align:left">《RocketMQ技术内幕》</td>
<td style="text-align:left">源码解析RocketMQ, 官方出品，必须精品。想深入学习RocketMQ, 这本书可以一读，很干，很干，建议配合白开水使用</td>
</tr>
<tr>
<td style="text-align:left">《云原生应用架构实践》</td>
<td style="text-align:left">还在聊分布式、微服务吗？你可能out了，现在我们来聊聊云原生吧。这本书是网易云团队出的关于容器化、云原生的一本书，系统的对企业自建应用层云服务做出了详细的阐述，很值得一读。</td>
</tr>
</tbody>
</table>
<p>…未完待续…</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文为分布式系列文章的集锦汇总，长期保持置顶及更新，读者可以在本文中更好的学习到某个具体的系列。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;我说分布式事务系列&quot;&gt;&lt;a href=&quot;#我说分布式事务系列&quot; class=&quot;headerlink&quot; title=&quot;我说分布式事务系列&quot;&gt;&lt;/a&gt;我说分布式事务系列&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:left&quot;&gt;文章链接&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2018/11/20/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8BTCC/&quot;&gt;我说分布式事务之TCC&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2018/12/06/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B%E6%9C%80%E5%A4%A7%E5%8A%AA%E5%8A%9B%E9%80%9A%E7%9F%A5%E5%9E%8B%E4%BA%8B%E5%8A%A1/&quot;&gt;我说分布式事务之最大努力通知型事务&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2018/12/13/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B%E5%8F%AF%E9%9D%A0%E6%B6%88%E6%81%AF%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E4%BA%8B%E5%8A%A11-%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/&quot;&gt;我说分布式事务之可靠消息最终一致性事务1-原理及实现&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2018/12/13/%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B%E6%B6%88%E6%81%AF%E4%B8%80%E8%87%B4%E6%80%A7%E4%BA%8B%E5%8A%A12-rocketmq%E7%9A%84%E5%AE%9E%E7%8E%B0/&quot;&gt;我说分布式事务之消息一致性事务2-rocketmq的实现&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2018/12/13/%E3%80%90%E6%B1%87%E6%80%BB%E3%80%91%E6%88%91%E8%AF%B4%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%B3%BB%E5%88%97/&quot;&gt;【汇总】我说分布式事务系列&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2017/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B%E8%81%8A%E8%81%8ATCC/&quot;&gt;分布式事务之聊聊TCC&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2017/04/09/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E5%B8%B8%E7%94%A8%E6%96%B9%E6%A1%88/&quot;&gt;分布式事务最终一致性常用方案&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;跟我学RocketMQ&quot;&gt;&lt;a href=&quot;#跟我学RocketMQ&quot; class=&quot;headerlink&quot; title=&quot;跟我学RocketMQ&quot;&gt;&lt;/a&gt;跟我学RocketMQ&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:left&quot;&gt;文章链接&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2019/01/09/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-1-%E4%B9%8B%E5%AE%89%E8%A3%85RocketMQ/&quot;&gt;[1-1]安装RocketMQ&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2019/01/09/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-2-%E4%B9%8B%E5%AE%89%E8%A3%85RocketMQ-Console%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0/&quot;&gt;[1-2]安装RocketMQ-Console管理平台&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2019/01/23/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-3-%E4%B9%8B%E5%8F%91%E9%80%81%E6%99%AE%E9%80%9A%E6%B6%88%E6%81%AF%E5%8F%8A%E5%B0%81%E8%A3%85DefaultMQProducer%E6%94%AF%E6%8C%81spring/&quot;&gt;[1-3]发送普通消息及封装DefaultMQProducer支持spring&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2019/01/23/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-4-%E4%B9%8B%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%E5%8F%8A%E5%B0%81%E8%A3%85DefaultMQPushConsumer%E6%94%AF%E6%8C%81spring/&quot;&gt;[1-4]消费消息及封装DefaultMQPushConsumer支持spring&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2019/01/23/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-5-%E4%B9%8B%E5%8F%91%E9%80%81%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%8F%8A%E5%B0%81%E8%A3%85TransactionMQProducer%E6%94%AF%E6%8C%81spring/&quot;&gt;[1-5]发送事务消息实现分布式事务及封装TransactionMQProducer支持spring&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2019/03/28/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E9%87%8D%E8%AF%95/&quot;&gt;[1-6]跟我学RocketMQ之消息重试&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:left&quot;&gt;&lt;a href=&quot;http://wuwenliang.net/2019/03/28/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89/&quot;&gt;[1-7]跟我学RocketMQ之消息幂等&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
    
    </summary>
    
      <category term="汇总盘点推荐" scheme="http://wuwenliang.net/categories/%E6%B1%87%E6%80%BB%E7%9B%98%E7%82%B9%E6%8E%A8%E8%8D%90/"/>
    
    
      <category term="汇总盘点推荐" scheme="http://wuwenliang.net/tags/%E6%B1%87%E6%80%BB%E7%9B%98%E7%82%B9%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>springboot2.x整合nacos配置服务实现配置获取及刷新</title>
    <link href="http://wuwenliang.net/2019/02/22/springboot2-x%E6%95%B4%E5%90%88nacos%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E9%85%8D%E7%BD%AE%E8%8E%B7%E5%8F%96%E5%8F%8A%E5%88%B7%E6%96%B0/"/>
    <id>http://wuwenliang.net/2019/02/22/springboot2-x整合nacos配置服务实现配置获取及刷新/</id>
    <published>2019-02-22T05:55:22.000Z</published>
    <updated>2019-02-26T13:01:45.775Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://wuwenliang.net/2019/02/22/springboot2-x%E6%95%B4%E5%90%88nacos%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E9%85%8D%E7%BD%AE%E8%8E%B7%E5%8F%96%E5%8F%8A%E5%88%B7%E6%96%B0/">原文链接</a></p>
<p>本文我将带领大家在springboot2.x的开发框架中整合alibaba-nacos，实现配置获取及刷新等功能。</p>
<p>引用官方介绍：</p>
<blockquote>
<p>Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您实现动态服务发现、服务配置管理、服务及流量管理。<br>Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。<br>Nacos 是构建以“服务”为中心的现代应用架构(例如微服务范式、云原生范式)的服务基础设施。</p>
</blockquote>
<p>可以看到，Nacos主要面向分布式配置级服务发现等领域，由于之前使用过阿里云的ACM配置服务体验良好，而Nacos便是ACM的开源版本，因此我们选择了Nacos作为<br>业务框架的分布式配置中心。</p>
<p>接下来开始进行Nacos的整合。<br><a id="more"></a><br>开始之前，要保证已经搭建好Nacos平台。</p>
<p>如何安装Nacos的Server请移步 <a href="https://nacos.io/zh-cn/docs/quick-start.html" target="_blank" rel="external">安装Nacos</a></p>
<h2 id="引入nacos-config-spring-boot-starter"><a href="#引入nacos-config-spring-boot-starter" class="headerlink" title="引入nacos-config-spring-boot-starter"></a>引入nacos-config-spring-boot-starter</h2><p>在pom.xml中添加如下依赖</p>
<pre><code>&lt;!--nacos-discovery-spring-boot-starter--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt;
    &lt;artifactId&gt;nacos-config-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;0.2.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>由于我们的项目的基础是springboot2.x，使用版本0.2.1即可。对于springboot1.x版本需要引入下面的依赖</p>
<pre><code>&lt;!--nacos-discovery-spring-boot-starter--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt;
    &lt;artifactId&gt;nacos-config-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;0.1.1&lt;/version&gt;
&lt;/dependency&gt;  
</code></pre><h2 id="application-properties中引入Nacos的config-server地址"><a href="#application-properties中引入Nacos的config-server地址" class="headerlink" title="application.properties中引入Nacos的config-server地址"></a>application.properties中引入Nacos的config-server地址</h2><p>在application.properties中添加如下配置</p>
<pre><code>##########################################################################
#
#     Nacos配置
#
##########################################################################
nacos.config.server-addr=172.30.xx.xx:8848,172.30.xx.xx:8848,172.30.xx.xx:8848
</code></pre><p>我这里使用的nacos服务端是集群模式，地址做了脱敏处理。</p>
<h2 id="编写配置读取类NacosConfigAnnoatationService"><a href="#编写配置读取类NacosConfigAnnoatationService" class="headerlink" title="编写配置读取类NacosConfigAnnoatationService"></a>编写配置读取类NacosConfigAnnoatationService</h2><p>Nacos的springboot客户端，提供了简洁易用的API，支持注解方式对配置进行读取即刷新。</p>
<pre><code>@Service
@NacosPropertySource(dataId = &quot;com.gaoyang.marketing.rocketmq.order&quot;, groupId=&quot;DEFAULT_GROUP&quot;, autoRefreshed = true)
public class NacosConfigAnnoatationService implements CommandLineRunner {

    private static final Logger LOGGER = LoggerFactory.getLogger(NacosConfigAnnoatationService.class);

    /**
     * ${name:hello}:key=name,默认值=hello
     */
    @NacosValue(value = &quot;${name:hello}&quot;, autoRefreshed = true)
    String name;

    @NacosValue(value = &quot;${interest:world}&quot;, autoRefreshed = true)
    String interest;

    @Override
    public void run(String... args) throws Exception {
        while (true) {
            Thread.sleep(4000);
            LOGGER.info(&quot;[NacosConfigAnnoatationService]注解方式获取到的配置项目,name={},interest={}&quot;, name, interest);
        }
    }
}
</code></pre><p>接下来对代码进行详细的解释。</p>
<p>我们编写了一个测试类，标记为spring的一个Service, 同时标注</p>
<pre><code>@NacosPropertySource(dataId = &quot;com.gaoyang.marketing.rocketmq.order&quot;, groupId=&quot;DEFAULT_GROUP&quot;, autoRefreshed = true)
</code></pre><p>使用 <strong>@NacosPropertySource</strong> 加载 dataId 为 com.gaoyang.marketing.rocketmq.order ，groupId如果不配置，则默认为<br><strong>DEFAULT_GROUP</strong> 的配置源，并开启自动更新。</p>
<p>通过spring的 <strong>@Value</strong> 注入配置，这里的两个配置是我在后台建立好的，如何建立配置在下一章节进行详细的展开。</p>
<p>以name配置项为例，添加注解</p>
<pre><code>@NacosValue(value = &quot;${name:hello}&quot;, autoRefreshed = true)
</code></pre><p>我们通过@NacosValue 注解设置属性值，name:hello 表示key为name的配置项的默认值为<br>hello，autoRefreshed=true表示开启自动刷新。</p>
<p>我们通过死循环来测试自动刷新是否生效。</p>
<h2 id="控制台配置配置项"><a href="#控制台配置配置项" class="headerlink" title="控制台配置配置项"></a>控制台配置配置项</h2><p>首先进入Nacos配置页面，输入账号密码，进行登录，如图</p>
<p><img src="/2019/02/22/springboot2-x整合nacos配置服务实现配置获取及刷新/./login.png" alt="登录Naocs控制台"></p>
<p>登录成功后在左侧菜单一次展开</p>
<pre><code>配置管理
    |-配置列表
</code></pre><p><img src="/2019/02/22/springboot2-x整合nacos配置服务实现配置获取及刷新/./add2.png" alt="配置列表"></p>
<p>点击 “+” 增加配置项。必填项为：dataId，groupId，配置内容。如图所示</p>
<p><img src="/2019/02/22/springboot2-x整合nacos配置服务实现配置获取及刷新/./add1.png" alt="新增配置"></p>
<p>填写完成后提交即可。</p>
<h2 id="测试配置更新"><a href="#测试配置更新" class="headerlink" title="测试配置更新"></a>测试配置更新</h2><p>我们首先运行样例，将项目启动。springboot中，对于标注了 <strong>@CommandLineRunner</strong> 的类，会在项目启动完后自动加载运行run()方法。</p>
<p>控制台打印如下内容，四秒打印一次，我截取一部分如下</p>
<pre><code>2019-02-22 11:54:51.209 [main] INFO  c.g.m.d.p.config.NacosConfigAnnoatationService [37] - 
[NacosConfigAnnoatationService]注解方式获取到的配置项目,name=snowalker,interest=coding
2019-02-22 11:54:55.209 [main] INFO  c.g.m.d.p.config.NacosConfigAnnoatationService [37] - 
[NacosConfigAnnoatationService]注解方式获取到的配置项目,name=snowalker,interest=coding
2019-02-22 11:54:59.210 [main] INFO  c.g.m.d.p.config.NacosConfigAnnoatationService [37] - 
[NacosConfigAnnoatationService]注解方式获取到的配置项目,name=snowalker,interest=coding
</code></pre><p>保持项目运行，我们进入管理控制台，在配置列表我们的那一项，点击 <strong>编辑</strong></p>
<p>修改name对应的配置为 snowalker23333 点击发布如图</p>
<p><img src="/2019/02/22/springboot2-x整合nacos配置服务实现配置获取及刷新/./update.png" alt="修改配置"></p>
<p>Nacos后台很贴心的为我们让我们对修改前后的配置项进行二次确认，点击确认发布后，查看控制台日志</p>
<pre><code>2019-02-22 11:55:23.214 [main] INFO  c.g.m.d.p.config.NacosConfigAnnoatationService [37] -
[NacosConfigAnnoatationService]注解方式获取到的配置项目,name=snowalker,interest=coding
2019-02-22 11:55:27.215 [main] INFO  c.g.m.d.p.config.NacosConfigAnnoatationService [37] - 
[NacosConfigAnnoatationService]注解方式获取到的配置项目,name=snowalker2333333,interest=code
2019-02-22 11:55:31.215 [main] INFO  c.g.m.d.p.config.NacosConfigAnnoatationService [37] - 
[NacosConfigAnnoatationService]注解方式获取到的配置项目,name=snowalker2333333,interest=code
</code></pre><p>可以看到，在项目运行的过程中，配置项热更新了。</p>
<p>它内部是通过一个Listener监听器在后台监听服务端的推送消息，达到对配置项的热更新的，和配置文件比起来相当方便了。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文主要从实战的角度，带领读者在springboot2.x中整合了Nacos实现了配置的读取及刷新的功能，从应用的角度出发，应当足够日常开发使用了，更多的<br>使用技巧和实现细节，我们有机会再讲。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://wuwenliang.net/2019/02/22/springboot2-x%E6%95%B4%E5%90%88nacos%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E9%85%8D%E7%BD%AE%E8%8E%B7%E5%8F%96%E5%8F%8A%E5%88%B7%E6%96%B0/&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文我将带领大家在springboot2.x的开发框架中整合alibaba-nacos，实现配置获取及刷新等功能。&lt;/p&gt;
&lt;p&gt;引用官方介绍：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您实现动态服务发现、服务配置管理、服务及流量管理。&lt;br&gt;Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。&lt;br&gt;Nacos 是构建以“服务”为中心的现代应用架构(例如微服务范式、云原生范式)的服务基础设施。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可以看到，Nacos主要面向分布式配置级服务发现等领域，由于之前使用过阿里云的ACM配置服务体验良好，而Nacos便是ACM的开源版本，因此我们选择了Nacos作为&lt;br&gt;业务框架的分布式配置中心。&lt;/p&gt;
&lt;p&gt;接下来开始进行Nacos的整合。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/categories/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/tags/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>自己写dubbo链路追踪工具包-实现dubbo调用中传递打印TraceId[实战整合篇]</title>
    <link href="http://wuwenliang.net/2019/02/21/%E8%87%AA%E5%B7%B1%E5%86%99dubbo%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E5%B7%A5%E5%85%B7%E5%8C%85-%E5%AE%9E%E7%8E%B0dubbo%E8%B0%83%E7%94%A8%E4%B8%AD%E4%BC%A0%E9%80%92%E6%89%93%E5%8D%B0TraceId-%E5%AE%9E%E6%88%98%E6%95%B4%E5%90%88%E7%AF%87/"/>
    <id>http://wuwenliang.net/2019/02/21/自己写dubbo链路追踪工具包-实现dubbo调用中传递打印TraceId-实战整合篇/</id>
    <published>2019-02-21T01:34:35.000Z</published>
    <updated>2019-02-27T16:19:38.339Z</updated>
    
    <content type="html"><![CDATA[<p>在上文 <a href="http://wuwenliang.net/2019/02/21/%E8%87%AA%E5%B7%B1%E5%86%99dubbo%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E5%B7%A5%E5%85%B7%E5%8C%85-%E5%AE%9E%E7%8E%B0dubbo%E8%B0%83%E7%94%A8%E4%B8%AD%E4%BC%A0%E9%80%92%E6%89%93%E5%8D%B0TraceId-%E5%BC%80%E5%8F%91%E5%8F%8A%E5%8E%9F%E7%90%86%E7%AF%87/">文章链接</a> 中，我从原理及代码实现的角度，完整的呈现了如何基于Dubbo的Filter及SPI机制开发TraceId的开发包。</p>
<p>本文中，我将着重从实战角度展现如何在项目中使用该工具包，实现TraceId的传递及日志打印。</p>
<h2 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h2><p>将开发好的工具包（名为shield-dubbo-tracer，<a href="https://github.com/TaXueWWL/shield-dubbo-tracer" target="_blank" rel="external">代码地址</a>）打包并上传至私服，添加坐标到我们的dubbo项目的pom.xml中。<strong>注意</strong>，由于工具包依赖dubbo，因此同时要添加dubbo的依赖，完整的依赖如下：（服务提供方和服务消费方中都需要添加）<br><a id="more"></a></p>
<pre><code>&lt;!--dubbo traceId工具--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.snowalker.shield.dubbo.tracer&lt;/groupId&gt;
    &lt;artifactId&gt;shield-dubbo-tracer&lt;/artifactId&gt;
    &lt;version&gt;0.1.0&lt;/version&gt;
&lt;/dependency&gt;
&lt;!-- dubbo依赖开始 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
    &lt;artifactId&gt;dubbo&lt;/artifactId&gt;
    &lt;version&gt;2.6.5&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;
    &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;
    &lt;version&gt;${zookeeper.version}&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
    &lt;artifactId&gt;curator-framework&lt;/artifactId&gt;
    &lt;version&gt;${curator-framework.version}&lt;/version&gt;
&lt;/dependency&gt;
&lt;!-- dubbo依赖结束 --&gt;
</code></pre><p>引入依赖即可，不需要额外的多余配置。</p>
<p>接下来就是在服务提供方和消费方之间进行服务调用，验证功能。</p>
<p>dubbo相关的配置请参考如下文章，本文不再赘述</p>
<p><a href="http://wuwenliang.net/2019/02/20/dubbo-springboot2-x%E6%95%B4%E5%90%88dubbo%E4%B9%8B%E4%BD%BF%E7%94%A8dubbo-spring-boot-starter/">[dubbo]springboot2.x整合dubbo之使用dubbo-spring-boot-starter
</a></p>
<p><a href="http://wuwenliang.net/2019/02/20/dubbo-springboot2-x%E6%95%B4%E5%90%88dubbo%E4%B9%8B%E6%95%B4%E5%90%88dubbo2-6-5/">[dubbo]springboot2.x整合dubbo之基于xml整合dubbo2.6.5
</a></p>
<h2 id="服务消费者逻辑"><a href="#服务消费者逻辑" class="headerlink" title="服务消费者逻辑"></a>服务消费者逻辑</h2><h3 id="消费者业务逻辑"><a href="#消费者业务逻辑" class="headerlink" title="消费者业务逻辑"></a>消费者业务逻辑</h3><pre><code>@Service
public class ChargeWalletConsumerService {

    /**dubbo服务接口*/
    @Autowired
    ChargeWalletFacade chargeWalletFacade;

    public void chargeWallet(ChargeWalletRequestData requestData) {
        TraceIdGenerator.createTraceId();
        String traceId = TraceIdUtil.getTraceId();
        System.out.println(&quot;[服务消费方]执行业务逻辑开始,traceId=&quot; + traceId);
        chargeWalletFacade.chargeWallet(requestData);
    }

}
</code></pre><p>逻辑很简单，在服务消费者侧，更准确的说是服务调用发起侧，需要显式调用TraceId的生成方法，</p>
<pre><code>TraceIdGenerator.createTraceId();
</code></pre><p>如果不调用，工具包会默认分配一个，但是在调用开始时候就获取不到了，因此从开发方便的角度，建议还是要显式的调用一次。</p>
<h3 id="消费者调用服务代码"><a href="#消费者调用服务代码" class="headerlink" title="消费者调用服务代码"></a>消费者调用服务代码</h3><pre><code>ApplicationContext context = SpringApplication.run(OrderApplication.class, args);
ChargeWalletConsumerService chargeWalletConsumerService =
        context.getBean(&quot;chargeWalletConsumerService&quot;, ChargeWalletConsumerService.class);
chargeWalletConsumerService.chargeWallet(new ChargeWalletRequestData());
</code></pre><p>逻辑很简单，从上下文中取到ChargeWalletConsumerService对应的bean，并调用业务方法，从而发起对远程服务的调用。</p>
<h2 id="服务提供方逻辑"><a href="#服务提供方逻辑" class="headerlink" title="服务提供方逻辑"></a>服务提供方逻辑</h2><p>接着是服务提供方，引入配置后也不需要额外的配置。</p>
<h3 id="服务提供方代码逻辑"><a href="#服务提供方代码逻辑" class="headerlink" title="服务提供方代码逻辑"></a>服务提供方代码逻辑</h3><pre><code>public class ChargeWalletFacadeImpl implements ChargeWalletFacade {

    @Resource(name = &quot;walletService&quot;)
    WalletService walletService;

    @Override
    public ResponseData&lt;ChargeWalletRepsonseData&gt; chargeWallet(ChargeWalletRequestData requestData) {
        String traceId = TraceIdUtil.getTraceId();
        System.out.println(&quot;[服务提供方]测试服务提供方,traceId=&quot; + traceId);
        return null;
    }
}
</code></pre><p>读者这里可能会有疑问，这个服务实现类没有添加任何注解啊？</p>
<p>不要紧张，我这里用的是xml的配置方式，该服务实现类已经在applicationContext-dubbo-service.xml中配置好了，核心配置如下：</p>
<pre><code>&lt;dubbo:service interface=&quot;com.gaoyang.marketing.dev.prototype.dubbo.api.ChargeWalletFacade&quot;
               ref=&quot;chargeWalletFacadeImpl&quot;
               version=&quot;1.0&quot; group=&quot;wallet&quot;
               timeout=&quot;3000&quot; owner=&quot;snowalker&quot; /&gt;
</code></pre><p>在20880端口暴露该服务。</p>
<p>到这里我们的测试代码就开发完成。</p>
<h2 id="测试TraceId传递"><a href="#测试TraceId传递" class="headerlink" title="测试TraceId传递"></a>测试TraceId传递</h2><ol>
<li>首先启动服务提供方</li>
<li>启动服务消费方，main方法中发起对提供方的调用</li>
<li>观察提供方及消费方的控制台打印情况。</li>
</ol>
<h3 id="服务消费方日志打印"><a href="#服务消费方日志打印" class="headerlink" title="服务消费方日志打印"></a>服务消费方日志打印</h3><pre><code>[服务消费方]执行业务逻辑开始,traceId=ac1e535620190221091119953783494f
</code></pre><h3 id="服务提供方日志打印"><a href="#服务提供方日志打印" class="headerlink" title="服务提供方日志打印"></a>服务提供方日志打印</h3><pre><code>[服务提供方]测试服务提供方,traceId=ac1e535620190221091119953783494f
</code></pre><p>可以看到，traceId已经从消费方传递至提供方，并能够灵活的取出做日志打印。</p>
<p>dubbo服务之间通过RpcContext隐式传参，在服务线程内通过TraceUtil上下文直接获取。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这里，我们就完成了集成TraceId工具包shield-dubbo-tracer的整合及测试工作，可以看到，整合过程是蛮简洁的，调用过程也是比较直观的，希望该工具包能够对大家做TraceId日志监控、链路追踪等工作有所帮助吧。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上文 &lt;a href=&quot;http://wuwenliang.net/2019/02/21/%E8%87%AA%E5%B7%B1%E5%86%99dubbo%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E5%B7%A5%E5%85%B7%E5%8C%85-%E5%AE%9E%E7%8E%B0dubbo%E8%B0%83%E7%94%A8%E4%B8%AD%E4%BC%A0%E9%80%92%E6%89%93%E5%8D%B0TraceId-%E5%BC%80%E5%8F%91%E5%8F%8A%E5%8E%9F%E7%90%86%E7%AF%87/&quot;&gt;文章链接&lt;/a&gt; 中，我从原理及代码实现的角度，完整的呈现了如何基于Dubbo的Filter及SPI机制开发TraceId的开发包。&lt;/p&gt;
&lt;p&gt;本文中，我将着重从实战角度展现如何在项目中使用该工具包，实现TraceId的传递及日志打印。&lt;/p&gt;
&lt;h2 id=&quot;引入依赖&quot;&gt;&lt;a href=&quot;#引入依赖&quot; class=&quot;headerlink&quot; title=&quot;引入依赖&quot;&gt;&lt;/a&gt;引入依赖&lt;/h2&gt;&lt;p&gt;将开发好的工具包（名为shield-dubbo-tracer，&lt;a href=&quot;https://github.com/TaXueWWL/shield-dubbo-tracer&quot;&gt;代码地址&lt;/a&gt;）打包并上传至私服，添加坐标到我们的dubbo项目的pom.xml中。&lt;strong&gt;注意&lt;/strong&gt;，由于工具包依赖dubbo，因此同时要添加dubbo的依赖，完整的依赖如下：（服务提供方和服务消费方中都需要添加）&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="自己写分布式组件系列" scheme="http://wuwenliang.net/categories/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E7%BB%84%E4%BB%B6%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="自己写分布式组件系列" scheme="http://wuwenliang.net/tags/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E7%BB%84%E4%BB%B6%E7%B3%BB%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>自己写dubbo链路追踪工具包-实现dubbo调用中传递打印TraceId[开发及原理篇]</title>
    <link href="http://wuwenliang.net/2019/02/21/%E8%87%AA%E5%B7%B1%E5%86%99dubbo%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA%E5%B7%A5%E5%85%B7%E5%8C%85-%E5%AE%9E%E7%8E%B0dubbo%E8%B0%83%E7%94%A8%E4%B8%AD%E4%BC%A0%E9%80%92%E6%89%93%E5%8D%B0TraceId-%E5%BC%80%E5%8F%91%E5%8F%8A%E5%8E%9F%E7%90%86%E7%AF%87/"/>
    <id>http://wuwenliang.net/2019/02/21/自己写dubbo链路追踪工具包-实现dubbo调用中传递打印TraceId-开发及原理篇/</id>
    <published>2019-02-20T16:32:51.000Z</published>
    <updated>2019-02-28T15:04:13.160Z</updated>
    
    <content type="html"><![CDATA[<p>在近期的两篇文章中，我带领大家使用springboot2.x整合了dubbo，完成了一个基础的服务化开发框架的搭建。文章链接如下</p>
<p><a href="http://wuwenliang.net/2019/02/20/dubbo-springboot2-x%E6%95%B4%E5%90%88dubbo%E4%B9%8B%E4%BD%BF%E7%94%A8dubbo-spring-boot-starter/">[dubbo]springboot2.x整合dubbo之使用dubbo-spring-boot-starter
</a></p>
<p><a href="http://wuwenliang.net/2019/02/20/dubbo-springboot2-x%E6%95%B4%E5%90%88dubbo%E4%B9%8B%E6%95%B4%E5%90%88dubbo2-6-5/">[dubbo]springboot2.x整合dubbo之基于xml整合dubbo2.6.5
</a></p>
<p>但是在生产环境下还是存在一定的问题，比如我们关心的调用链追踪的问题。</p>
<p>本文中，我将继续带领大家基于dubbo2.6.5开发一个轻量级的TraceId获取及传递工具包，实现在dubbo服务的提供方及消费方中 <strong>设置/获取/传递</strong> TraceId的需求。</p>
<p><a href="https://github.com/TaXueWWL/shield-dubbo-tracer" target="_blank" rel="external">代码地址</a><br><a id="more"></a></p>
<h2 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h2><p>通过dubbo的Filter及扩展点机制，开发TraceId获取及传递的工具包，实现在服务业务的上下游中对TraceId的 <strong>设置/获取/传递</strong> 的需求。</p>
<h2 id="原理讲解"><a href="#原理讲解" class="headerlink" title="原理讲解"></a>原理讲解</h2><p>在编写代码之前，先对Filter机制和扩展点机制做一个简要的讲解，以便加深我们的理解，当然如果只是简单的整合使用该工具包，可以直接跳过这段，进入编码环节。</p>
<h3 id="Filter机制简述"><a href="#Filter机制简述" class="headerlink" title="Filter机制简述"></a>Filter机制简述</h3><p>Dubbo中的Filter与我们在javaweb中的Filter的理解是类似的，都是在请求处理前后做一些通用的逻辑，Filter可以有多个支持层层嵌套。</p>
<p>Dubbo官方针对Filter做了很多的原生支持，目前大致有20多个，包括我们熟知的RpcContext，accesslog等功能都是通过filter来实现的。</p>
<p>开发一个自定的Filter很简单，只需要编写我们的Filter类，实现<strong>com.alibaba.dubbo.rpc.Filter</strong> 接口，重写其invoke(Invoker&lt;?&gt; invoker, Invocation invocation) 方法即可。</p>
<p>具体的过程我将在下文展开讲解。</p>
<h3 id="SPI机制简述"><a href="#SPI机制简述" class="headerlink" title="SPI机制简述"></a>SPI机制简述</h3><p>这里直接引用官网的描述：</p>
<blockquote>
<p>SPI 全称为 Service Provider Interface，是一种服务发现机制。SPI 的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。正因此特性，我们可以很容易的通过 SPI 机制为我们的程序提供拓展功能。SPI 机制在第三方框架中也有所应用，比如 Dubbo 就是通过 SPI 机制加载所有的组件。不过，Dubbo 并未使用 Java 原生的 SPI 机制，而是对其进行了增强，使其能够更好的满足需求。</p>
</blockquote>
<p>Filter机制便是Dubbo中SPI的一个应用场景，Dubbo对java的原生SPI做了扩展，使Dubbo具备了更丰富的扩展性。</p>
<p>Dubbo官方对Dubbo的定位是微内核架构，不想依赖三方框架如Spring、Guice等，这使得Dubbo的实现更加的优雅。</p>
<blockquote>
<p>通常微核心都会采用 Factory、IoC、OSGi 等方式管理插件生命周期。考虑 Dubbo 的适用面，不想强依赖 Spring 等 IoC 容器。自已造一个小的 IoC 容器，也觉得有点过度设计，所以打算采用最简单的 Factory 方式管理插件。–引用自《扩展点重构》</p>
</blockquote>
<p>具体的细节可以参考文章最后的参考链接。</p>
<p>接下来就进入到我们的正式的设计编码环节。</p>
<h2 id="编码实现"><a href="#编码实现" class="headerlink" title="编码实现"></a>编码实现</h2><p>首先建立一个maven工程，我将其命名为shield-dubbo-tracer。</p>
<h3 id="依赖引入"><a href="#依赖引入" class="headerlink" title="依赖引入"></a>依赖引入</h3><p>在项目的pom.xml中引入必要的依赖，如下</p>
<pre><code>&lt;properties&gt;
    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
    &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;
&lt;/properties&gt;

&lt;dependencies&gt;
    &lt;!-- https://mvnrepository.com/artifact/com.alibaba/dubbo --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
        &lt;artifactId&gt;dubbo&lt;/artifactId&gt;
        &lt;version&gt;2.6.5&lt;/version&gt;
        &lt;scope&gt;provided &lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;junit&lt;/groupId&gt;
        &lt;artifactId&gt;junit&lt;/artifactId&gt;
        &lt;version&gt;4.11&lt;/version&gt;
        &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
        &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
        &lt;version&gt;1.7.22&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre><p>由于我们的工具包是基于dubbo运行的，因此要添加dubbo依赖，这里使用provided的作用域的原因是：我们不确定工具包的调用方具体使用哪个版本的dubbo，因此在打包的时候不需要将dubbo依赖都打到最终的jar中，保证我们工程的纯洁性和轻量性，同时也能很好的避免调用方出现依赖冲突的可能。</p>
<h3 id="编写TraceId生成类–TraceIdGenerator"><a href="#编写TraceId生成类–TraceIdGenerator" class="headerlink" title="编写TraceId生成类–TraceIdGenerator"></a>编写TraceId生成类–TraceIdGenerator</h3><p>首先定义一个名为TraceIdGenerator的类，该类主要用于生成TraceId，且类的作用域是public，可供外部直接调用，核心代码如下</p>
<pre><code>public class TraceIdGenerator {

    /**
    * 消费端创建TraceId,并设置到线程上下文中
    * 该方法只调用一次
    * @return
    */
    public static String createTraceId() {
        // 创建的同时就设置到上下文中
        String traceId = getTraceid();
        TraceIdUtil.setTraceId(traceId);
        return traceId;
    }

    /**
    * 生成32位traceId
    * @return
    */
    private static String getTraceid() {
        String result = &quot;&quot;;
        String ip = &quot;&quot;;

        // 获取本地ipv4地址
        try {
            InetAddress address = InetAddress.getLocalHost();
            ip = address.getHostAddress();
        } catch (Exception var5) {
            return result;
        }

        // 根据.截取为String数组
        String[] ipAddressInArray = ip.split(&quot;\\.&quot;);
        // 拼装为字符串,将每一个元素转换为16进制
        for(int i = 3; i &gt;= 0; --i) {
            Integer id = Integer.parseInt(ipAddressInArray[3 - i]);
            result = result + String.format(&quot;%02x&quot;, id);
        }
        // 拼装时间戳及随机数
        SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyyMMddHHmmssSSS&quot;);
        result = result + simpleDateFormat.format(new Date()) + UuidUtil.getUuid().substring(0, 7);
        return result;
    }

}
</code></pre><p>注释写的应当是比较详细的，这里总结一下，createTraceId()方法是提供给外部完成TraceId生成功能的。它内部调用私有静态方法getTraceid()生成32的一串TraceId的同时将该TraceId设置到本地线程的上下文TraceIdUtil中，并将该TraceId返回供后续业务使用。</p>
<h3 id="编写线程上下文TraceIdUtil"><a href="#编写线程上下文TraceIdUtil" class="headerlink" title="编写线程上下文TraceIdUtil"></a>编写线程上下文TraceIdUtil</h3><p>上面提到，生成TraceId的同时设置到了TraceIdUtil中，TraceIdUtil可以认为是当前线程/当前线程子线程的TraceId的容器，具体代码如下</p>
<pre><code>......
/**使用InheritableThreadLocal便于在主子线程间传递参数*/
private static final ThreadLocal&lt;String&gt; TRACE_ID = new InheritableThreadLocal&lt;&gt;();

public TraceIdUtil() {
}

/**
 * 从当前线程局部变量获取TraceId
 * 首次调用该方法会生成traceId，后续每次都从线程上下文获取
 * @return
 */
public static String getTraceId() {
    return TRACE_ID.get();
}

public static void setTraceId(String traceId) {
    TRACE_ID.set(traceId);
}

public static void removeTraceId() {
    TRACE_ID.remove();
}
......
</code></pre><p>有心的你可能发现了，我在这里使用了InheritableThreadLocal类作为TraceId保存的容器，之所以使用InheritableThreadLocal是要达到在当前线程的子线程中也能获取到TraceId的值，如果使用它的父类ThreadLocal则只能在当前线程获取到TraceId。关于InheritableThreadLocal的详细的介绍请自行参看文章末尾的参考链接中的《InheritableThreadLocal详解》一文，这里不再赘述。</p>
<p>通过TraceIdUtil，我们能够实现</p>
<ol>
<li>将TraceId设置到当前线程的线程上下文中</li>
<li>从当前线程上下文中获取TraceId</li>
<li>从当前线程上下文中移除TraceId等的功能。</li>
</ol>
<h3 id="编写自定义的TraceIdFilter实现com-alibaba-dubbo-rpc-Filter接口"><a href="#编写自定义的TraceIdFilter实现com-alibaba-dubbo-rpc-Filter接口" class="headerlink" title="编写自定义的TraceIdFilter实现com.alibaba.dubbo.rpc.Filter接口"></a>编写自定义的TraceIdFilter实现com.alibaba.dubbo.rpc.Filter接口</h3><p>完成前面的准备工作，我们即将进行工具包开发的重头戏，实现自定义的TraceId传递Filter。</p>
<p>编写类TraceIdFilter，实现接口com.alibaba.dubbo.rpc.Filter，重写其invoke方法。</p>
<p>核心代码如下：</p>
<pre><code>@Activate(group = {Constants.PROVIDER, Constants.CONSUMER})
public class TraceIdFilter implements Filter {

    ......
    @Override
    public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException {
        RpcContext rpcContext = RpcContext.getContext();
        String traceId = &quot;&quot;;
        if (rpcContext.isConsumerSide()) {
            if (StringUtils.isBlank(TraceIdUtil.getTraceId())) {
                // 根调用，生成TraceId
                traceId = TraceIdGenerator.createTraceId();
            } else {
                // 后续调用，从Rpc上下文取出并设置到线程上下文
                traceId = TraceIdUtil.getTraceId();
            }
            TraceIdUtil.setTraceId(traceId);
            RpcContext.getContext().setAttachment(TraceIdConst.TRACE_ID, TraceIdUtil.getTraceId());
        }
        if (rpcContext.isProviderSide()) {
            // 服务提供方，从Rpc上下文获取traceId
            traceId = RpcContext.getContext().getAttachment(TraceIdConst.TRACE_ID);
            TraceIdUtil.setTraceId(traceId);
        }
        Result result = invoker.invoke(invocation);
        return result;
    }
    ......
}
</code></pre><p>这里简单先接单介绍下 <strong>@Activate</strong> 注解，该注解表示一个扩展是否被激活(即是否能够使用), 它可以放在类定义、方法之上。dubbo用它在spi扩展类定义上，表示这个扩展实现激活条件和时机。</p>
<p>这里我将TraceIdFilter标注为</p>
<pre><code>@Activate(group = {Constants.PROVIDER, Constants.CONSUMER})
</code></pre><p>标识该拓展会在服务提供方和服务消费方同时生效。</p>
<p>接下来，我们详细的梳理一下重写的invoke方法的逻辑。</p>
<h4 id="ConsumerSide消费者侧核心逻辑"><a href="#ConsumerSide消费者侧核心逻辑" class="headerlink" title="ConsumerSide消费者侧核心逻辑"></a>ConsumerSide消费者侧核心逻辑</h4><p>首先获取到RpcContext上下文，判断当前调用者属于服务提供方还是服务消费方。</p>
<p>如果是服务消费方，则从线程上下文TraceIdUtil中获取TraceId判断其是否为空。即如下的判断逻辑</p>
<pre><code>if (StringUtils.isBlank(TraceIdUtil.getTraceId())) {
</code></pre><p>如果判断返回true，表明当前是消费侧的根调用，且消费侧没有显式的生成TraceId，则我们的组件生成一个TraceId设置到当前线程的上下文，并将其通过RpcContext隐式传参的方式传递给后续的服务。代码为</p>
<pre><code>TraceIdUtil.setTraceId(traceId);
RpcContext.getContext().setAttachment(TraceIdConst.TRACE_ID, TraceIdUtil.getTraceId());
</code></pre><p>如果线程上下文TraceIdUtil存在TraceId，表明当前消费端已经存在TraceId。</p>
<p>因为存在TraceId，则我们直接从线程上下文中取出该TraceId，并通过RpcContext隐式传参方式传递给后续的服务，核心代码为</p>
<pre><code>......
traceId = TraceIdUtil.getTraceId();
......
TraceIdUtil.setTraceId(traceId);
RpcContext.getContext().setAttachment(TraceIdConst.TRACE_ID, TraceIdUtil.getTraceId());
</code></pre><h4 id="ProviderSide提供者侧核心逻辑"><a href="#ProviderSide提供者侧核心逻辑" class="headerlink" title="ProviderSide提供者侧核心逻辑"></a>ProviderSide提供者侧核心逻辑</h4><p>提供者侧的逻辑就比较容易了，提供者的角色主要就是对TraceId的读取。</p>
<p>核心代码如下：</p>
<pre><code>if (rpcContext.isProviderSide()) {
    // 服务提供方，从Rpc上下文获取traceId
    traceId = RpcContext.getContext().getAttachment(TraceIdConst.TRACE_ID);
    TraceIdUtil.setTraceId(traceId);
}
</code></pre><p>可能这里你有疑问了，如果一个服务既是服务的提供者，又是消费者呢？该如何处理，其实在上文已经讲到了，如果它是提供方，则只需要从RpcContext上下文中读取TraceId进行使用即可。消费方的角色会在上述的消费者侧的逻辑处理，即读取TraceId，设置到当前线程，通过RpcContext隐式传递。</p>
<p>到这里，我们就完成了TraceFilter的主要逻辑，通过</p>
<pre><code>Result result = invoker.invoke(invocation);
return result;
</code></pre><p>使业务逻辑继续往下走即可。</p>
<h3 id="编写配置META-INF-dubbo-com-alibaba-dubbo-rpc-Filter"><a href="#编写配置META-INF-dubbo-com-alibaba-dubbo-rpc-Filter" class="headerlink" title="编写配置META-INF/dubbo/com.alibaba.dubbo.rpc.Filter"></a>编写配置META-INF/dubbo/com.alibaba.dubbo.rpc.Filter</h3><p>最后一步是dubbo的SPI规范要求的，不能更改。</p>
<p>在资源文件夹下创建 META-INF/dubbo 文件夹，在其中创建名为<strong>com.alibaba.dubbo.rpc.Filter</strong> 的文件，并编辑文件内容，在其中配置我们自定义的TraceIdFilter</p>
<pre><code>traceIdFilter=com.snowalker.shield.dubbo.tracer.TraceIdFilter
</code></pre><p>具体的文件包路径如下</p>
<pre><code>src
|-main
    |-java
        |-com
            |-xxx
                |-XxxFilter.java (实现Filter接口)
    |-resources
        |-META-INF
            |-dubbo
                |-org.apache.dubbo.rpc.Filter 
                (纯文本文件，内容为：xxx=com.xxx.XxxFilter)
</code></pre><p>要严格按照该路径进行开发和配置。</p>
<h2 id="打包上传私服"><a href="#打包上传私服" class="headerlink" title="打包上传私服"></a>打包上传私服</h2><p>到这里我们便可以打包该工具包并上传至私服，在业务中使用了。后续我会将完整的代码整理并上传至我的github仓库，以便读者自行参考打包使用。</p>
<pre><code>mvn clean deploy -Dmaven.test.skip=true
</code></pre><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文主要从开发及原理的角度，带领大家基于dubbo2.6.5实现了TraceId  <strong>设置/获取/传递</strong> 的需求，具有较高的实战价值。在下一篇中，我会以实际的案例展示如何在项目中使用该工具包，欢迎阅读。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="http://dubbo.apache.org/zh-cn/docs/dev/impls/filter.html" target="_blank" rel="external">dubbo官网：调用拦截扩展</a></p>
<p><a href="http://dubbo.apache.org/zh-cn/docs/source_code_guide/dubbo-spi.html" target="_blank" rel="external">dubbo官网：DUBBO SPI介绍</a></p>
<p><a href="http://dubbo.apache.org/zh-cn/docs/dev/principals/extension.html" target="_blank" rel="external">扩展点重构</a></p>
<p><a href="https://www.jianshu.com/p/94ba4a918ff5" target="_blank" rel="external">InheritableThreadLocal详解</a></p>
<p><a href="https://blog.csdn.net/hewenbo111/article/details/80487252" target="_blank" rel="external">InheritableThreadLocal——父线程传递本地变量到子线程的解决方式及分析</a></p>
<p><a href="https://www.jianshu.com/p/e0774f965aa3" target="_blank" rel="external">TransmittableThreadLocal详解</a></p>
<p><a href="https://www.cnblogs.com/wangzhuxing/p/9826555.html" target="_blank" rel="external">dubbo系列七、dubbo @Activate 注解使用和实现解析</a></p>
<p><a href="https://my.oschina.net/LucasZhu/blog/2046356" target="_blank" rel="external">Dubbo链路追踪——生成全局ID（traceId）</a></p>
<p><a href="https://www.cnblogs.com/hzzll/p/6738955.html" target="_blank" rel="external">maven中scope属性的介绍</a></p>
<p><a href="https://blog.csdn.net/meegomeego/article/details/8726124" target="_blank" rel="external">%02x 格式化符号代表什么</a></p>
<p><a href="https://blog.csdn.net/typ1805/article/details/82141983" target="_blank" rel="external">springboot整合dubbo报错No such extension traceIdFilter for filter/com.alibaba.dubbo.rpc.Filter</a></p>
<h2 id="补充知识点：Maven中-DskipTests和-Dmaven-test-skip-true的区别"><a href="#补充知识点：Maven中-DskipTests和-Dmaven-test-skip-true的区别" class="headerlink" title="补充知识点：Maven中-DskipTests和-Dmaven.test.skip=true的区别"></a>补充知识点：Maven中-DskipTests和-Dmaven.test.skip=true的区别</h2><p>在使用mv编译、打包时为了跳过测试，会使用参数-DskipTests和-Dmaven.test.skip=true，这两个参数的主要区别是：</p>
<pre><code>-DskipTests，不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下。

-Dmaven.test.skip=true，不执行测试用例也不编译测试用例类。
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在近期的两篇文章中，我带领大家使用springboot2.x整合了dubbo，完成了一个基础的服务化开发框架的搭建。文章链接如下&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://wuwenliang.net/2019/02/20/dubbo-springboot2-x%E6%95%B4%E5%90%88dubbo%E4%B9%8B%E4%BD%BF%E7%94%A8dubbo-spring-boot-starter/&quot;&gt;[dubbo]springboot2.x整合dubbo之使用dubbo-spring-boot-starter
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://wuwenliang.net/2019/02/20/dubbo-springboot2-x%E6%95%B4%E5%90%88dubbo%E4%B9%8B%E6%95%B4%E5%90%88dubbo2-6-5/&quot;&gt;[dubbo]springboot2.x整合dubbo之基于xml整合dubbo2.6.5
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;但是在生产环境下还是存在一定的问题，比如我们关心的调用链追踪的问题。&lt;/p&gt;
&lt;p&gt;本文中，我将继续带领大家基于dubbo2.6.5开发一个轻量级的TraceId获取及传递工具包，实现在dubbo服务的提供方及消费方中 &lt;strong&gt;设置/获取/传递&lt;/strong&gt; TraceId的需求。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/TaXueWWL/shield-dubbo-tracer&quot;&gt;代码地址&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="自己写分布式组件系列" scheme="http://wuwenliang.net/categories/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E7%BB%84%E4%BB%B6%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="自己写分布式组件系列" scheme="http://wuwenliang.net/tags/%E8%87%AA%E5%B7%B1%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E7%BB%84%E4%BB%B6%E7%B3%BB%E5%88%97/"/>
    
  </entry>
  
</feed>
